{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1\n",
    "\n",
    "1. Generate strings of length 15 over the alphabet a, b, c, d\n",
    "\n",
    "2. Label your strings basing on matching a 5-element regular expression\n",
    "\n",
    "3. Balance your dataset of size 10000 so that approximately half of the dataset contains regex-matching parts.\n",
    "\n",
    "4. Prepare your data for training using one-hot encoding\n",
    "\n",
    "5. Divide your dataset into training and testing parts.\n",
    "\n",
    "6. Implement and train a model consisting of one convolutional layer with one filter followed by one fully-connected layer and train it to classify your strings. After training, examine the values of the filter\n",
    "\n",
    "7. Implement and train more complex models (more filters, layers) and analyze their performance on the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def generate_string(length = 15, alphabet = \"abcd\", pattern = \"cabad\", contains = True):\n",
    "      \n",
    "      pattern_len = len(pattern)\n",
    "      if contains: \n",
    "            # we need to generate prefix and sufix to our pattern both might be 0 lentgth ofc \n",
    "            prefix_len = random.randint(0,length - pattern_len)\n",
    "            suffix_len = length - pattern_len - prefix_len\n",
    "            prefix = ''.join(random.choices(\"abcd\" , k=prefix_len))\n",
    "            suffix = ''.join(random.choices(\"abcd\" , k=suffix_len))\n",
    "            return prefix + pattern + suffix\n",
    "      else: \n",
    "            while True:\n",
    "                  candidate = ''.join(random.choices(\"abcd\" , k=length))\n",
    "                  if pattern not in candidate:\n",
    "                        return candidate\n",
    "def generate_dataset(size = 10000):\n",
    "      expressions = []\n",
    "      labels = []\n",
    "      half = size // 2\n",
    "      \n",
    "      \n",
    "      for _ in range(half):\n",
    "            expressions.append(generate_string(length=15,alphabet=\"abcd\",pattern=\"cabad\",contains=True))\n",
    "            labels.append(1)\n",
    "      for _ in range(size- half):\n",
    "            expressions.append(generate_string(length=15,alphabet=\"abcd\",pattern=\"cabad\",contains=False))\n",
    "            labels.append(0)\n",
    "            \n",
    "      return pd.DataFrame({\"expressions\":expressions,\"contains_abcd\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cbbabaacccaacab'"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_string(contains=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expressions</th>\n",
       "      <th>contains_abcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bbcabaddbabaadc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcabaddabacbdda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dcccdcccabadbcd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>addbcabadaabdcc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cabadcbaccddccd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>acbcbaddacbadbd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>abcaabacacdadbd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>abbdacdaabadbcc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>bbdbdbcbbbadaaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>bbccdcdacaccbcb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          expressions  contains_abcd\n",
       "0     bbcabaddbabaadc              1\n",
       "1     bcabaddabacbdda              1\n",
       "2     dcccdcccabadbcd              1\n",
       "3     addbcabadaabdcc              1\n",
       "4     cabadcbaccddccd              1\n",
       "...               ...            ...\n",
       "9995  acbcbaddacbadbd              0\n",
       "9996  abcaabacacdadbd              0\n",
       "9997  abbdacdaabadbcc              0\n",
       "9998  bbdbdbcbbbadaaa              0\n",
       "9999  bbccdcdacaccbcb              0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 1402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indexes = {'a':0,'b':1,'c':2,'d':3}\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_expression(s,map,num_classes):\n",
    "    one_hot = torch.zeros(size = (len(s),num_classes))\n",
    "    for i, char in enumerate(s):\n",
    "        one_hot[i,map[char]] = 1 \n",
    "    return one_hot\n",
    "def one_hot_encode_dataset(dataset,shape,map):\n",
    "    table = torch.empty(size = shape)\n",
    "    for i,s in enumerate(dataset.iloc[:,0]):\n",
    "        table[i] = one_hot_encode_expression(s,map = map,num_classes= shape[-1])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_character(char,characters = ['a','b','c','d']):\n",
    "    index = torch.argmax(char)\n",
    "    return characters[index]\n",
    "\n",
    "def decode_string(dataset, index):\n",
    "    expression = \"\"\n",
    "    for letter in dataset[index]:\n",
    "        expression += decode_character(letter)\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generate_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode_expression(s,char_indexes,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.empty(size = (10000,15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_dataset(dataset,shape,map):\n",
    "    table = torch.empty(size = shape)\n",
    "    for i,s in enumerate(dataset.iloc[:,0]):\n",
    "        table[i] = one_hot_encode_expression(s,map = map,num_classes= shape[-1])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot_encode_dataset(dataset=df,shape = (10000,15,4),map =char_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_string(dataset=X,index=5000) == df.iloc[5000,0]  # to make sure that one hot encoding works correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(data=df.iloc[:,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oh = torch.nn.functional.one_hot(y,num_classes=2)  # it will be probably useful to keep labels in both vector and one hot tensor form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X.view(10000,4,15),y,test_size=0.2)  # to have shape as desired by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 1., 0.]],\n",
       " \n",
       "         [[0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [1., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 1., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 1., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.]]]),\n",
       " tensor([1, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 1416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5].view(5,15,4),y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh , y_test_oh = nn.functional.one_hot(y_train,num_classes=2).type(torch.float32) , nn.functional.one_hot(y_test,num_classes=2).type(torch.float32)  # it will be probably useful to keep labels in both vector and one hot tensor form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 0]),\n",
       " tensor([[0., 1.],\n",
       "         [1., 0.]]))"
      ]
     },
     "execution_count": 1418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2],y_train_oh[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 4, 15])"
      ]
     },
     "execution_count": 1419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 1., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 1.,  ..., 1., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 1420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 1421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple conv model \n",
    "class SimpleConvNet(nn.Module):\n",
    "    # in channels is equal to number of alphabet letters from which dataset is constructed 4 in case of abcd \n",
    "    # 1 out channels = one filter \n",
    "    # let's go with kernel size equal to pattern length 5 in oour case\n",
    "    def __init__(self,num_chars,pattern_len):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=num_chars , out_channels = 1,kernel_size= pattern_len,bias = False),\n",
    "                                   nn.ReLU())\n",
    "        self.fc = nn.Linear(in_features=11,out_features=2,bias= False)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.squeeze()\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvNet(num_chars=4,pattern_len=5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 4, 15])"
      ]
     },
     "execution_count": 1424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create custom dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    \n",
    "# Create Dataset instances\n",
    "train_dataset = TensorDataset(X_train, y_train_oh)\n",
    "test_dataset = TensorDataset(X_test, y_test_oh)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          dataloader,\n",
    "          loss_fn,\n",
    "          optimizer,\n",
    "          epochs = 10):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "    # put model in train mode\n",
    "    \n",
    "\n",
    "      \n",
    "      # setrup train loss and accuracy \n",
    "      model.train()\n",
    "      train_loss , train_acc = 0,0\n",
    "      # loop through dataloader in batches \n",
    "      for batch, (X,y) in enumerate(dataloader):\n",
    "            \n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(X)\n",
    "          \n",
    "            # calcualte loss \n",
    "            loss = loss_fn(y_pred,y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # zero grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # loss backward \n",
    "            loss.backward()\n",
    "            \n",
    "            # optimizer step \n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "           \n",
    "            # Adjust metrics to get average loss  per batch \n",
    "      train_loss = train_loss / len(dataloader)\n",
    "      \n",
    "      print(f\"Epoch{epoch} | train loss {train_loss}\")\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 | train loss 0.6162455262988806\n",
      "Epoch1 | train loss 0.6159301717579365\n",
      "Epoch2 | train loss 0.6156205464154482\n",
      "Epoch3 | train loss 0.6153219208866357\n",
      "Epoch4 | train loss 0.6150265320762992\n",
      "Epoch5 | train loss 0.6147287131100893\n",
      "Epoch6 | train loss 0.6144331711158156\n",
      "Epoch7 | train loss 0.6141345789283514\n",
      "Epoch8 | train loss 0.6138305127993227\n",
      "Epoch9 | train loss 0.6135298562794924\n",
      "Epoch10 | train loss 0.6132428694516421\n",
      "Epoch11 | train loss 0.6129669805243612\n",
      "Epoch12 | train loss 0.6127045322209597\n",
      "Epoch13 | train loss 0.6124401993304491\n",
      "Epoch14 | train loss 0.6121680257096886\n",
      "Epoch15 | train loss 0.6118951651081442\n",
      "Epoch16 | train loss 0.6116393000632524\n",
      "Epoch17 | train loss 0.6113893457129598\n",
      "Epoch18 | train loss 0.6111458441615105\n",
      "Epoch19 | train loss 0.6109024115279317\n",
      "Epoch20 | train loss 0.6106596566736698\n",
      "Epoch21 | train loss 0.6104140988737344\n",
      "Epoch22 | train loss 0.6101668963581324\n",
      "Epoch23 | train loss 0.6099217769131065\n",
      "Epoch24 | train loss 0.6096788489446044\n",
      "Epoch25 | train loss 0.6094334144517779\n",
      "Epoch26 | train loss 0.6091935941949487\n",
      "Epoch27 | train loss 0.6089571134373546\n",
      "Epoch28 | train loss 0.6087178127840162\n",
      "Epoch29 | train loss 0.6084873295947909\n",
      "Epoch30 | train loss 0.6082585858926177\n",
      "Epoch31 | train loss 0.6080239380896092\n",
      "Epoch32 | train loss 0.6077827168628573\n",
      "Epoch33 | train loss 0.6075536666065454\n",
      "Epoch34 | train loss 0.6073235144838691\n",
      "Epoch35 | train loss 0.6070911958068609\n",
      "Epoch36 | train loss 0.6068561093136668\n",
      "Epoch37 | train loss 0.6066288160532713\n",
      "Epoch38 | train loss 0.606410589814186\n",
      "Epoch39 | train loss 0.6061973769962787\n",
      "Epoch40 | train loss 0.6059862312301993\n",
      "Epoch41 | train loss 0.6057764062657952\n",
      "Epoch42 | train loss 0.6055606340616941\n",
      "Epoch43 | train loss 0.6053423450887203\n",
      "Epoch44 | train loss 0.6051345992088318\n",
      "Epoch45 | train loss 0.6049319332465529\n",
      "Epoch46 | train loss 0.6047332092002035\n",
      "Epoch47 | train loss 0.6045346217602492\n",
      "Epoch48 | train loss 0.6043393640965223\n",
      "Epoch49 | train loss 0.6041486493125557\n",
      "Epoch50 | train loss 0.6039594847336411\n",
      "Epoch51 | train loss 0.6037839363887906\n",
      "Epoch52 | train loss 0.6036127695441246\n",
      "Epoch53 | train loss 0.6034477001056076\n",
      "Epoch54 | train loss 0.6032867187261581\n",
      "Epoch55 | train loss 0.6031294639408589\n",
      "Epoch56 | train loss 0.6029718927294015\n",
      "Epoch57 | train loss 0.6028165050968528\n",
      "Epoch58 | train loss 0.6026606296002864\n",
      "Epoch59 | train loss 0.6025096793845296\n",
      "Epoch60 | train loss 0.6023663221299649\n",
      "Epoch61 | train loss 0.6022268015146256\n",
      "Epoch62 | train loss 0.6020894788578153\n",
      "Epoch63 | train loss 0.6019555665552616\n",
      "Epoch64 | train loss 0.6018296450003982\n",
      "Epoch65 | train loss 0.6017026991397142\n",
      "Epoch66 | train loss 0.6015772073715925\n",
      "Epoch67 | train loss 0.6014552019536495\n",
      "Epoch68 | train loss 0.6013383115828037\n",
      "Epoch69 | train loss 0.601225830540061\n",
      "Epoch70 | train loss 0.6011143720149994\n",
      "Epoch71 | train loss 0.6010074197500944\n",
      "Epoch72 | train loss 0.6009030218049883\n",
      "Epoch73 | train loss 0.6008016247674823\n",
      "Epoch74 | train loss 0.6007036527991295\n",
      "Epoch75 | train loss 0.6006070782616735\n",
      "Epoch76 | train loss 0.6005128775164486\n",
      "Epoch77 | train loss 0.6004190278425813\n",
      "Epoch78 | train loss 0.6003262774273753\n",
      "Epoch79 | train loss 0.6002341047674418\n",
      "Epoch80 | train loss 0.6001423615589738\n",
      "Epoch81 | train loss 0.6000508263334632\n",
      "Epoch82 | train loss 0.5999608047306537\n",
      "Epoch83 | train loss 0.5998692829161882\n",
      "Epoch84 | train loss 0.5997786436602474\n",
      "Epoch85 | train loss 0.5996905924752355\n",
      "Epoch86 | train loss 0.5996008676290512\n",
      "Epoch87 | train loss 0.5995070337876678\n",
      "Epoch88 | train loss 0.599411944039166\n",
      "Epoch89 | train loss 0.5993182006105781\n",
      "Epoch90 | train loss 0.5992246932536364\n",
      "Epoch91 | train loss 0.5991292559728026\n",
      "Epoch92 | train loss 0.5990264105051756\n",
      "Epoch93 | train loss 0.598924758322537\n",
      "Epoch94 | train loss 0.5988248938694596\n",
      "Epoch95 | train loss 0.5987291030213236\n",
      "Epoch96 | train loss 0.5986351911351084\n",
      "Epoch97 | train loss 0.5985349529236555\n",
      "Epoch98 | train loss 0.5984354501217604\n",
      "Epoch99 | train loss 0.5983321344479918\n",
      "Epoch100 | train loss 0.598231109417975\n",
      "Epoch101 | train loss 0.5981265990808606\n",
      "Epoch102 | train loss 0.5980232076719403\n",
      "Epoch103 | train loss 0.5979208288714289\n",
      "Epoch104 | train loss 0.5978170400485396\n",
      "Epoch105 | train loss 0.597715744562447\n",
      "Epoch106 | train loss 0.5976119768247008\n",
      "Epoch107 | train loss 0.5975063341110944\n",
      "Epoch108 | train loss 0.59740225430578\n",
      "Epoch109 | train loss 0.5972934981063008\n",
      "Epoch110 | train loss 0.5971854250878096\n",
      "Epoch111 | train loss 0.5970777584984899\n",
      "Epoch112 | train loss 0.5969764597341418\n",
      "Epoch113 | train loss 0.5968705914542078\n",
      "Epoch114 | train loss 0.596761220395565\n",
      "Epoch115 | train loss 0.5966540006920695\n",
      "Epoch116 | train loss 0.5965466561913491\n",
      "Epoch117 | train loss 0.5964438155293464\n",
      "Epoch118 | train loss 0.5963401266559959\n",
      "Epoch119 | train loss 0.5962387287616729\n",
      "Epoch120 | train loss 0.5961389941722155\n",
      "Epoch121 | train loss 0.5960389619320631\n",
      "Epoch122 | train loss 0.5959419183805585\n",
      "Epoch123 | train loss 0.5958463243767619\n",
      "Epoch124 | train loss 0.5957509046792984\n",
      "Epoch125 | train loss 0.5956553963944315\n",
      "Epoch126 | train loss 0.5955554592609406\n",
      "Epoch127 | train loss 0.5954546866938472\n",
      "Epoch128 | train loss 0.5953557388857007\n",
      "Epoch129 | train loss 0.5952597579360008\n",
      "Epoch130 | train loss 0.5951614540070296\n",
      "Epoch131 | train loss 0.5950607541203499\n",
      "Epoch132 | train loss 0.5949459231272339\n",
      "Epoch133 | train loss 0.5948317148908973\n",
      "Epoch134 | train loss 0.5947223523259163\n",
      "Epoch135 | train loss 0.5946184989064932\n",
      "Epoch136 | train loss 0.5945123675093055\n",
      "Epoch137 | train loss 0.5944029148668051\n",
      "Epoch138 | train loss 0.5942945490032434\n",
      "Epoch139 | train loss 0.5941847545281053\n",
      "Epoch140 | train loss 0.5940731811150909\n",
      "Epoch141 | train loss 0.5939606495201588\n",
      "Epoch142 | train loss 0.5938512893766165\n",
      "Epoch143 | train loss 0.593741351403296\n",
      "Epoch144 | train loss 0.5936190179362894\n",
      "Epoch145 | train loss 0.5934878058359027\n",
      "Epoch146 | train loss 0.5933579731360078\n",
      "Epoch147 | train loss 0.5932398631796241\n",
      "Epoch148 | train loss 0.5931176886707544\n",
      "Epoch149 | train loss 0.592990140132606\n",
      "Epoch150 | train loss 0.5928660883754492\n",
      "Epoch151 | train loss 0.5927430659905076\n",
      "Epoch152 | train loss 0.5926282858476043\n",
      "Epoch153 | train loss 0.5925200575217605\n",
      "Epoch154 | train loss 0.5924111612141132\n",
      "Epoch155 | train loss 0.5923007054999471\n",
      "Epoch156 | train loss 0.5921928936243057\n",
      "Epoch157 | train loss 0.5920873324945569\n",
      "Epoch158 | train loss 0.5919824266806245\n",
      "Epoch159 | train loss 0.5918817965686322\n",
      "Epoch160 | train loss 0.5917799996957183\n",
      "Epoch161 | train loss 0.591675128415227\n",
      "Epoch162 | train loss 0.5915692375227809\n",
      "Epoch163 | train loss 0.5914651926979423\n",
      "Epoch164 | train loss 0.5913608640804887\n",
      "Epoch165 | train loss 0.5912540097534656\n",
      "Epoch166 | train loss 0.591148874759674\n",
      "Epoch167 | train loss 0.5910466958209872\n",
      "Epoch168 | train loss 0.5909398483112455\n",
      "Epoch169 | train loss 0.5908301493898034\n",
      "Epoch170 | train loss 0.5907227672636509\n",
      "Epoch171 | train loss 0.5906172339245677\n",
      "Epoch172 | train loss 0.590513661839068\n",
      "Epoch173 | train loss 0.5904133828729391\n",
      "Epoch174 | train loss 0.5903196443989873\n",
      "Epoch175 | train loss 0.5902288337424397\n",
      "Epoch176 | train loss 0.5901399096474051\n",
      "Epoch177 | train loss 0.5900520535930991\n",
      "Epoch178 | train loss 0.5899620132520795\n",
      "Epoch179 | train loss 0.5898660572245717\n",
      "Epoch180 | train loss 0.5897681330889464\n",
      "Epoch181 | train loss 0.5896694470569491\n",
      "Epoch182 | train loss 0.5895746584609151\n",
      "Epoch183 | train loss 0.5894809047132731\n",
      "Epoch184 | train loss 0.5893894750252366\n",
      "Epoch185 | train loss 0.5892994657531381\n",
      "Epoch186 | train loss 0.5892113783955574\n",
      "Epoch187 | train loss 0.5891224544495344\n",
      "Epoch188 | train loss 0.589031144529581\n",
      "Epoch189 | train loss 0.5889398508146405\n",
      "Epoch190 | train loss 0.5888511279225349\n",
      "Epoch191 | train loss 0.5887637019529939\n",
      "Epoch192 | train loss 0.588668955154717\n",
      "Epoch193 | train loss 0.5885732675716281\n",
      "Epoch194 | train loss 0.5884793880581856\n",
      "Epoch195 | train loss 0.58838728684932\n",
      "Epoch196 | train loss 0.5882992171868682\n",
      "Epoch197 | train loss 0.5882142871245741\n",
      "Epoch198 | train loss 0.5881307709217072\n",
      "Epoch199 | train loss 0.588047829978168\n",
      "Epoch200 | train loss 0.5879653813317418\n",
      "Epoch201 | train loss 0.5878843504935503\n",
      "Epoch202 | train loss 0.587802689857781\n",
      "Epoch203 | train loss 0.5877187990769744\n",
      "Epoch204 | train loss 0.5876327011734247\n",
      "Epoch205 | train loss 0.5875439111888409\n",
      "Epoch206 | train loss 0.5874545244127511\n",
      "Epoch207 | train loss 0.5873643469437957\n",
      "Epoch208 | train loss 0.5872733192145825\n",
      "Epoch209 | train loss 0.5871835012733936\n",
      "Epoch210 | train loss 0.5870967384427785\n",
      "Epoch211 | train loss 0.5870086592808366\n",
      "Epoch212 | train loss 0.5869194729626179\n",
      "Epoch213 | train loss 0.5868294537812472\n",
      "Epoch214 | train loss 0.586738292388618\n",
      "Epoch215 | train loss 0.5866480673104525\n",
      "Epoch216 | train loss 0.586559866592288\n",
      "Epoch217 | train loss 0.586471831202507\n",
      "Epoch218 | train loss 0.5863830771297216\n",
      "Epoch219 | train loss 0.5862914190813899\n",
      "Epoch220 | train loss 0.5861995999515056\n",
      "Epoch221 | train loss 0.5861066410318017\n",
      "Epoch222 | train loss 0.5860162410140037\n",
      "Epoch223 | train loss 0.5859304709360004\n",
      "Epoch224 | train loss 0.585848539173603\n",
      "Epoch225 | train loss 0.5857677068188787\n",
      "Epoch226 | train loss 0.5856857741996646\n",
      "Epoch227 | train loss 0.5856020548194647\n",
      "Epoch228 | train loss 0.5855199382454157\n",
      "Epoch229 | train loss 0.5854388320073486\n",
      "Epoch230 | train loss 0.5853587026894093\n",
      "Epoch231 | train loss 0.5852826395258307\n",
      "Epoch232 | train loss 0.585207546427846\n",
      "Epoch233 | train loss 0.5851337070390582\n",
      "Epoch234 | train loss 0.5850583875924349\n",
      "Epoch235 | train loss 0.5849809155985713\n",
      "Epoch236 | train loss 0.58490408513695\n",
      "Epoch237 | train loss 0.5848268511518836\n",
      "Epoch238 | train loss 0.5847473398968578\n",
      "Epoch239 | train loss 0.5846678614616394\n",
      "Epoch240 | train loss 0.5845884278416633\n",
      "Epoch241 | train loss 0.5845071744173765\n",
      "Epoch242 | train loss 0.5844265129417181\n",
      "Epoch243 | train loss 0.5843419072031975\n",
      "Epoch244 | train loss 0.584257166981697\n",
      "Epoch245 | train loss 0.5841729900985956\n",
      "Epoch246 | train loss 0.5840883179754018\n",
      "Epoch247 | train loss 0.5840068251267075\n",
      "Epoch248 | train loss 0.5839272490143776\n",
      "Epoch249 | train loss 0.5838460626080633\n",
      "Epoch250 | train loss 0.5837641539797187\n",
      "Epoch251 | train loss 0.5836820938065648\n",
      "Epoch252 | train loss 0.5836014031246305\n",
      "Epoch253 | train loss 0.5835205056518317\n",
      "Epoch254 | train loss 0.5834422418102622\n",
      "Epoch255 | train loss 0.5833629401400685\n",
      "Epoch256 | train loss 0.5832837713509798\n",
      "Epoch257 | train loss 0.5832051854208111\n",
      "Epoch258 | train loss 0.5831286404281855\n",
      "Epoch259 | train loss 0.583051593862474\n",
      "Epoch260 | train loss 0.5829770588502288\n",
      "Epoch261 | train loss 0.5829028495773673\n",
      "Epoch262 | train loss 0.5828299770504236\n",
      "Epoch263 | train loss 0.5827558180689811\n",
      "Epoch264 | train loss 0.5826814882457256\n",
      "Epoch265 | train loss 0.5826088095083832\n",
      "Epoch266 | train loss 0.5825321496278048\n",
      "Epoch267 | train loss 0.5824572642520071\n",
      "Epoch268 | train loss 0.5823792032897472\n",
      "Epoch269 | train loss 0.5823011117428541\n",
      "Epoch270 | train loss 0.5822237100824714\n",
      "Epoch271 | train loss 0.5821462373435498\n",
      "Epoch272 | train loss 0.5820653021708131\n",
      "Epoch273 | train loss 0.58198501303792\n",
      "Epoch274 | train loss 0.5819053684547544\n",
      "Epoch275 | train loss 0.5818290085345507\n",
      "Epoch276 | train loss 0.5817552307620645\n",
      "Epoch277 | train loss 0.5816823370754719\n",
      "Epoch278 | train loss 0.581611424908042\n",
      "Epoch279 | train loss 0.5815394942834974\n",
      "Epoch280 | train loss 0.5814676356688142\n",
      "Epoch281 | train loss 0.5813954230770468\n",
      "Epoch282 | train loss 0.581323926821351\n",
      "Epoch283 | train loss 0.5812543115764857\n",
      "Epoch284 | train loss 0.5811831400543451\n",
      "Epoch285 | train loss 0.5811144823208452\n",
      "Epoch286 | train loss 0.5810438848286867\n",
      "Epoch287 | train loss 0.5809742249548435\n",
      "Epoch288 | train loss 0.5809045728296042\n",
      "Epoch289 | train loss 0.5808371610194445\n",
      "Epoch290 | train loss 0.5807715691253543\n",
      "Epoch291 | train loss 0.5807081773132086\n",
      "Epoch292 | train loss 0.5806474228203297\n",
      "Epoch293 | train loss 0.5805855530127882\n",
      "Epoch294 | train loss 0.5805248420313001\n",
      "Epoch295 | train loss 0.5804636907577515\n",
      "Epoch296 | train loss 0.5804042847082019\n",
      "Epoch297 | train loss 0.5803457375615835\n",
      "Epoch298 | train loss 0.5802870582044125\n",
      "Epoch299 | train loss 0.5802288559824228\n",
      "Epoch300 | train loss 0.5801706961169839\n",
      "Epoch301 | train loss 0.5801138881221414\n",
      "Epoch302 | train loss 0.5800592638552189\n",
      "Epoch303 | train loss 0.5800049113109708\n",
      "Epoch304 | train loss 0.5799511285126209\n",
      "Epoch305 | train loss 0.5798980110511184\n",
      "Epoch306 | train loss 0.5798451917618513\n",
      "Epoch307 | train loss 0.5797907116636634\n",
      "Epoch308 | train loss 0.5797384846583009\n",
      "Epoch309 | train loss 0.5796869460493326\n",
      "Epoch310 | train loss 0.5796358279511332\n",
      "Epoch311 | train loss 0.5795843582972884\n",
      "Epoch312 | train loss 0.5795324255153537\n",
      "Epoch313 | train loss 0.5794795605540276\n",
      "Epoch314 | train loss 0.5794263429567218\n",
      "Epoch315 | train loss 0.5793730131536722\n",
      "Epoch316 | train loss 0.5793197881057859\n",
      "Epoch317 | train loss 0.5792660985514522\n",
      "Epoch318 | train loss 0.57921332154423\n",
      "Epoch319 | train loss 0.5791605109721423\n",
      "Epoch320 | train loss 0.5791067808866501\n",
      "Epoch321 | train loss 0.579052753597498\n",
      "Epoch322 | train loss 0.5789995763450861\n",
      "Epoch323 | train loss 0.5789479246735573\n",
      "Epoch324 | train loss 0.5788964981585741\n",
      "Epoch325 | train loss 0.5788478928431868\n",
      "Epoch326 | train loss 0.5787891167029738\n",
      "Epoch327 | train loss 0.5787206162512303\n",
      "Epoch328 | train loss 0.5786517261341214\n",
      "Epoch329 | train loss 0.5785874901339412\n",
      "Epoch330 | train loss 0.578525015860796\n",
      "Epoch331 | train loss 0.5784627158939838\n",
      "Epoch332 | train loss 0.5783981867134571\n",
      "Epoch333 | train loss 0.5783315555006265\n",
      "Epoch334 | train loss 0.5782655667513609\n",
      "Epoch335 | train loss 0.5781983902305364\n",
      "Epoch336 | train loss 0.5781323331966997\n",
      "Epoch337 | train loss 0.5780666328966617\n",
      "Epoch338 | train loss 0.5779978617653251\n",
      "Epoch339 | train loss 0.577932448014617\n",
      "Epoch340 | train loss 0.577865797393024\n",
      "Epoch341 | train loss 0.5778026565164328\n",
      "Epoch342 | train loss 0.577740284241736\n",
      "Epoch343 | train loss 0.5776799505203962\n",
      "Epoch344 | train loss 0.5776194842532277\n",
      "Epoch345 | train loss 0.5775576469302177\n",
      "Epoch346 | train loss 0.5774938890337944\n",
      "Epoch347 | train loss 0.5774307195097208\n",
      "Epoch348 | train loss 0.5773670517653227\n",
      "Epoch349 | train loss 0.5773036463186145\n",
      "Epoch350 | train loss 0.5772401385754347\n",
      "Epoch351 | train loss 0.5771756756678224\n",
      "Epoch352 | train loss 0.5771107112988829\n",
      "Epoch353 | train loss 0.5770476296916605\n",
      "Epoch354 | train loss 0.576987848803401\n",
      "Epoch355 | train loss 0.5769262143969536\n",
      "Epoch356 | train loss 0.5768639805167913\n",
      "Epoch357 | train loss 0.5768018330633641\n",
      "Epoch358 | train loss 0.5767413830012083\n",
      "Epoch359 | train loss 0.5766807846724987\n",
      "Epoch360 | train loss 0.5766198357194662\n",
      "Epoch361 | train loss 0.5765577284619212\n",
      "Epoch362 | train loss 0.5764896083623171\n",
      "Epoch363 | train loss 0.5764234310388565\n",
      "Epoch364 | train loss 0.5763588299229742\n",
      "Epoch365 | train loss 0.5762955690175295\n",
      "Epoch366 | train loss 0.5762327396124601\n",
      "Epoch367 | train loss 0.5761703677475453\n",
      "Epoch368 | train loss 0.5761088213324547\n",
      "Epoch369 | train loss 0.5760483257845044\n",
      "Epoch370 | train loss 0.5759872447326779\n",
      "Epoch371 | train loss 0.5759283779934049\n",
      "Epoch372 | train loss 0.5758695246651768\n",
      "Epoch373 | train loss 0.5758138754963875\n",
      "Epoch374 | train loss 0.5757556535676122\n",
      "Epoch375 | train loss 0.5756981308944523\n",
      "Epoch376 | train loss 0.5756417899765074\n",
      "Epoch377 | train loss 0.5755839704349637\n",
      "Epoch378 | train loss 0.5755245381593704\n",
      "Epoch379 | train loss 0.5754679671116173\n",
      "Epoch380 | train loss 0.5754137734882534\n",
      "Epoch381 | train loss 0.5753575191460549\n",
      "Epoch382 | train loss 0.5753039320372045\n",
      "Epoch383 | train loss 0.5752504874393344\n",
      "Epoch384 | train loss 0.5751948798634112\n",
      "Epoch385 | train loss 0.575139834806323\n",
      "Epoch386 | train loss 0.57508505506441\n",
      "Epoch387 | train loss 0.5750298065692186\n",
      "Epoch388 | train loss 0.5749734159186483\n",
      "Epoch389 | train loss 0.574915364459157\n",
      "Epoch390 | train loss 0.5748590525053442\n",
      "Epoch391 | train loss 0.5748020269721746\n",
      "Epoch392 | train loss 0.5747459683939815\n",
      "Epoch393 | train loss 0.5746908541768789\n",
      "Epoch394 | train loss 0.5746371809765697\n",
      "Epoch395 | train loss 0.5745814832672477\n",
      "Epoch396 | train loss 0.5745260361023248\n",
      "Epoch397 | train loss 0.5744710526242852\n",
      "Epoch398 | train loss 0.5744171393848956\n",
      "Epoch399 | train loss 0.5743657699227334\n",
      "Epoch400 | train loss 0.5743153955414891\n",
      "Epoch401 | train loss 0.5742659097909928\n",
      "Epoch402 | train loss 0.574216999169439\n",
      "Epoch403 | train loss 0.5741661450080574\n",
      "Epoch404 | train loss 0.5741128575988114\n",
      "Epoch405 | train loss 0.5740605729445815\n",
      "Epoch406 | train loss 0.5740067489631474\n",
      "Epoch407 | train loss 0.5739511820115148\n",
      "Epoch408 | train loss 0.5738981561176479\n",
      "Epoch409 | train loss 0.5738467049412429\n",
      "Epoch410 | train loss 0.5737961667776108\n",
      "Epoch411 | train loss 0.573746544457972\n",
      "Epoch412 | train loss 0.5736974722892046\n",
      "Epoch413 | train loss 0.5736484670452774\n",
      "Epoch414 | train loss 0.5736004929617047\n",
      "Epoch415 | train loss 0.5735534847900271\n",
      "Epoch416 | train loss 0.573505287244916\n",
      "Epoch417 | train loss 0.5734584212861955\n",
      "Epoch418 | train loss 0.573412755355239\n",
      "Epoch419 | train loss 0.573365776296705\n",
      "Epoch420 | train loss 0.5733178996667266\n",
      "Epoch421 | train loss 0.5732709887064993\n",
      "Epoch422 | train loss 0.5732224522344768\n",
      "Epoch423 | train loss 0.5731709968857467\n",
      "Epoch424 | train loss 0.5731215257570148\n",
      "Epoch425 | train loss 0.5730730056576431\n",
      "Epoch426 | train loss 0.5730260385945439\n",
      "Epoch427 | train loss 0.5729792481288314\n",
      "Epoch428 | train loss 0.5729335151426495\n",
      "Epoch429 | train loss 0.5728858731687069\n",
      "Epoch430 | train loss 0.572838396448642\n",
      "Epoch431 | train loss 0.5727908935584128\n",
      "Epoch432 | train loss 0.572745379600674\n",
      "Epoch433 | train loss 0.5727017891034484\n",
      "Epoch434 | train loss 0.5726583221927285\n",
      "Epoch435 | train loss 0.5726166288368404\n",
      "Epoch436 | train loss 0.5725738757662475\n",
      "Epoch437 | train loss 0.5725304729305207\n",
      "Epoch438 | train loss 0.5724899546802044\n",
      "Epoch439 | train loss 0.5724498341046274\n",
      "Epoch440 | train loss 0.5724112380295991\n",
      "Epoch441 | train loss 0.5723736236616969\n",
      "Epoch442 | train loss 0.5723355641216039\n",
      "Epoch443 | train loss 0.5722960979118943\n",
      "Epoch444 | train loss 0.5722573378682136\n",
      "Epoch445 | train loss 0.5722201389074325\n",
      "Epoch446 | train loss 0.5721827605739236\n",
      "Epoch447 | train loss 0.5721470141038298\n",
      "Epoch448 | train loss 0.5721113328076899\n",
      "Epoch449 | train loss 0.5720760959014296\n",
      "Epoch450 | train loss 0.5720418009907007\n",
      "Epoch451 | train loss 0.5720090963691473\n",
      "Epoch452 | train loss 0.5719779682904482\n",
      "Epoch453 | train loss 0.5719463771954179\n",
      "Epoch454 | train loss 0.57191495815292\n",
      "Epoch455 | train loss 0.5718842843919992\n",
      "Epoch456 | train loss 0.5718531312048435\n",
      "Epoch457 | train loss 0.5718238602951169\n",
      "Epoch458 | train loss 0.5717936861701309\n",
      "Epoch459 | train loss 0.5717642381973564\n",
      "Epoch460 | train loss 0.571735919546336\n",
      "Epoch461 | train loss 0.5717074077948928\n",
      "Epoch462 | train loss 0.5716797250322998\n",
      "Epoch463 | train loss 0.5716515344753862\n",
      "Epoch464 | train loss 0.5716240950673819\n",
      "Epoch465 | train loss 0.571595832761377\n",
      "Epoch466 | train loss 0.571567514501512\n",
      "Epoch467 | train loss 0.5715390359051525\n",
      "Epoch468 | train loss 0.5715121196210384\n",
      "Epoch469 | train loss 0.5714843370765448\n",
      "Epoch470 | train loss 0.5714573436044157\n",
      "Epoch471 | train loss 0.5714303601160645\n",
      "Epoch472 | train loss 0.5714036322943866\n",
      "Epoch473 | train loss 0.5713777818717063\n",
      "Epoch474 | train loss 0.5713434152491391\n",
      "Epoch475 | train loss 0.5713087511435151\n",
      "Epoch476 | train loss 0.5712728332541883\n",
      "Epoch477 | train loss 0.5712388379126787\n",
      "Epoch478 | train loss 0.5712071064673364\n",
      "Epoch479 | train loss 0.5711737013235688\n",
      "Epoch480 | train loss 0.5711405796930193\n",
      "Epoch481 | train loss 0.5711076892912388\n",
      "Epoch482 | train loss 0.5710741364955902\n",
      "Epoch483 | train loss 0.5710369077697396\n",
      "Epoch484 | train loss 0.5710014424473048\n",
      "Epoch485 | train loss 0.5709670111723244\n",
      "Epoch486 | train loss 0.5709329099953174\n",
      "Epoch487 | train loss 0.5709007338434458\n",
      "Epoch488 | train loss 0.57086820024997\n",
      "Epoch489 | train loss 0.5708353908360004\n",
      "Epoch490 | train loss 0.5708033752068877\n",
      "Epoch491 | train loss 0.5707717197202146\n",
      "Epoch492 | train loss 0.5707412690110505\n",
      "Epoch493 | train loss 0.5707068231701851\n",
      "Epoch494 | train loss 0.5706708636879921\n",
      "Epoch495 | train loss 0.5706346121802927\n",
      "Epoch496 | train loss 0.5706002268195153\n",
      "Epoch497 | train loss 0.5705654997006059\n",
      "Epoch498 | train loss 0.5705327503755688\n",
      "Epoch499 | train loss 0.5705001037940383\n",
      "Epoch500 | train loss 0.5704678117856383\n",
      "Epoch501 | train loss 0.5704319650307298\n",
      "Epoch502 | train loss 0.570395327527076\n",
      "Epoch503 | train loss 0.5703606518916786\n",
      "Epoch504 | train loss 0.5703265197016298\n",
      "Epoch505 | train loss 0.5702933583408594\n",
      "Epoch506 | train loss 0.5702575648389757\n",
      "Epoch507 | train loss 0.5702195695973933\n",
      "Epoch508 | train loss 0.5701822210103273\n",
      "Epoch509 | train loss 0.5701458968035876\n",
      "Epoch510 | train loss 0.5701107986643911\n",
      "Epoch511 | train loss 0.5700748384930193\n",
      "Epoch512 | train loss 0.5700381142646074\n",
      "Epoch513 | train loss 0.5700030924379825\n",
      "Epoch514 | train loss 0.569969901368022\n",
      "Epoch515 | train loss 0.569937324412167\n",
      "Epoch516 | train loss 0.5699061872251332\n",
      "Epoch517 | train loss 0.5698740491271019\n",
      "Epoch518 | train loss 0.5698428319208324\n",
      "Epoch519 | train loss 0.5698100479133427\n",
      "Epoch520 | train loss 0.5697792541980743\n",
      "Epoch521 | train loss 0.569748783390969\n",
      "Epoch522 | train loss 0.5697188084758819\n",
      "Epoch523 | train loss 0.5696888549625874\n",
      "Epoch524 | train loss 0.5696598725952208\n",
      "Epoch525 | train loss 0.569631087705493\n",
      "Epoch526 | train loss 0.5696019005030394\n",
      "Epoch527 | train loss 0.5695734318904578\n",
      "Epoch528 | train loss 0.5695442471653223\n",
      "Epoch529 | train loss 0.5695157309249044\n",
      "Epoch530 | train loss 0.5694879677891731\n",
      "Epoch531 | train loss 0.5694591431692243\n",
      "Epoch532 | train loss 0.5694313436187803\n",
      "Epoch533 | train loss 0.5694033909961581\n",
      "Epoch534 | train loss 0.5693760929629207\n",
      "Epoch535 | train loss 0.5693492595292627\n",
      "Epoch536 | train loss 0.5693233479559422\n",
      "Epoch537 | train loss 0.56929668745026\n",
      "Epoch538 | train loss 0.5692703855223954\n",
      "Epoch539 | train loss 0.569243922457099\n",
      "Epoch540 | train loss 0.569219013787806\n",
      "Epoch541 | train loss 0.5691939556412399\n",
      "Epoch542 | train loss 0.5691696314886212\n",
      "Epoch543 | train loss 0.5691453729569912\n",
      "Epoch544 | train loss 0.5691214434616267\n",
      "Epoch545 | train loss 0.5690980310738086\n",
      "Epoch546 | train loss 0.5690749211609364\n",
      "Epoch547 | train loss 0.569051916860044\n",
      "Epoch548 | train loss 0.5690293298847974\n",
      "Epoch549 | train loss 0.5690066530555487\n",
      "Epoch550 | train loss 0.5689826327748597\n",
      "Epoch551 | train loss 0.5689583999663591\n",
      "Epoch552 | train loss 0.5689350711740553\n",
      "Epoch553 | train loss 0.5689117898792029\n",
      "Epoch554 | train loss 0.5688890921324492\n",
      "Epoch555 | train loss 0.5688669612631202\n",
      "Epoch556 | train loss 0.5688458011113107\n",
      "Epoch557 | train loss 0.5688232151977718\n",
      "Epoch558 | train loss 0.56880165617913\n",
      "Epoch559 | train loss 0.5687800055742264\n",
      "Epoch560 | train loss 0.5687581603601575\n",
      "Epoch561 | train loss 0.5687368767336011\n",
      "Epoch562 | train loss 0.5687160457484424\n",
      "Epoch563 | train loss 0.568694864846766\n",
      "Epoch564 | train loss 0.5686730061843991\n",
      "Epoch565 | train loss 0.5686512442491949\n",
      "Epoch566 | train loss 0.568629773631692\n",
      "Epoch567 | train loss 0.5686085308529436\n",
      "Epoch568 | train loss 0.5685874785482884\n",
      "Epoch569 | train loss 0.5685662680305541\n",
      "Epoch570 | train loss 0.5685447491332889\n",
      "Epoch571 | train loss 0.5685237446427345\n",
      "Epoch572 | train loss 0.5685027640685439\n",
      "Epoch573 | train loss 0.5684807427041233\n",
      "Epoch574 | train loss 0.5684600107185542\n",
      "Epoch575 | train loss 0.568439393490553\n",
      "Epoch576 | train loss 0.5684185057878495\n",
      "Epoch577 | train loss 0.5683973716385663\n",
      "Epoch578 | train loss 0.5683774492703378\n",
      "Epoch579 | train loss 0.5683558978699148\n",
      "Epoch580 | train loss 0.5683357596583665\n",
      "Epoch581 | train loss 0.5683142160624266\n",
      "Epoch582 | train loss 0.5682939780130982\n",
      "Epoch583 | train loss 0.568272414188832\n",
      "Epoch584 | train loss 0.568251298200339\n",
      "Epoch585 | train loss 0.5682310925237835\n",
      "Epoch586 | train loss 0.5682101131044328\n",
      "Epoch587 | train loss 0.5681890237331391\n",
      "Epoch588 | train loss 0.5681673539802432\n",
      "Epoch589 | train loss 0.5681458957679569\n",
      "Epoch590 | train loss 0.5681247010454535\n",
      "Epoch591 | train loss 0.5681035760231317\n",
      "Epoch592 | train loss 0.5680832995660603\n",
      "Epoch593 | train loss 0.5680616790428757\n",
      "Epoch594 | train loss 0.568041084036231\n",
      "Epoch595 | train loss 0.5680207590945066\n",
      "Epoch596 | train loss 0.5679995534569025\n",
      "Epoch597 | train loss 0.5679800279811025\n",
      "Epoch598 | train loss 0.5679600298777223\n",
      "Epoch599 | train loss 0.5679390595294536\n",
      "Epoch600 | train loss 0.5679197647236287\n",
      "Epoch601 | train loss 0.5679011512733996\n",
      "Epoch602 | train loss 0.567882627043873\n",
      "Epoch603 | train loss 0.5678642443753779\n",
      "Epoch604 | train loss 0.5678451791591942\n",
      "Epoch605 | train loss 0.5678253077343106\n",
      "Epoch606 | train loss 0.5678046187385917\n",
      "Epoch607 | train loss 0.5677855187095702\n",
      "Epoch608 | train loss 0.5677668691053986\n",
      "Epoch609 | train loss 0.5677462422102689\n",
      "Epoch610 | train loss 0.5677269000001252\n",
      "Epoch611 | train loss 0.5677067872695625\n",
      "Epoch612 | train loss 0.5676870986819267\n",
      "Epoch613 | train loss 0.5676690597645938\n",
      "Epoch614 | train loss 0.567649274840951\n",
      "Epoch615 | train loss 0.567631345372647\n",
      "Epoch616 | train loss 0.567610575798899\n",
      "Epoch617 | train loss 0.5675918854773044\n",
      "Epoch618 | train loss 0.5675730510056018\n",
      "Epoch619 | train loss 0.5675540115125477\n",
      "Epoch620 | train loss 0.567535569369793\n",
      "Epoch621 | train loss 0.5675171981193126\n",
      "Epoch622 | train loss 0.5674982713162899\n",
      "Epoch623 | train loss 0.5674810919351876\n",
      "Epoch624 | train loss 0.5674622238986194\n",
      "Epoch625 | train loss 0.567444962989539\n",
      "Epoch626 | train loss 0.5674258352629841\n",
      "Epoch627 | train loss 0.5674088052101434\n",
      "Epoch628 | train loss 0.5673913121782244\n",
      "Epoch629 | train loss 0.5673728977330029\n",
      "Epoch630 | train loss 0.5673564104363322\n",
      "Epoch631 | train loss 0.5673383880592883\n",
      "Epoch632 | train loss 0.5673207347281277\n",
      "Epoch633 | train loss 0.5673029238171875\n",
      "Epoch634 | train loss 0.5672857373952865\n",
      "Epoch635 | train loss 0.5672681812383235\n",
      "Epoch636 | train loss 0.567248205728829\n",
      "Epoch637 | train loss 0.5672286203689874\n",
      "Epoch638 | train loss 0.5672100956551731\n",
      "Epoch639 | train loss 0.5671912533976138\n",
      "Epoch640 | train loss 0.5671718015149235\n",
      "Epoch641 | train loss 0.5671533781662583\n",
      "Epoch642 | train loss 0.5671360064670443\n",
      "Epoch643 | train loss 0.5671191754937172\n",
      "Epoch644 | train loss 0.5671021163836122\n",
      "Epoch645 | train loss 0.5670855088531971\n",
      "Epoch646 | train loss 0.5670682207681239\n",
      "Epoch647 | train loss 0.5670528501085937\n",
      "Epoch648 | train loss 0.5670368661731482\n",
      "Epoch649 | train loss 0.5670207180455327\n",
      "Epoch650 | train loss 0.5670048120990395\n",
      "Epoch651 | train loss 0.5669892983697354\n",
      "Epoch652 | train loss 0.5669737151451408\n",
      "Epoch653 | train loss 0.5669577617757022\n",
      "Epoch654 | train loss 0.5669420160539448\n",
      "Epoch655 | train loss 0.5669256304204464\n",
      "Epoch656 | train loss 0.5669101345725358\n",
      "Epoch657 | train loss 0.566894811168313\n",
      "Epoch658 | train loss 0.5668796718679369\n",
      "Epoch659 | train loss 0.5668639610335231\n",
      "Epoch660 | train loss 0.5668480203486979\n",
      "Epoch661 | train loss 0.5668320322223007\n",
      "Epoch662 | train loss 0.5668159027770162\n",
      "Epoch663 | train loss 0.5668001403659582\n",
      "Epoch664 | train loss 0.5667848458699882\n",
      "Epoch665 | train loss 0.5667698876745999\n",
      "Epoch666 | train loss 0.5667550870217383\n",
      "Epoch667 | train loss 0.5667408648692072\n",
      "Epoch668 | train loss 0.5667262476868927\n",
      "Epoch669 | train loss 0.5667123136483133\n",
      "Epoch670 | train loss 0.566697971969843\n",
      "Epoch671 | train loss 0.5666841263882816\n",
      "Epoch672 | train loss 0.5666699014790356\n",
      "Epoch673 | train loss 0.5666558983549476\n",
      "Epoch674 | train loss 0.5666414256207645\n",
      "Epoch675 | train loss 0.5666274394094944\n",
      "Epoch676 | train loss 0.5666121221147478\n",
      "Epoch677 | train loss 0.5665954833477735\n",
      "Epoch678 | train loss 0.5665790406614541\n",
      "Epoch679 | train loss 0.5665632262267173\n",
      "Epoch680 | train loss 0.5665471196174622\n",
      "Epoch681 | train loss 0.5665314310789108\n",
      "Epoch682 | train loss 0.5665157592669129\n",
      "Epoch683 | train loss 0.5665000620670617\n",
      "Epoch684 | train loss 0.5664833207987249\n",
      "Epoch685 | train loss 0.5664663474634289\n",
      "Epoch686 | train loss 0.5664497390389442\n",
      "Epoch687 | train loss 0.5664327761158348\n",
      "Epoch688 | train loss 0.5664161545224488\n",
      "Epoch689 | train loss 0.5663990609161556\n",
      "Epoch690 | train loss 0.5663823964446784\n",
      "Epoch691 | train loss 0.566365262940526\n",
      "Epoch692 | train loss 0.5663482961244881\n",
      "Epoch693 | train loss 0.5663310755603015\n",
      "Epoch694 | train loss 0.5663140789233148\n",
      "Epoch695 | train loss 0.5662970943003893\n",
      "Epoch696 | train loss 0.566280418895185\n",
      "Epoch697 | train loss 0.5662636193074286\n",
      "Epoch698 | train loss 0.5662470311671496\n",
      "Epoch699 | train loss 0.5662309725955129\n",
      "Epoch700 | train loss 0.5662147945165634\n",
      "Epoch701 | train loss 0.5661977491341531\n",
      "Epoch702 | train loss 0.5661798327043652\n",
      "Epoch703 | train loss 0.5661628350615502\n",
      "Epoch704 | train loss 0.5661457553133369\n",
      "Epoch705 | train loss 0.5661290439590811\n",
      "Epoch706 | train loss 0.5661119285225868\n",
      "Epoch707 | train loss 0.5660954866930843\n",
      "Epoch708 | train loss 0.5660787422955036\n",
      "Epoch709 | train loss 0.5660621747002006\n",
      "Epoch710 | train loss 0.5660458901152015\n",
      "Epoch711 | train loss 0.5660295220278203\n",
      "Epoch712 | train loss 0.5660131687298418\n",
      "Epoch713 | train loss 0.5659949432685971\n",
      "Epoch714 | train loss 0.5659765633381904\n",
      "Epoch715 | train loss 0.5659601598419249\n",
      "Epoch716 | train loss 0.5659439203329384\n",
      "Epoch717 | train loss 0.5659277203306555\n",
      "Epoch718 | train loss 0.5659124461375177\n",
      "Epoch719 | train loss 0.565896841045469\n",
      "Epoch720 | train loss 0.5658812740445137\n",
      "Epoch721 | train loss 0.5658663932606578\n",
      "Epoch722 | train loss 0.5658517975732684\n",
      "Epoch723 | train loss 0.5658377907425165\n",
      "Epoch724 | train loss 0.5658236267231405\n",
      "Epoch725 | train loss 0.5658102087117731\n",
      "Epoch726 | train loss 0.565795618277043\n",
      "Epoch727 | train loss 0.5657817034050823\n",
      "Epoch728 | train loss 0.5657665517553687\n",
      "Epoch729 | train loss 0.5657507497444749\n",
      "Epoch730 | train loss 0.5657350381463766\n",
      "Epoch731 | train loss 0.5657193007692695\n",
      "Epoch732 | train loss 0.5657038483396173\n",
      "Epoch733 | train loss 0.565688577145338\n",
      "Epoch734 | train loss 0.5656738295406103\n",
      "Epoch735 | train loss 0.5656589125841855\n",
      "Epoch736 | train loss 0.5656446410343051\n",
      "Epoch737 | train loss 0.5656301960162818\n",
      "Epoch738 | train loss 0.565616546664387\n",
      "Epoch739 | train loss 0.5656023492664098\n",
      "Epoch740 | train loss 0.5655884679965675\n",
      "Epoch741 | train loss 0.5655754799954593\n",
      "Epoch742 | train loss 0.5655621350742877\n",
      "Epoch743 | train loss 0.5655493015795946\n",
      "Epoch744 | train loss 0.5655361407250166\n",
      "Epoch745 | train loss 0.5655219359323382\n",
      "Epoch746 | train loss 0.5655090581811965\n",
      "Epoch747 | train loss 0.5654959341697395\n",
      "Epoch748 | train loss 0.565482890419662\n",
      "Epoch749 | train loss 0.5654705306515098\n",
      "Epoch750 | train loss 0.5654583718441427\n",
      "Epoch751 | train loss 0.5654463426396251\n",
      "Epoch752 | train loss 0.5654348460398615\n",
      "Epoch753 | train loss 0.5654234704189003\n",
      "Epoch754 | train loss 0.5654130236059427\n",
      "Epoch755 | train loss 0.565400956235826\n",
      "Epoch756 | train loss 0.5653899106755853\n",
      "Epoch757 | train loss 0.5653796267695725\n",
      "Epoch758 | train loss 0.5653681566007436\n",
      "Epoch759 | train loss 0.56535700365901\n",
      "Epoch760 | train loss 0.5653455623798073\n",
      "Epoch761 | train loss 0.5653345195949078\n",
      "Epoch762 | train loss 0.5653236173279583\n",
      "Epoch763 | train loss 0.5653133553825319\n",
      "Epoch764 | train loss 0.5653016470558941\n",
      "Epoch765 | train loss 0.5652913807891309\n",
      "Epoch766 | train loss 0.5652796258591115\n",
      "Epoch767 | train loss 0.5652686003409326\n",
      "Epoch768 | train loss 0.5652569433674216\n",
      "Epoch769 | train loss 0.5652456760779023\n",
      "Epoch770 | train loss 0.5652333026751876\n",
      "Epoch771 | train loss 0.5652220824733376\n",
      "Epoch772 | train loss 0.5652111260406673\n",
      "Epoch773 | train loss 0.5651995194144547\n",
      "Epoch774 | train loss 0.5651880947127939\n",
      "Epoch775 | train loss 0.5651762140169739\n",
      "Epoch776 | train loss 0.5651656605303288\n",
      "Epoch777 | train loss 0.5651544691622257\n",
      "Epoch778 | train loss 0.5651429231837392\n",
      "Epoch779 | train loss 0.5651328049786389\n",
      "Epoch780 | train loss 0.5651212359964848\n",
      "Epoch781 | train loss 0.5651107777655124\n",
      "Epoch782 | train loss 0.5650991185382008\n",
      "Epoch783 | train loss 0.5650888617523014\n",
      "Epoch784 | train loss 0.5650770154781639\n",
      "Epoch785 | train loss 0.5650660338625312\n",
      "Epoch786 | train loss 0.5650564668141306\n",
      "Epoch787 | train loss 0.565045015141368\n",
      "Epoch788 | train loss 0.5650329072587192\n",
      "Epoch789 | train loss 0.5650220430083572\n",
      "Epoch790 | train loss 0.565010627862066\n",
      "Epoch791 | train loss 0.5649994596466422\n",
      "Epoch792 | train loss 0.5649890363961458\n",
      "Epoch793 | train loss 0.5649778937548399\n",
      "Epoch794 | train loss 0.5649651510082185\n",
      "Epoch795 | train loss 0.5649511487782002\n",
      "Epoch796 | train loss 0.5649372605606914\n",
      "Epoch797 | train loss 0.5649241440370679\n",
      "Epoch798 | train loss 0.5649114112742245\n",
      "Epoch799 | train loss 0.5648990014381706\n",
      "Epoch800 | train loss 0.5648865030892193\n",
      "Epoch801 | train loss 0.5648745012283325\n",
      "Epoch802 | train loss 0.5648621120490134\n",
      "Epoch803 | train loss 0.5648495800234378\n",
      "Epoch804 | train loss 0.5648366450704634\n",
      "Epoch805 | train loss 0.5648239621147514\n",
      "Epoch806 | train loss 0.5648098735883832\n",
      "Epoch807 | train loss 0.5647955128550529\n",
      "Epoch808 | train loss 0.5647809036448598\n",
      "Epoch809 | train loss 0.5647663335315883\n",
      "Epoch810 | train loss 0.5647522851079703\n",
      "Epoch811 | train loss 0.5647378903999924\n",
      "Epoch812 | train loss 0.5647227639332414\n",
      "Epoch813 | train loss 0.5647070579044521\n",
      "Epoch814 | train loss 0.5646909837797284\n",
      "Epoch815 | train loss 0.5646744332835079\n",
      "Epoch816 | train loss 0.5646590672619641\n",
      "Epoch817 | train loss 0.5646438966877758\n",
      "Epoch818 | train loss 0.5646278921514749\n",
      "Epoch819 | train loss 0.5646121652051806\n",
      "Epoch820 | train loss 0.5645969766750931\n",
      "Epoch821 | train loss 0.5645816021971405\n",
      "Epoch822 | train loss 0.5645659535005688\n",
      "Epoch823 | train loss 0.5645515408739448\n",
      "Epoch824 | train loss 0.5645372046716511\n",
      "Epoch825 | train loss 0.5645221937075258\n",
      "Epoch826 | train loss 0.5645070311799646\n",
      "Epoch827 | train loss 0.5644937492161989\n",
      "Epoch828 | train loss 0.564479440562427\n",
      "Epoch829 | train loss 0.5644645354151726\n",
      "Epoch830 | train loss 0.5644497588649392\n",
      "Epoch831 | train loss 0.5644358733855188\n",
      "Epoch832 | train loss 0.5644208595901727\n",
      "Epoch833 | train loss 0.5644049625471235\n",
      "Epoch834 | train loss 0.564389404244721\n",
      "Epoch835 | train loss 0.564374350644648\n",
      "Epoch836 | train loss 0.564359039850533\n",
      "Epoch837 | train loss 0.5643439713679254\n",
      "Epoch838 | train loss 0.5643295313045382\n",
      "Epoch839 | train loss 0.5643146797269583\n",
      "Epoch840 | train loss 0.5642995774559677\n",
      "Epoch841 | train loss 0.5642850669100881\n",
      "Epoch842 | train loss 0.5642707230523228\n",
      "Epoch843 | train loss 0.5642565581761301\n",
      "Epoch844 | train loss 0.5642423240840435\n",
      "Epoch845 | train loss 0.5642282113060355\n",
      "Epoch846 | train loss 0.5642138887569308\n",
      "Epoch847 | train loss 0.5641994612105191\n",
      "Epoch848 | train loss 0.5641849094629288\n",
      "Epoch849 | train loss 0.5641685731336474\n",
      "Epoch850 | train loss 0.5641512808017433\n",
      "Epoch851 | train loss 0.5641345154680312\n",
      "Epoch852 | train loss 0.5641174549981952\n",
      "Epoch853 | train loss 0.5641008185222744\n",
      "Epoch854 | train loss 0.5640836715698242\n",
      "Epoch855 | train loss 0.5640655255317688\n",
      "Epoch856 | train loss 0.564047633241862\n",
      "Epoch857 | train loss 0.5640304550155997\n",
      "Epoch858 | train loss 0.5640139363147318\n",
      "Epoch859 | train loss 0.5639957503974438\n",
      "Epoch860 | train loss 0.5639778520911932\n",
      "Epoch861 | train loss 0.5639596188813448\n",
      "Epoch862 | train loss 0.5639419840089976\n",
      "Epoch863 | train loss 0.5639241340570151\n",
      "Epoch864 | train loss 0.5639073755964636\n",
      "Epoch865 | train loss 0.5638906933926046\n",
      "Epoch866 | train loss 0.5638735611177981\n",
      "Epoch867 | train loss 0.5638565681315959\n",
      "Epoch868 | train loss 0.5638398224301636\n",
      "Epoch869 | train loss 0.5638222240284085\n",
      "Epoch870 | train loss 0.5638045994006098\n",
      "Epoch871 | train loss 0.5637865898385644\n",
      "Epoch872 | train loss 0.563768877722323\n",
      "Epoch873 | train loss 0.5637511529773473\n",
      "Epoch874 | train loss 0.5637345742806792\n",
      "Epoch875 | train loss 0.5637166509777307\n",
      "Epoch876 | train loss 0.5636971902474761\n",
      "Epoch877 | train loss 0.5636795211955905\n",
      "Epoch878 | train loss 0.5636624876782298\n",
      "Epoch879 | train loss 0.5636453550681472\n",
      "Epoch880 | train loss 0.5636287257634103\n",
      "Epoch881 | train loss 0.5636123955622315\n",
      "Epoch882 | train loss 0.5635962157696486\n",
      "Epoch883 | train loss 0.5635802359692752\n",
      "Epoch884 | train loss 0.5635646735318005\n",
      "Epoch885 | train loss 0.5635487951338292\n",
      "Epoch886 | train loss 0.5635338208079338\n",
      "Epoch887 | train loss 0.5635179313458503\n",
      "Epoch888 | train loss 0.5635028496384621\n",
      "Epoch889 | train loss 0.5634880305826664\n",
      "Epoch890 | train loss 0.563472905382514\n",
      "Epoch891 | train loss 0.5634587352909147\n",
      "Epoch892 | train loss 0.5634438627026975\n",
      "Epoch893 | train loss 0.5634292797371745\n",
      "Epoch894 | train loss 0.5634138110093773\n",
      "Epoch895 | train loss 0.5633983244933188\n",
      "Epoch896 | train loss 0.5633830870129168\n",
      "Epoch897 | train loss 0.5633669001795352\n",
      "Epoch898 | train loss 0.5633523049764335\n",
      "Epoch899 | train loss 0.5633369867317378\n",
      "Epoch900 | train loss 0.5633201880380512\n",
      "Epoch901 | train loss 0.563304986897856\n",
      "Epoch902 | train loss 0.5632886910997331\n",
      "Epoch903 | train loss 0.563273055087775\n",
      "Epoch904 | train loss 0.5632573148421943\n",
      "Epoch905 | train loss 0.5632418614812196\n",
      "Epoch906 | train loss 0.5632269787043334\n",
      "Epoch907 | train loss 0.5632114200852811\n",
      "Epoch908 | train loss 0.56319639980793\n",
      "Epoch909 | train loss 0.5631811363995075\n",
      "Epoch910 | train loss 0.56316584745422\n",
      "Epoch911 | train loss 0.5631503449939191\n",
      "Epoch912 | train loss 0.5631355470791459\n",
      "Epoch913 | train loss 0.5631200868822634\n",
      "Epoch914 | train loss 0.5631054966524244\n",
      "Epoch915 | train loss 0.5630901875160634\n",
      "Epoch916 | train loss 0.5630737964995205\n",
      "Epoch917 | train loss 0.5630582957156003\n",
      "Epoch918 | train loss 0.5630436275154352\n",
      "Epoch919 | train loss 0.5630283121019601\n",
      "Epoch920 | train loss 0.5630125027894973\n",
      "Epoch921 | train loss 0.5629968919232488\n",
      "Epoch922 | train loss 0.562981774173677\n",
      "Epoch923 | train loss 0.5629668492823839\n",
      "Epoch924 | train loss 0.5629518761485816\n",
      "Epoch925 | train loss 0.5629364778846502\n",
      "Epoch926 | train loss 0.5629224069230259\n",
      "Epoch927 | train loss 0.5629072562977672\n",
      "Epoch928 | train loss 0.5628934595175088\n",
      "Epoch929 | train loss 0.5628788659349084\n",
      "Epoch930 | train loss 0.5628637187369168\n",
      "Epoch931 | train loss 0.5628489588014781\n",
      "Epoch932 | train loss 0.5628336637280882\n",
      "Epoch933 | train loss 0.5628195193782449\n",
      "Epoch934 | train loss 0.5628039972856641\n",
      "Epoch935 | train loss 0.5627898857928813\n",
      "Epoch936 | train loss 0.562773895598948\n",
      "Epoch937 | train loss 0.562759115844965\n",
      "Epoch938 | train loss 0.5627429649978876\n",
      "Epoch939 | train loss 0.5627254770696163\n",
      "Epoch940 | train loss 0.5627102695219218\n",
      "Epoch941 | train loss 0.5626942634396255\n",
      "Epoch942 | train loss 0.5626791548170149\n",
      "Epoch943 | train loss 0.5626639525778592\n",
      "Epoch944 | train loss 0.562648743763566\n",
      "Epoch945 | train loss 0.5626334882341325\n",
      "Epoch946 | train loss 0.5626177824102342\n",
      "Epoch947 | train loss 0.5626036923378706\n",
      "Epoch948 | train loss 0.5625876350142062\n",
      "Epoch949 | train loss 0.5625705441460014\n",
      "Epoch950 | train loss 0.562554732337594\n",
      "Epoch951 | train loss 0.5625389946438372\n",
      "Epoch952 | train loss 0.5625240208394825\n",
      "Epoch953 | train loss 0.562508876118809\n",
      "Epoch954 | train loss 0.5624939952418209\n",
      "Epoch955 | train loss 0.5624790790118277\n",
      "Epoch956 | train loss 0.562464230954647\n",
      "Epoch957 | train loss 0.5624496062844991\n",
      "Epoch958 | train loss 0.5624348699301481\n",
      "Epoch959 | train loss 0.562420671377331\n",
      "Epoch960 | train loss 0.5624064366146923\n",
      "Epoch961 | train loss 0.5623927704244852\n",
      "Epoch962 | train loss 0.5623781223222614\n",
      "Epoch963 | train loss 0.5623637211509049\n",
      "Epoch964 | train loss 0.5623493778891862\n",
      "Epoch965 | train loss 0.5623336181417108\n",
      "Epoch966 | train loss 0.5623188900761307\n",
      "Epoch967 | train loss 0.5623042358830571\n",
      "Epoch968 | train loss 0.5622880674339831\n",
      "Epoch969 | train loss 0.5622721584141255\n",
      "Epoch970 | train loss 0.5622557015717029\n",
      "Epoch971 | train loss 0.5622412532754243\n",
      "Epoch972 | train loss 0.5622266430966556\n",
      "Epoch973 | train loss 0.5622117009572685\n",
      "Epoch974 | train loss 0.5621972891315817\n",
      "Epoch975 | train loss 0.5621815127320587\n",
      "Epoch976 | train loss 0.56216662786901\n",
      "Epoch977 | train loss 0.5621515679545701\n",
      "Epoch978 | train loss 0.5621364551596344\n",
      "Epoch979 | train loss 0.5621214211173355\n",
      "Epoch980 | train loss 0.5621064777858555\n",
      "Epoch981 | train loss 0.5620912744477391\n",
      "Epoch982 | train loss 0.5620758388750255\n",
      "Epoch983 | train loss 0.562060780338943\n",
      "Epoch984 | train loss 0.5620459767058492\n",
      "Epoch985 | train loss 0.562030336856842\n",
      "Epoch986 | train loss 0.5620140294544399\n",
      "Epoch987 | train loss 0.5619979788549244\n",
      "Epoch988 | train loss 0.5619827235676348\n",
      "Epoch989 | train loss 0.561967845838517\n",
      "Epoch990 | train loss 0.561953688506037\n",
      "Epoch991 | train loss 0.5619376413151622\n",
      "Epoch992 | train loss 0.5619228671491147\n",
      "Epoch993 | train loss 0.5619070730917156\n",
      "Epoch994 | train loss 0.5618900843895972\n",
      "Epoch995 | train loss 0.5618735935539008\n",
      "Epoch996 | train loss 0.5618576550297439\n",
      "Epoch997 | train loss 0.5618411032482982\n",
      "Epoch998 | train loss 0.5618236612714828\n",
      "Epoch999 | train loss 0.5618069767020643\n",
      "Epoch1000 | train loss 0.5617914901301265\n",
      "Epoch1001 | train loss 0.5617760643735528\n",
      "Epoch1002 | train loss 0.5617591525055468\n",
      "Epoch1003 | train loss 0.5617438102699817\n",
      "Epoch1004 | train loss 0.5617282697558403\n",
      "Epoch1005 | train loss 0.5617138777859509\n",
      "Epoch1006 | train loss 0.5616999380849301\n",
      "Epoch1007 | train loss 0.5616841023601592\n",
      "Epoch1008 | train loss 0.5616684583574534\n",
      "Epoch1009 | train loss 0.561650881562382\n",
      "Epoch1010 | train loss 0.5616337786614894\n",
      "Epoch1011 | train loss 0.5616163132712245\n",
      "Epoch1012 | train loss 0.5615989607200027\n",
      "Epoch1013 | train loss 0.5615802993625403\n",
      "Epoch1014 | train loss 0.561562675088644\n",
      "Epoch1015 | train loss 0.561545068025589\n",
      "Epoch1016 | train loss 0.5615270776487887\n",
      "Epoch1017 | train loss 0.5615088118799031\n",
      "Epoch1018 | train loss 0.5614914626069367\n",
      "Epoch1019 | train loss 0.5614744113013148\n",
      "Epoch1020 | train loss 0.5614568512141704\n",
      "Epoch1021 | train loss 0.5614408722147346\n",
      "Epoch1022 | train loss 0.5614244964905083\n",
      "Epoch1023 | train loss 0.5614082611352206\n",
      "Epoch1024 | train loss 0.5613926290161908\n",
      "Epoch1025 | train loss 0.56137576950714\n",
      "Epoch1026 | train loss 0.5613596037961542\n",
      "Epoch1027 | train loss 0.561343969386071\n",
      "Epoch1028 | train loss 0.5613280705735088\n",
      "Epoch1029 | train loss 0.5613122313283384\n",
      "Epoch1030 | train loss 0.5612971227988601\n",
      "Epoch1031 | train loss 0.5612816474586725\n",
      "Epoch1032 | train loss 0.5612641416490078\n",
      "Epoch1033 | train loss 0.561246748380363\n",
      "Epoch1034 | train loss 0.5612299385294318\n",
      "Epoch1035 | train loss 0.561213717572391\n",
      "Epoch1036 | train loss 0.5611976331286133\n",
      "Epoch1037 | train loss 0.5611782522313297\n",
      "Epoch1038 | train loss 0.5611602954566479\n",
      "Epoch1039 | train loss 0.5611431431025267\n",
      "Epoch1040 | train loss 0.5611263014376163\n",
      "Epoch1041 | train loss 0.5611096252314747\n",
      "Epoch1042 | train loss 0.561093264464289\n",
      "Epoch1043 | train loss 0.5610775349847973\n",
      "Epoch1044 | train loss 0.5610604915209114\n",
      "Epoch1045 | train loss 0.561043677739799\n",
      "Epoch1046 | train loss 0.5610262886062265\n",
      "Epoch1047 | train loss 0.5610086233727634\n",
      "Epoch1048 | train loss 0.5609911932982504\n",
      "Epoch1049 | train loss 0.5609735135734081\n",
      "Epoch1050 | train loss 0.5609561844915152\n",
      "Epoch1051 | train loss 0.560939592923969\n",
      "Epoch1052 | train loss 0.5609232138283551\n",
      "Epoch1053 | train loss 0.5609062347002327\n",
      "Epoch1054 | train loss 0.560891073551029\n",
      "Epoch1055 | train loss 0.5608758360333741\n",
      "Epoch1056 | train loss 0.560859868247062\n",
      "Epoch1057 | train loss 0.5608442572690546\n",
      "Epoch1058 | train loss 0.5608288613334298\n",
      "Epoch1059 | train loss 0.560813843794167\n",
      "Epoch1060 | train loss 0.560798405148089\n",
      "Epoch1061 | train loss 0.5607833876088262\n",
      "Epoch1062 | train loss 0.5607681396603584\n",
      "Epoch1063 | train loss 0.560752871632576\n",
      "Epoch1064 | train loss 0.560737377256155\n",
      "Epoch1065 | train loss 0.5607217162288726\n",
      "Epoch1066 | train loss 0.5607070902734995\n",
      "Epoch1067 | train loss 0.5606912826001644\n",
      "Epoch1068 | train loss 0.5606757712736726\n",
      "Epoch1069 | train loss 0.5606602936983108\n",
      "Epoch1070 | train loss 0.5606451180949807\n",
      "Epoch1071 | train loss 0.560629897788167\n",
      "Epoch1072 | train loss 0.5606149741448462\n",
      "Epoch1073 | train loss 0.5606000592559576\n",
      "Epoch1074 | train loss 0.5605854443646967\n",
      "Epoch1075 | train loss 0.56057079968974\n",
      "Epoch1076 | train loss 0.5605560786277056\n",
      "Epoch1077 | train loss 0.5605408379249275\n",
      "Epoch1078 | train loss 0.5605255120620132\n",
      "Epoch1079 | train loss 0.5605107717774809\n",
      "Epoch1080 | train loss 0.56049759991467\n",
      "Epoch1081 | train loss 0.56048145448789\n",
      "Epoch1082 | train loss 0.5604682461544871\n",
      "Epoch1083 | train loss 0.5604519474878907\n",
      "Epoch1084 | train loss 0.5604396619088948\n",
      "Epoch1085 | train loss 0.5604232705943286\n",
      "Epoch1086 | train loss 0.560411455258727\n",
      "Epoch1087 | train loss 0.560396783836186\n",
      "Epoch1088 | train loss 0.5603816973790526\n",
      "Epoch1089 | train loss 0.5603684024699033\n",
      "Epoch1090 | train loss 0.5603545632958412\n",
      "Epoch1091 | train loss 0.5603413099981844\n",
      "Epoch1092 | train loss 0.5603283587284387\n",
      "Epoch1093 | train loss 0.5603137023933232\n",
      "Epoch1094 | train loss 0.5603006844036281\n",
      "Epoch1095 | train loss 0.5602877134270966\n",
      "Epoch1096 | train loss 0.5602745946124196\n",
      "Epoch1097 | train loss 0.5602619221061468\n",
      "Epoch1098 | train loss 0.5602487426996231\n",
      "Epoch1099 | train loss 0.5602358259260655\n",
      "Epoch1100 | train loss 0.560222547147423\n",
      "Epoch1101 | train loss 0.5602096600271761\n",
      "Epoch1102 | train loss 0.5601967806741596\n",
      "Epoch1103 | train loss 0.5601840197481215\n",
      "Epoch1104 | train loss 0.5601709604449571\n",
      "Epoch1105 | train loss 0.5601580656133592\n",
      "Epoch1106 | train loss 0.560145357362926\n",
      "Epoch1107 | train loss 0.5601311549730599\n",
      "Epoch1108 | train loss 0.5601180575042963\n",
      "Epoch1109 | train loss 0.560104394890368\n",
      "Epoch1110 | train loss 0.5600913238339126\n",
      "Epoch1111 | train loss 0.5600768820382654\n",
      "Epoch1112 | train loss 0.5600618283636868\n",
      "Epoch1113 | train loss 0.5600464016012847\n",
      "Epoch1114 | train loss 0.5600312953442335\n",
      "Epoch1115 | train loss 0.5600168396905064\n",
      "Epoch1116 | train loss 0.5600013016536832\n",
      "Epoch1117 | train loss 0.5599856144748628\n",
      "Epoch1118 | train loss 0.5599704958871007\n",
      "Epoch1119 | train loss 0.5599568093381823\n",
      "Epoch1120 | train loss 0.5599421099759638\n",
      "Epoch1121 | train loss 0.5599286243692041\n",
      "Epoch1122 | train loss 0.5599143642373383\n",
      "Epoch1123 | train loss 0.5599010015465319\n",
      "Epoch1124 | train loss 0.5598882350325585\n",
      "Epoch1125 | train loss 0.5598748340271413\n",
      "Epoch1126 | train loss 0.5598616068065166\n",
      "Epoch1127 | train loss 0.5598477604053914\n",
      "Epoch1128 | train loss 0.559834786914289\n",
      "Epoch1129 | train loss 0.5598221733793616\n",
      "Epoch1130 | train loss 0.5598094677552581\n",
      "Epoch1131 | train loss 0.5597964723594486\n",
      "Epoch1132 | train loss 0.5597847020626068\n",
      "Epoch1133 | train loss 0.5597705691307783\n",
      "Epoch1134 | train loss 0.5597589354030788\n",
      "Epoch1135 | train loss 0.5597472559101879\n",
      "Epoch1136 | train loss 0.5597353019751609\n",
      "Epoch1137 | train loss 0.5597226451523603\n",
      "Epoch1138 | train loss 0.5597103986516595\n",
      "Epoch1139 | train loss 0.5596990527771414\n",
      "Epoch1140 | train loss 0.5596865142323076\n",
      "Epoch1141 | train loss 0.5596756831556559\n",
      "Epoch1142 | train loss 0.559663610663265\n",
      "Epoch1143 | train loss 0.5596529037877918\n",
      "Epoch1144 | train loss 0.5596407346613705\n",
      "Epoch1145 | train loss 0.5596296126022935\n",
      "Epoch1146 | train loss 0.5596168829128146\n",
      "Epoch1147 | train loss 0.5596062202192843\n",
      "Epoch1148 | train loss 0.5595933671109379\n",
      "Epoch1149 | train loss 0.5595819235406816\n",
      "Epoch1150 | train loss 0.5595702922530472\n",
      "Epoch1151 | train loss 0.5595581424795091\n",
      "Epoch1152 | train loss 0.559545884989202\n",
      "Epoch1153 | train loss 0.559534502774477\n",
      "Epoch1154 | train loss 0.559522692002356\n",
      "Epoch1155 | train loss 0.5595103100314737\n",
      "Epoch1156 | train loss 0.5594970115460456\n",
      "Epoch1157 | train loss 0.5594837689585984\n",
      "Epoch1158 | train loss 0.5594723531417549\n",
      "Epoch1159 | train loss 0.5594602281413973\n",
      "Epoch1160 | train loss 0.559449611492455\n",
      "Epoch1161 | train loss 0.5594366238079965\n",
      "Epoch1162 | train loss 0.5594254914484919\n",
      "Epoch1163 | train loss 0.5594136268086731\n",
      "Epoch1164 | train loss 0.5594022749364376\n",
      "Epoch1165 | train loss 0.5593917015194892\n",
      "Epoch1166 | train loss 0.5593802924081683\n",
      "Epoch1167 | train loss 0.5593687443062663\n",
      "Epoch1168 | train loss 0.5593588661588729\n",
      "Epoch1169 | train loss 0.55934745201841\n",
      "Epoch1170 | train loss 0.5593371760286391\n",
      "Epoch1171 | train loss 0.5593261609971524\n",
      "Epoch1172 | train loss 0.5593154600448906\n",
      "Epoch1173 | train loss 0.5593043794855476\n",
      "Epoch1174 | train loss 0.5592936555482447\n",
      "Epoch1175 | train loss 0.5592831590585411\n",
      "Epoch1176 | train loss 0.5592727727629244\n",
      "Epoch1177 | train loss 0.5592617504671216\n",
      "Epoch1178 | train loss 0.559251283686608\n",
      "Epoch1179 | train loss 0.5592402934655547\n",
      "Epoch1180 | train loss 0.5592305682040751\n",
      "Epoch1181 | train loss 0.5592203175462782\n",
      "Epoch1182 | train loss 0.5592104094289243\n",
      "Epoch1183 | train loss 0.5592001063376665\n",
      "Epoch1184 | train loss 0.5591905073821545\n",
      "Epoch1185 | train loss 0.5591799149475992\n",
      "Epoch1186 | train loss 0.5591694252192974\n",
      "Epoch1187 | train loss 0.5591598580032587\n",
      "Epoch1188 | train loss 0.5591504610329866\n",
      "Epoch1189 | train loss 0.559140535518527\n",
      "Epoch1190 | train loss 0.5591309880279005\n",
      "Epoch1191 | train loss 0.5591211853176355\n",
      "Epoch1192 | train loss 0.5591122423857451\n",
      "Epoch1193 | train loss 0.559101232457906\n",
      "Epoch1194 | train loss 0.5590917996503413\n",
      "Epoch1195 | train loss 0.5590828581340611\n",
      "Epoch1196 | train loss 0.5590739998407662\n",
      "Epoch1197 | train loss 0.5590642331913114\n",
      "Epoch1198 | train loss 0.5590551088377833\n",
      "Epoch1199 | train loss 0.5590458916313946\n",
      "Epoch1200 | train loss 0.5590362828969956\n",
      "Epoch1201 | train loss 0.5590269650146366\n",
      "Epoch1202 | train loss 0.5590179129503667\n",
      "Epoch1203 | train loss 0.5590084097161889\n",
      "Epoch1204 | train loss 0.5589995027706027\n",
      "Epoch1205 | train loss 0.5589902232214808\n",
      "Epoch1206 | train loss 0.5589809266477823\n",
      "Epoch1207 | train loss 0.5589717761054636\n",
      "Epoch1208 | train loss 0.5589627160318196\n",
      "Epoch1209 | train loss 0.5589540798962116\n",
      "Epoch1210 | train loss 0.5589445186033845\n",
      "Epoch1211 | train loss 0.5589358036592603\n",
      "Epoch1212 | train loss 0.5589274680428207\n",
      "Epoch1213 | train loss 0.5589183875545859\n",
      "Epoch1214 | train loss 0.5589101328700781\n",
      "Epoch1215 | train loss 0.5589011208154261\n",
      "Epoch1216 | train loss 0.558891738820821\n",
      "Epoch1217 | train loss 0.5588836912624537\n",
      "Epoch1218 | train loss 0.5588747201301157\n",
      "Epoch1219 | train loss 0.5588664421439171\n",
      "Epoch1220 | train loss 0.5588571637868881\n",
      "Epoch1221 | train loss 0.5588483807072043\n",
      "Epoch1222 | train loss 0.5588391429185867\n",
      "Epoch1223 | train loss 0.5588302972353995\n",
      "Epoch1224 | train loss 0.5588212088681758\n",
      "Epoch1225 | train loss 0.5588128064014017\n",
      "Epoch1226 | train loss 0.5588036575354636\n",
      "Epoch1227 | train loss 0.5587950965762138\n",
      "Epoch1228 | train loss 0.5587860201112926\n",
      "Epoch1229 | train loss 0.5587775021046401\n",
      "Epoch1230 | train loss 0.558768612369895\n",
      "Epoch1231 | train loss 0.5587583737447858\n",
      "Epoch1232 | train loss 0.5587497800216079\n",
      "Epoch1233 | train loss 0.5587409507855773\n",
      "Epoch1234 | train loss 0.5587313251942396\n",
      "Epoch1235 | train loss 0.5587232603132725\n",
      "Epoch1236 | train loss 0.5587143607065082\n",
      "Epoch1237 | train loss 0.5587060524895787\n",
      "Epoch1238 | train loss 0.5586966649256646\n",
      "Epoch1239 | train loss 0.558688221052289\n",
      "Epoch1240 | train loss 0.5586787244305015\n",
      "Epoch1241 | train loss 0.5586705245822668\n",
      "Epoch1242 | train loss 0.5586611262150109\n",
      "Epoch1243 | train loss 0.5586527931690216\n",
      "Epoch1244 | train loss 0.5586441856995225\n",
      "Epoch1245 | train loss 0.5586348487809301\n",
      "Epoch1246 | train loss 0.5586265620589256\n",
      "Epoch1247 | train loss 0.5586178336665034\n",
      "Epoch1248 | train loss 0.5586092324368656\n",
      "Epoch1249 | train loss 0.5586009489186108\n",
      "Epoch1250 | train loss 0.5585914634726942\n",
      "Epoch1251 | train loss 0.5585828885994851\n",
      "Epoch1252 | train loss 0.558573383167386\n",
      "Epoch1253 | train loss 0.5585649839602411\n",
      "Epoch1254 | train loss 0.5585563832893967\n",
      "Epoch1255 | train loss 0.5585470836237073\n",
      "Epoch1256 | train loss 0.5585384996980429\n",
      "Epoch1257 | train loss 0.5585296839661896\n",
      "Epoch1258 | train loss 0.5585207035019993\n",
      "Epoch1259 | train loss 0.558511853609234\n",
      "Epoch1260 | train loss 0.5585029748827219\n",
      "Epoch1261 | train loss 0.5584936456382275\n",
      "Epoch1262 | train loss 0.5584848534874618\n",
      "Epoch1263 | train loss 0.558476935569197\n",
      "Epoch1264 | train loss 0.5584675890021026\n",
      "Epoch1265 | train loss 0.5584586808085441\n",
      "Epoch1266 | train loss 0.5584492354094982\n",
      "Epoch1267 | train loss 0.5584416899830102\n",
      "Epoch1268 | train loss 0.5584317638538778\n",
      "Epoch1269 | train loss 0.5584235189110041\n",
      "Epoch1270 | train loss 0.5584145817160606\n",
      "Epoch1271 | train loss 0.5584060017950833\n",
      "Epoch1272 | train loss 0.5583965441770852\n",
      "Epoch1273 | train loss 0.5583884471096099\n",
      "Epoch1274 | train loss 0.5583791112527251\n",
      "Epoch1275 | train loss 0.5583695023134351\n",
      "Epoch1276 | train loss 0.5583599859662354\n",
      "Epoch1277 | train loss 0.558350774217397\n",
      "Epoch1278 | train loss 0.5583413623645902\n",
      "Epoch1279 | train loss 0.5583326966874301\n",
      "Epoch1280 | train loss 0.55832426244393\n",
      "Epoch1281 | train loss 0.5583157847821713\n",
      "Epoch1282 | train loss 0.5583072769641876\n",
      "Epoch1283 | train loss 0.5582987037859857\n",
      "Epoch1284 | train loss 0.5582930349931121\n",
      "Epoch1285 | train loss 0.5582855715230107\n",
      "Epoch1286 | train loss 0.558276544958353\n",
      "Epoch1287 | train loss 0.5582681008242071\n",
      "Epoch1288 | train loss 0.5582599182240665\n",
      "Epoch1289 | train loss 0.5582525528408587\n",
      "Epoch1290 | train loss 0.5582441074587404\n",
      "Epoch1291 | train loss 0.5582353308424354\n",
      "Epoch1292 | train loss 0.5582273102179169\n",
      "Epoch1293 | train loss 0.5582188613899052\n",
      "Epoch1294 | train loss 0.5582108151167631\n",
      "Epoch1295 | train loss 0.5582023250870407\n",
      "Epoch1296 | train loss 0.5581945169344544\n",
      "Epoch1297 | train loss 0.5581860891729593\n",
      "Epoch1298 | train loss 0.5581777260825038\n",
      "Epoch1299 | train loss 0.5581695427373051\n",
      "Epoch1300 | train loss 0.558160518296063\n",
      "Epoch1301 | train loss 0.5581521488912403\n",
      "Epoch1302 | train loss 0.5581438382901251\n",
      "Epoch1303 | train loss 0.5581359129399062\n",
      "Epoch1304 | train loss 0.5581279090419412\n",
      "Epoch1305 | train loss 0.5581196031905711\n",
      "Epoch1306 | train loss 0.5581108818948269\n",
      "Epoch1307 | train loss 0.5581026852503419\n",
      "Epoch1308 | train loss 0.558093075864017\n",
      "Epoch1309 | train loss 0.5580854161269962\n",
      "Epoch1310 | train loss 0.5580771895870567\n",
      "Epoch1311 | train loss 0.5580682647041977\n",
      "Epoch1312 | train loss 0.5580609461292625\n",
      "Epoch1313 | train loss 0.55805249504745\n",
      "Epoch1314 | train loss 0.5580436312407255\n",
      "Epoch1315 | train loss 0.5580360300466418\n",
      "Epoch1316 | train loss 0.5580274096317589\n",
      "Epoch1317 | train loss 0.5580186510458589\n",
      "Epoch1318 | train loss 0.5580109862424433\n",
      "Epoch1319 | train loss 0.5580031941831112\n",
      "Epoch1320 | train loss 0.5579946911893785\n",
      "Epoch1321 | train loss 0.5579865410923958\n",
      "Epoch1322 | train loss 0.5579787439294159\n",
      "Epoch1323 | train loss 0.5579696176573634\n",
      "Epoch1324 | train loss 0.5579620430991054\n",
      "Epoch1325 | train loss 0.557954226359725\n",
      "Epoch1326 | train loss 0.5579448138549924\n",
      "Epoch1327 | train loss 0.5579366862773896\n",
      "Epoch1328 | train loss 0.5579286959767341\n",
      "Epoch1329 | train loss 0.5579207022860646\n",
      "Epoch1330 | train loss 0.5579124331846833\n",
      "Epoch1331 | train loss 0.5579035632312298\n",
      "Epoch1332 | train loss 0.5578962302207947\n",
      "Epoch1333 | train loss 0.5578876308910549\n",
      "Epoch1334 | train loss 0.5578780608437955\n",
      "Epoch1335 | train loss 0.5578708699718118\n",
      "Epoch1336 | train loss 0.5578607668913901\n",
      "Epoch1337 | train loss 0.5578525607660413\n",
      "Epoch1338 | train loss 0.5578447967022657\n",
      "Epoch1339 | train loss 0.5578357937559485\n",
      "Epoch1340 | train loss 0.5578283033892513\n",
      "Epoch1341 | train loss 0.5578194497153163\n",
      "Epoch1342 | train loss 0.557811960875988\n",
      "Epoch1343 | train loss 0.5578032616525889\n",
      "Epoch1344 | train loss 0.5577959620580077\n",
      "Epoch1345 | train loss 0.5577878524549306\n",
      "Epoch1346 | train loss 0.5577794095873833\n",
      "Epoch1347 | train loss 0.5577710217796266\n",
      "Epoch1348 | train loss 0.5577636975236238\n",
      "Epoch1349 | train loss 0.5577557661384344\n",
      "Epoch1350 | train loss 0.5577491083927453\n",
      "Epoch1351 | train loss 0.5577404614724218\n",
      "Epoch1352 | train loss 0.55773299112916\n",
      "Epoch1353 | train loss 0.5577254484593869\n",
      "Epoch1354 | train loss 0.5577183936908842\n",
      "Epoch1355 | train loss 0.5577107877843082\n",
      "Epoch1356 | train loss 0.5577035684138536\n",
      "Epoch1357 | train loss 0.557696265950799\n",
      "Epoch1358 | train loss 0.5576892002113163\n",
      "Epoch1359 | train loss 0.5576821454428136\n",
      "Epoch1360 | train loss 0.5576750515215099\n",
      "Epoch1361 | train loss 0.5576672287657857\n",
      "Epoch1362 | train loss 0.5576603671908379\n",
      "Epoch1363 | train loss 0.5576526993513107\n",
      "Epoch1364 | train loss 0.5576452797278761\n",
      "Epoch1365 | train loss 0.557637514360249\n",
      "Epoch1366 | train loss 0.5576305384747684\n",
      "Epoch1367 | train loss 0.5576227223500609\n",
      "Epoch1368 | train loss 0.5576153152994812\n",
      "Epoch1369 | train loss 0.5576076070778072\n",
      "Epoch1370 | train loss 0.5575999405793846\n",
      "Epoch1371 | train loss 0.5575928914919496\n",
      "Epoch1372 | train loss 0.5575853998214007\n",
      "Epoch1373 | train loss 0.557577763274312\n",
      "Epoch1374 | train loss 0.5575704354979097\n",
      "Epoch1375 | train loss 0.5575636875629425\n",
      "Epoch1376 | train loss 0.5575548326410353\n",
      "Epoch1377 | train loss 0.5575481184758246\n",
      "Epoch1378 | train loss 0.557540124785155\n",
      "Epoch1379 | train loss 0.5575337280891836\n",
      "Epoch1380 | train loss 0.5575258821621537\n",
      "Epoch1381 | train loss 0.5575197879225016\n",
      "Epoch1382 | train loss 0.5575123758614063\n",
      "Epoch1383 | train loss 0.5575067844986915\n",
      "Epoch1384 | train loss 0.5574995392560959\n",
      "Epoch1385 | train loss 0.5574922083318233\n",
      "Epoch1386 | train loss 0.5574867303669453\n",
      "Epoch1387 | train loss 0.5574793335422874\n",
      "Epoch1388 | train loss 0.5574742550589145\n",
      "Epoch1389 | train loss 0.557467739880085\n",
      "Epoch1390 | train loss 0.5574609005823732\n",
      "Epoch1391 | train loss 0.5574549814127385\n",
      "Epoch1392 | train loss 0.5574478174373507\n",
      "Epoch1393 | train loss 0.5574419427290559\n",
      "Epoch1394 | train loss 0.5574354341253638\n",
      "Epoch1395 | train loss 0.5574288176372647\n",
      "Epoch1396 | train loss 0.5574230480007827\n",
      "Epoch1397 | train loss 0.5574157687090338\n",
      "Epoch1398 | train loss 0.5574082575365901\n",
      "Epoch1399 | train loss 0.5574015151336789\n",
      "Epoch1400 | train loss 0.5573950439691544\n",
      "Epoch1401 | train loss 0.5573886969871819\n",
      "Epoch1402 | train loss 0.5573815802112222\n",
      "Epoch1403 | train loss 0.5573741067573428\n",
      "Epoch1404 | train loss 0.557366939354688\n",
      "Epoch1405 | train loss 0.5573609716072678\n",
      "Epoch1406 | train loss 0.5573549288883806\n",
      "Epoch1407 | train loss 0.5573487627506256\n",
      "Epoch1408 | train loss 0.5573428296297789\n",
      "Epoch1409 | train loss 0.5573376118950546\n",
      "Epoch1410 | train loss 0.557331770490855\n",
      "Epoch1411 | train loss 0.5573268722742796\n",
      "Epoch1412 | train loss 0.557320709284395\n",
      "Epoch1413 | train loss 0.5573144583590328\n",
      "Epoch1414 | train loss 0.5573088696971535\n",
      "Epoch1415 | train loss 0.5573022152855992\n",
      "Epoch1416 | train loss 0.557295803502202\n",
      "Epoch1417 | train loss 0.5572895772755146\n",
      "Epoch1418 | train loss 0.5572838096693158\n",
      "Epoch1419 | train loss 0.5572779189422726\n",
      "Epoch1420 | train loss 0.557272182200104\n",
      "Epoch1421 | train loss 0.5572661090828478\n",
      "Epoch1422 | train loss 0.5572604268044233\n",
      "Epoch1423 | train loss 0.5572544403374196\n",
      "Epoch1424 | train loss 0.5572488217614591\n",
      "Epoch1425 | train loss 0.5572429452836514\n",
      "Epoch1426 | train loss 0.5572369383089244\n",
      "Epoch1427 | train loss 0.5572314321063458\n",
      "Epoch1428 | train loss 0.5572243522852659\n",
      "Epoch1429 | train loss 0.5572198395058513\n",
      "Epoch1430 | train loss 0.5572126401774585\n",
      "Epoch1431 | train loss 0.5572081925347447\n",
      "Epoch1432 | train loss 0.5572028260864318\n",
      "Epoch1433 | train loss 0.5571966321393848\n",
      "Epoch1434 | train loss 0.5571903705783189\n",
      "Epoch1435 | train loss 0.5571869236417115\n",
      "Epoch1436 | train loss 0.5571797855943441\n",
      "Epoch1437 | train loss 0.5571747440844774\n",
      "Epoch1438 | train loss 0.5571695728227496\n",
      "Epoch1439 | train loss 0.5571644589677454\n",
      "Epoch1440 | train loss 0.5571585194021463\n",
      "Epoch1441 | train loss 0.5571535909548402\n",
      "Epoch1442 | train loss 0.5571478234790266\n",
      "Epoch1443 | train loss 0.5571425174921751\n",
      "Epoch1444 | train loss 0.5571374833583832\n",
      "Epoch1445 | train loss 0.5571322334744037\n",
      "Epoch1446 | train loss 0.5571264522336423\n",
      "Epoch1447 | train loss 0.5571218663081526\n",
      "Epoch1448 | train loss 0.5571170407347381\n",
      "Epoch1449 | train loss 0.5571119621396065\n",
      "Epoch1450 | train loss 0.5571066448278725\n",
      "Epoch1451 | train loss 0.5571019217185676\n",
      "Epoch1452 | train loss 0.5570977625250816\n",
      "Epoch1453 | train loss 0.5570920115709305\n",
      "Epoch1454 | train loss 0.557088049724698\n",
      "Epoch1455 | train loss 0.5570828028395772\n",
      "Epoch1456 | train loss 0.5570788631215692\n",
      "Epoch1457 | train loss 0.5570741409063339\n",
      "Epoch1458 | train loss 0.5570697717368602\n",
      "Epoch1459 | train loss 0.5570636889897287\n",
      "Epoch1460 | train loss 0.5570595979690551\n",
      "Epoch1461 | train loss 0.557052476927638\n",
      "Epoch1462 | train loss 0.5570469874702394\n",
      "Epoch1463 | train loss 0.5570417791046203\n",
      "Epoch1464 | train loss 0.5570365903899074\n",
      "Epoch1465 | train loss 0.5570312364958226\n",
      "Epoch1466 | train loss 0.5570263100042939\n",
      "Epoch1467 | train loss 0.5570222839713097\n",
      "Epoch1468 | train loss 0.5570170613192021\n",
      "Epoch1469 | train loss 0.5570121668837964\n",
      "Epoch1470 | train loss 0.5570076950639486\n",
      "Epoch1471 | train loss 0.5570023480243981\n",
      "Epoch1472 | train loss 0.5569978810101748\n",
      "Epoch1473 | train loss 0.5569930480979383\n",
      "Epoch1474 | train loss 0.5569872068054974\n",
      "Epoch1475 | train loss 0.5569840147159993\n",
      "Epoch1476 | train loss 0.5569789986684919\n",
      "Epoch1477 | train loss 0.5569732650369406\n",
      "Epoch1478 | train loss 0.5569704282656311\n",
      "Epoch1479 | train loss 0.5569655198603869\n",
      "Epoch1480 | train loss 0.5569609575346113\n",
      "Epoch1481 | train loss 0.556956916861236\n",
      "Epoch1482 | train loss 0.5569513965398073\n",
      "Epoch1483 | train loss 0.5569481152482331\n",
      "Epoch1484 | train loss 0.5569447369500995\n",
      "Epoch1485 | train loss 0.5569401650875807\n",
      "Epoch1486 | train loss 0.5569359463453293\n",
      "Epoch1487 | train loss 0.5569306693598628\n",
      "Epoch1488 | train loss 0.5569271571934223\n",
      "Epoch1489 | train loss 0.5569219373352826\n",
      "Epoch1490 | train loss 0.5569178035482765\n",
      "Epoch1491 | train loss 0.5569140797294676\n",
      "Epoch1492 | train loss 0.556910487934947\n",
      "Epoch1493 | train loss 0.5569066711515188\n",
      "Epoch1494 | train loss 0.5569032387621701\n",
      "Epoch1495 | train loss 0.5568986931443214\n",
      "Epoch1496 | train loss 0.5568949132598937\n",
      "Epoch1497 | train loss 0.5568906122818589\n",
      "Epoch1498 | train loss 0.556887279972434\n",
      "Epoch1499 | train loss 0.5568828618526459\n",
      "Epoch1500 | train loss 0.5568793868087232\n",
      "Epoch1501 | train loss 0.5568755850195884\n",
      "Epoch1502 | train loss 0.5568709885142744\n",
      "Epoch1503 | train loss 0.5568678890168667\n",
      "Epoch1504 | train loss 0.5568638009205461\n",
      "Epoch1505 | train loss 0.5568597668781876\n",
      "Epoch1506 | train loss 0.5568565768934787\n",
      "Epoch1507 | train loss 0.5568525161780417\n",
      "Epoch1508 | train loss 0.5568492874875665\n",
      "Epoch1509 | train loss 0.5568448971584439\n",
      "Epoch1510 | train loss 0.5568404768593609\n",
      "Epoch1511 | train loss 0.5568369543552398\n",
      "Epoch1512 | train loss 0.5568338707834483\n",
      "Epoch1513 | train loss 0.5568301586806774\n",
      "Epoch1514 | train loss 0.5568257953971625\n",
      "Epoch1515 | train loss 0.5568225910142064\n",
      "Epoch1516 | train loss 0.5568192529305815\n",
      "Epoch1517 | train loss 0.556814678646624\n",
      "Epoch1518 | train loss 0.5568123321980238\n",
      "Epoch1519 | train loss 0.556808398552239\n",
      "Epoch1520 | train loss 0.5568044876866043\n",
      "Epoch1521 | train loss 0.5568013557046652\n",
      "Epoch1522 | train loss 0.5567971139214933\n",
      "Epoch1523 | train loss 0.5567944959364831\n",
      "Epoch1524 | train loss 0.556790663599968\n",
      "Epoch1525 | train loss 0.5567876617982983\n",
      "Epoch1526 | train loss 0.5567834958620369\n",
      "Epoch1527 | train loss 0.5567805313877762\n",
      "Epoch1528 | train loss 0.5567774445191026\n",
      "Epoch1529 | train loss 0.556773499250412\n",
      "Epoch1530 | train loss 0.5567694190703333\n",
      "Epoch1531 | train loss 0.5567666917853057\n",
      "Epoch1532 | train loss 0.5567633328959346\n",
      "Epoch1533 | train loss 0.5567599286511541\n",
      "Epoch1534 | train loss 0.5567565041407943\n",
      "Epoch1535 | train loss 0.5567528577148915\n",
      "Epoch1536 | train loss 0.5567494034208358\n",
      "Epoch1537 | train loss 0.5567464696988463\n",
      "Epoch1538 | train loss 0.5567431441880762\n",
      "Epoch1539 | train loss 0.5567398782446981\n",
      "Epoch1540 | train loss 0.5567364119365812\n",
      "Epoch1541 | train loss 0.55673284528777\n",
      "Epoch1542 | train loss 0.5567294256389141\n",
      "Epoch1543 | train loss 0.5567265153303742\n",
      "Epoch1544 | train loss 0.5567235889099539\n",
      "Epoch1545 | train loss 0.5567205050401389\n",
      "Epoch1546 | train loss 0.5567166314274072\n",
      "Epoch1547 | train loss 0.5567131313122808\n",
      "Epoch1548 | train loss 0.5567102349177003\n",
      "Epoch1549 | train loss 0.5567065090872347\n",
      "Epoch1550 | train loss 0.5567033780366182\n",
      "Epoch1551 | train loss 0.5567000057734549\n",
      "Epoch1552 | train loss 0.5566965455748141\n",
      "Epoch1553 | train loss 0.5566928777471185\n",
      "Epoch1554 | train loss 0.5566894642077387\n",
      "Epoch1555 | train loss 0.5566857722774148\n",
      "Epoch1556 | train loss 0.5566823563352227\n",
      "Epoch1557 | train loss 0.5566784330829978\n",
      "Epoch1558 | train loss 0.5566747971065342\n",
      "Epoch1559 | train loss 0.5566711135022342\n",
      "Epoch1560 | train loss 0.5566677908599377\n",
      "Epoch1561 | train loss 0.5566630001738667\n",
      "Epoch1562 | train loss 0.5566596555523574\n",
      "Epoch1563 | train loss 0.5566552910208702\n",
      "Epoch1564 | train loss 0.5566541330888868\n",
      "Epoch1565 | train loss 0.5566501431725919\n",
      "Epoch1566 | train loss 0.556646214146167\n",
      "Epoch1567 | train loss 0.5566423938795925\n",
      "Epoch1568 | train loss 0.5566392725333571\n",
      "Epoch1569 | train loss 0.5566363831050694\n",
      "Epoch1570 | train loss 0.5566327185556292\n",
      "Epoch1571 | train loss 0.5566295759379863\n",
      "Epoch1572 | train loss 0.5566272945888341\n",
      "Epoch1573 | train loss 0.5566231190599501\n",
      "Epoch1574 | train loss 0.556620118599385\n",
      "Epoch1575 | train loss 0.5566174443252385\n",
      "Epoch1576 | train loss 0.5566135044768452\n",
      "Epoch1577 | train loss 0.5566106170974672\n",
      "Epoch1578 | train loss 0.5566078866273165\n",
      "Epoch1579 | train loss 0.5566048189438879\n",
      "Epoch1580 | train loss 0.5566009993106127\n",
      "Epoch1581 | train loss 0.5565987847559154\n",
      "Epoch1582 | train loss 0.5565954620763659\n",
      "Epoch1583 | train loss 0.5565924811549485\n",
      "Epoch1584 | train loss 0.5565886055678129\n",
      "Epoch1585 | train loss 0.5565864359401167\n",
      "Epoch1586 | train loss 0.5565826849453152\n",
      "Epoch1587 | train loss 0.556580078098923\n",
      "Epoch1588 | train loss 0.5565763863548636\n",
      "Epoch1589 | train loss 0.556573253236711\n",
      "Epoch1590 | train loss 0.5565707834810019\n",
      "Epoch1591 | train loss 0.5565677831880749\n",
      "Epoch1592 | train loss 0.5565640914812684\n",
      "Epoch1593 | train loss 0.556561631783843\n",
      "Epoch1594 | train loss 0.5565576539933681\n",
      "Epoch1595 | train loss 0.5565547207184136\n",
      "Epoch1596 | train loss 0.556552331969142\n",
      "Epoch1597 | train loss 0.5565492240339518\n",
      "Epoch1598 | train loss 0.5565460978075862\n",
      "Epoch1599 | train loss 0.5565419165045022\n",
      "Epoch1600 | train loss 0.5565400541760027\n",
      "Epoch1601 | train loss 0.5565364692546427\n",
      "Epoch1602 | train loss 0.556534223165363\n",
      "Epoch1603 | train loss 0.5565300068818033\n",
      "Epoch1604 | train loss 0.5565275632590055\n",
      "Epoch1605 | train loss 0.5565246062539518\n",
      "Epoch1606 | train loss 0.5565209045261145\n",
      "Epoch1607 | train loss 0.55651869289577\n",
      "Epoch1608 | train loss 0.5565151165053248\n",
      "Epoch1609 | train loss 0.5565129266306758\n",
      "Epoch1610 | train loss 0.5565099071711301\n",
      "Epoch1611 | train loss 0.5565063306502998\n",
      "Epoch1612 | train loss 0.556504187155515\n",
      "Epoch1613 | train loss 0.5565005988255143\n",
      "Epoch1614 | train loss 0.5564984394237399\n",
      "Epoch1615 | train loss 0.5564949537068605\n",
      "Epoch1616 | train loss 0.5564927418343723\n",
      "Epoch1617 | train loss 0.5564892210438848\n",
      "Epoch1618 | train loss 0.5564871055260301\n",
      "Epoch1619 | train loss 0.5564836502447724\n",
      "Epoch1620 | train loss 0.5564814596436918\n",
      "Epoch1621 | train loss 0.5564779975451529\n",
      "Epoch1622 | train loss 0.5564759039878845\n",
      "Epoch1623 | train loss 0.5564727058447897\n",
      "Epoch1624 | train loss 0.5564712872728705\n",
      "Epoch1625 | train loss 0.5564670730382204\n",
      "Epoch1626 | train loss 0.5564650845527649\n",
      "Epoch1627 | train loss 0.556461650878191\n",
      "Epoch1628 | train loss 0.5564596589282155\n",
      "Epoch1629 | train loss 0.5564575720950962\n",
      "Epoch1630 | train loss 0.5564536406844854\n",
      "Epoch1631 | train loss 0.5564509802870452\n",
      "Epoch1632 | train loss 0.5564488689415157\n",
      "Epoch1633 | train loss 0.5564463869668543\n",
      "Epoch1634 | train loss 0.5564442507177592\n",
      "Epoch1635 | train loss 0.5564405723661184\n",
      "Epoch1636 | train loss 0.5564375696331263\n",
      "Epoch1637 | train loss 0.5564356265962124\n",
      "Epoch1638 | train loss 0.5564331766590476\n",
      "Epoch1639 | train loss 0.5564301837421953\n",
      "Epoch1640 | train loss 0.5564278092421592\n",
      "Epoch1641 | train loss 0.5564244987815619\n",
      "Epoch1642 | train loss 0.5564225457794965\n",
      "Epoch1643 | train loss 0.5564191386289895\n",
      "Epoch1644 | train loss 0.5564170013554395\n",
      "Epoch1645 | train loss 0.5564140648394823\n",
      "Epoch1646 | train loss 0.5564116415381432\n",
      "Epoch1647 | train loss 0.5564086995087564\n",
      "Epoch1648 | train loss 0.5564057593792677\n",
      "Epoch1649 | train loss 0.5564037581905723\n",
      "Epoch1650 | train loss 0.5564011195860803\n",
      "Epoch1651 | train loss 0.5563983159512281\n",
      "Epoch1652 | train loss 0.5563955895602704\n",
      "Epoch1653 | train loss 0.5563920843601227\n",
      "Epoch1654 | train loss 0.5563900291919708\n",
      "Epoch1655 | train loss 0.5563874489627778\n",
      "Epoch1656 | train loss 0.5563846838660538\n",
      "Epoch1657 | train loss 0.556382095515728\n",
      "Epoch1658 | train loss 0.556380036007613\n",
      "Epoch1659 | train loss 0.556376651134342\n",
      "Epoch1660 | train loss 0.5563740178383887\n",
      "Epoch1661 | train loss 0.5563715087994933\n",
      "Epoch1662 | train loss 0.5563687044009566\n",
      "Epoch1663 | train loss 0.5563666253723204\n",
      "Epoch1664 | train loss 0.5563634207844734\n",
      "Epoch1665 | train loss 0.5563605349510908\n",
      "Epoch1666 | train loss 0.5563585445471108\n",
      "Epoch1667 | train loss 0.5563552135974169\n",
      "Epoch1668 | train loss 0.556353275179863\n",
      "Epoch1669 | train loss 0.5563499118387699\n",
      "Epoch1670 | train loss 0.5563476589694619\n",
      "Epoch1671 | train loss 0.5563452448509634\n",
      "Epoch1672 | train loss 0.5563426491431892\n",
      "Epoch1673 | train loss 0.5563401922956109\n",
      "Epoch1674 | train loss 0.5563373224250973\n",
      "Epoch1675 | train loss 0.556335069462657\n",
      "Epoch1676 | train loss 0.5563320847600699\n",
      "Epoch1677 | train loss 0.5563300860486925\n",
      "Epoch1678 | train loss 0.5563270628079772\n",
      "Epoch1679 | train loss 0.5563254147209227\n",
      "Epoch1680 | train loss 0.5563219328597188\n",
      "Epoch1681 | train loss 0.5563195701688528\n",
      "Epoch1682 | train loss 0.5563173610903323\n",
      "Epoch1683 | train loss 0.5563155788742006\n",
      "Epoch1684 | train loss 0.5563118995726108\n",
      "Epoch1685 | train loss 0.5563093054480851\n",
      "Epoch1686 | train loss 0.5563076590932906\n",
      "Epoch1687 | train loss 0.5563044195249677\n",
      "Epoch1688 | train loss 0.5563026119768619\n",
      "Epoch1689 | train loss 0.5563006697781384\n",
      "Epoch1690 | train loss 0.5562973158806562\n",
      "Epoch1691 | train loss 0.5562945289723575\n",
      "Epoch1692 | train loss 0.5562929248809815\n",
      "Epoch1693 | train loss 0.5562896564975381\n",
      "Epoch1694 | train loss 0.5562873811647296\n",
      "Epoch1695 | train loss 0.5562856624647975\n",
      "Epoch1696 | train loss 0.556281795911491\n",
      "Epoch1697 | train loss 0.5562799401022493\n",
      "Epoch1698 | train loss 0.5562782014906407\n",
      "Epoch1699 | train loss 0.5562750114500523\n",
      "Epoch1700 | train loss 0.5562725161202252\n",
      "Epoch1701 | train loss 0.5562708848342299\n",
      "Epoch1702 | train loss 0.5562677821144462\n",
      "Epoch1703 | train loss 0.5562654894217849\n",
      "Epoch1704 | train loss 0.5562624102830886\n",
      "Epoch1705 | train loss 0.5562613609805703\n",
      "Epoch1706 | train loss 0.5562576084956526\n",
      "Epoch1707 | train loss 0.5562570213526488\n",
      "Epoch1708 | train loss 0.5562530013360083\n",
      "Epoch1709 | train loss 0.5562516490928828\n",
      "Epoch1710 | train loss 0.5562482416629791\n",
      "Epoch1711 | train loss 0.5562473043799401\n",
      "Epoch1712 | train loss 0.5562433969601989\n",
      "Epoch1713 | train loss 0.556241199336946\n",
      "Epoch1714 | train loss 0.5562379276007414\n",
      "Epoch1715 | train loss 0.5562361872941256\n",
      "Epoch1716 | train loss 0.5562340617179871\n",
      "Epoch1717 | train loss 0.5562295293062925\n",
      "Epoch1718 | train loss 0.5562284902483224\n",
      "Epoch1719 | train loss 0.556224950030446\n",
      "Epoch1720 | train loss 0.5562231710180641\n",
      "Epoch1721 | train loss 0.5562212481722235\n",
      "Epoch1722 | train loss 0.5562187047675252\n",
      "Epoch1723 | train loss 0.5562166023999453\n",
      "Epoch1724 | train loss 0.5562148307822645\n",
      "Epoch1725 | train loss 0.556212130766362\n",
      "Epoch1726 | train loss 0.556210805028677\n",
      "Epoch1727 | train loss 0.5562078051641584\n",
      "Epoch1728 | train loss 0.5562045426294208\n",
      "Epoch1729 | train loss 0.5562023192830384\n",
      "Epoch1730 | train loss 0.5561994900554419\n",
      "Epoch1731 | train loss 0.5561959324590862\n",
      "Epoch1732 | train loss 0.5561934256181121\n",
      "Epoch1733 | train loss 0.5561913165450096\n",
      "Epoch1734 | train loss 0.5561879445239901\n",
      "Epoch1735 | train loss 0.5561861114576458\n",
      "Epoch1736 | train loss 0.5561835030838848\n",
      "Epoch1737 | train loss 0.5561801716499031\n",
      "Epoch1738 | train loss 0.5561782800965012\n",
      "Epoch1739 | train loss 0.5561747014150024\n",
      "Epoch1740 | train loss 0.5561730624362826\n",
      "Epoch1741 | train loss 0.5561703344248236\n",
      "Epoch1742 | train loss 0.5561669256165623\n",
      "Epoch1743 | train loss 0.5561658429913223\n",
      "Epoch1744 | train loss 0.5561628330498933\n",
      "Epoch1745 | train loss 0.5561593525111675\n",
      "Epoch1746 | train loss 0.5561571487784386\n",
      "Epoch1747 | train loss 0.5561553496308624\n",
      "Epoch1748 | train loss 0.5561519145406782\n",
      "Epoch1749 | train loss 0.5561506162956357\n",
      "Epoch1750 | train loss 0.5561484568752348\n",
      "Epoch1751 | train loss 0.5561441530101001\n",
      "Epoch1752 | train loss 0.5561437700130045\n",
      "Epoch1753 | train loss 0.5561412863433361\n",
      "Epoch1754 | train loss 0.5561372911930085\n",
      "Epoch1755 | train loss 0.5561350350826979\n",
      "Epoch1756 | train loss 0.5561333060078323\n",
      "Epoch1757 | train loss 0.5561306746676564\n",
      "Epoch1758 | train loss 0.5561279121600091\n",
      "Epoch1759 | train loss 0.5561256412230432\n",
      "Epoch1760 | train loss 0.5561244850791991\n",
      "Epoch1761 | train loss 0.5561211917176843\n",
      "Epoch1762 | train loss 0.556118823941797\n",
      "Epoch1763 | train loss 0.5561165199615061\n",
      "Epoch1764 | train loss 0.5561146941035986\n",
      "Epoch1765 | train loss 0.5561114973016084\n",
      "Epoch1766 | train loss 0.5561087745800615\n",
      "Epoch1767 | train loss 0.5561072166450322\n",
      "Epoch1768 | train loss 0.5561048590764404\n",
      "Epoch1769 | train loss 0.5561019966751337\n",
      "Epoch1770 | train loss 0.5561004547029733\n",
      "Epoch1771 | train loss 0.5560977187938988\n",
      "Epoch1772 | train loss 0.5560952096432448\n",
      "Epoch1773 | train loss 0.5560936495848\n",
      "Epoch1774 | train loss 0.5560909693688154\n",
      "Epoch1775 | train loss 0.5560888710059225\n",
      "Epoch1776 | train loss 0.5560874405875802\n",
      "Epoch1777 | train loss 0.5560846787318587\n",
      "Epoch1778 | train loss 0.5560832131840289\n",
      "Epoch1779 | train loss 0.5560808254033327\n",
      "Epoch1780 | train loss 0.5560786490142345\n",
      "Epoch1781 | train loss 0.5560763129591941\n",
      "Epoch1782 | train loss 0.5560744685120881\n",
      "Epoch1783 | train loss 0.55607213255018\n",
      "Epoch1784 | train loss 0.556070040948689\n",
      "Epoch1785 | train loss 0.5560676951706409\n",
      "Epoch1786 | train loss 0.5560649460181594\n",
      "Epoch1787 | train loss 0.5560631326027214\n",
      "Epoch1788 | train loss 0.5560596684925259\n",
      "Epoch1789 | train loss 0.5560579843260348\n",
      "Epoch1790 | train loss 0.5560554440133274\n",
      "Epoch1791 | train loss 0.556052279677242\n",
      "Epoch1792 | train loss 0.5560511777922511\n",
      "Epoch1793 | train loss 0.5560481733642518\n",
      "Epoch1794 | train loss 0.5560449162870645\n",
      "Epoch1795 | train loss 0.556042978670448\n",
      "Epoch1796 | train loss 0.5560417238622903\n",
      "Epoch1797 | train loss 0.5560374633595347\n",
      "Epoch1798 | train loss 0.5560356547310948\n",
      "Epoch1799 | train loss 0.556033948585391\n",
      "Epoch1800 | train loss 0.5560308762639761\n",
      "Epoch1801 | train loss 0.5560297721065581\n",
      "Epoch1802 | train loss 0.5560255941748619\n",
      "Epoch1803 | train loss 0.5560251439921557\n",
      "Epoch1804 | train loss 0.5560216650739312\n",
      "Epoch1805 | train loss 0.556020182929933\n",
      "Epoch1806 | train loss 0.5560170733369887\n",
      "Epoch1807 | train loss 0.5560161813348532\n",
      "Epoch1808 | train loss 0.5560133854858578\n",
      "Epoch1809 | train loss 0.5560103380307555\n",
      "Epoch1810 | train loss 0.5560094457678497\n",
      "Epoch1811 | train loss 0.5560065498389304\n",
      "Epoch1812 | train loss 0.5560037222132087\n",
      "Epoch1813 | train loss 0.5560026247240603\n",
      "Epoch1814 | train loss 0.5560004511475563\n",
      "Epoch1815 | train loss 0.5559975381568074\n",
      "Epoch1816 | train loss 0.5559958830289543\n",
      "Epoch1817 | train loss 0.5559918953664601\n",
      "Epoch1818 | train loss 0.5559916349500418\n",
      "Epoch1819 | train loss 0.5559887700714171\n",
      "Epoch1820 | train loss 0.555987155996263\n",
      "Epoch1821 | train loss 0.5559848044998944\n",
      "Epoch1822 | train loss 0.555981151368469\n",
      "Epoch1823 | train loss 0.5559806210920215\n",
      "Epoch1824 | train loss 0.5559786037541926\n",
      "Epoch1825 | train loss 0.5559757181443274\n",
      "Epoch1826 | train loss 0.5559729836136102\n",
      "Epoch1827 | train loss 0.555972058493644\n",
      "Epoch1828 | train loss 0.5559696961566806\n",
      "Epoch1829 | train loss 0.5559673431888222\n",
      "Epoch1830 | train loss 0.5559654775820673\n",
      "Epoch1831 | train loss 0.5559636196494102\n",
      "Epoch1832 | train loss 0.5559613130800426\n",
      "Epoch1833 | train loss 0.5559589529410005\n",
      "Epoch1834 | train loss 0.5559560957364738\n",
      "Epoch1835 | train loss 0.5559554700180889\n",
      "Epoch1836 | train loss 0.5559534150920808\n",
      "Epoch1837 | train loss 0.5559511018544435\n",
      "Epoch1838 | train loss 0.5559485995769501\n",
      "Epoch1839 | train loss 0.5559469861723483\n",
      "Epoch1840 | train loss 0.5559447474963963\n",
      "Epoch1841 | train loss 0.555941723883152\n",
      "Epoch1842 | train loss 0.5559408955648542\n",
      "Epoch1843 | train loss 0.5559385012649\n",
      "Epoch1844 | train loss 0.555935966745019\n",
      "Epoch1845 | train loss 0.5559342850744724\n",
      "Epoch1846 | train loss 0.5559323652461171\n",
      "Epoch1847 | train loss 0.5559298406541348\n",
      "Epoch1848 | train loss 0.5559278167970478\n",
      "Epoch1849 | train loss 0.5559253871627152\n",
      "Epoch1850 | train loss 0.5559234003163874\n",
      "Epoch1851 | train loss 0.5559210884943604\n",
      "Epoch1852 | train loss 0.5559193002432585\n",
      "Epoch1853 | train loss 0.555916894339025\n",
      "Epoch1854 | train loss 0.5559149990417063\n",
      "Epoch1855 | train loss 0.5559136746637523\n",
      "Epoch1856 | train loss 0.5559106338024139\n",
      "Epoch1857 | train loss 0.5559087700769305\n",
      "Epoch1858 | train loss 0.5559064622037113\n",
      "Epoch1859 | train loss 0.5559046267904342\n",
      "Epoch1860 | train loss 0.5559028876200318\n",
      "Epoch1861 | train loss 0.5559012780338526\n",
      "Epoch1862 | train loss 0.5558984321542084\n",
      "Epoch1863 | train loss 0.5558952086791397\n",
      "Epoch1864 | train loss 0.5558939161151648\n",
      "Epoch1865 | train loss 0.5558913973160088\n",
      "Epoch1866 | train loss 0.5558894105814397\n",
      "Epoch1867 | train loss 0.5558870938047766\n",
      "Epoch1868 | train loss 0.5558854612335563\n",
      "Epoch1869 | train loss 0.5558825209736824\n",
      "Epoch1870 | train loss 0.5558808470889925\n",
      "Epoch1871 | train loss 0.5558781975135207\n",
      "Epoch1872 | train loss 0.5558761474862695\n",
      "Epoch1873 | train loss 0.5558744166977704\n",
      "Epoch1874 | train loss 0.5558719076029957\n",
      "Epoch1875 | train loss 0.555870130546391\n",
      "Epoch1876 | train loss 0.555868831910193\n",
      "Epoch1877 | train loss 0.55586485337466\n",
      "Epoch1878 | train loss 0.5558638500422239\n",
      "Epoch1879 | train loss 0.5558614827692508\n",
      "Epoch1880 | train loss 0.5558596809208393\n",
      "Epoch1881 | train loss 0.555857529900968\n",
      "Epoch1882 | train loss 0.555856362786144\n",
      "Epoch1883 | train loss 0.5558525577932596\n",
      "Epoch1884 | train loss 0.5558518024533987\n",
      "Epoch1885 | train loss 0.5558484321273863\n",
      "Epoch1886 | train loss 0.5558480483293533\n",
      "Epoch1887 | train loss 0.5558448568359018\n",
      "Epoch1888 | train loss 0.5558440376445651\n",
      "Epoch1889 | train loss 0.5558409369550645\n",
      "Epoch1890 | train loss 0.5558388535305858\n",
      "Epoch1891 | train loss 0.5558377008326352\n",
      "Epoch1892 | train loss 0.5558350555412471\n",
      "Epoch1893 | train loss 0.555833813007921\n",
      "Epoch1894 | train loss 0.5558310106769204\n",
      "Epoch1895 | train loss 0.555829146951437\n",
      "Epoch1896 | train loss 0.5558284422568976\n",
      "Epoch1897 | train loss 0.5558241315558553\n",
      "Epoch1898 | train loss 0.5558235865458846\n",
      "Epoch1899 | train loss 0.5558203186094761\n",
      "Epoch1900 | train loss 0.555820002052933\n",
      "Epoch1901 | train loss 0.5558168509043753\n",
      "Epoch1902 | train loss 0.5558154563046992\n",
      "Epoch1903 | train loss 0.5558125120587647\n",
      "Epoch1904 | train loss 0.5558121127821505\n",
      "Epoch1905 | train loss 0.5558094708248973\n",
      "Epoch1906 | train loss 0.5558072552643716\n",
      "Epoch1907 | train loss 0.5558062984235584\n",
      "Epoch1908 | train loss 0.5558028003759682\n",
      "Epoch1909 | train loss 0.5558018915355205\n",
      "Epoch1910 | train loss 0.5558003363758326\n",
      "Epoch1911 | train loss 0.5557970989309251\n",
      "Epoch1912 | train loss 0.555796722099185\n",
      "Epoch1913 | train loss 0.5557942628115415\n",
      "Epoch1914 | train loss 0.5557918773964048\n",
      "Epoch1915 | train loss 0.5557911295443774\n",
      "Epoch1916 | train loss 0.5557886258885264\n",
      "Epoch1917 | train loss 0.5557867209985852\n",
      "Epoch1918 | train loss 0.5557856026291847\n",
      "Epoch1919 | train loss 0.5557839569076896\n",
      "Epoch1920 | train loss 0.5557813175581395\n",
      "Epoch1921 | train loss 0.5557794392853975\n",
      "Epoch1922 | train loss 0.5557777444459497\n",
      "Epoch1923 | train loss 0.5557753789424896\n",
      "Epoch1924 | train loss 0.5557754365727305\n",
      "Epoch1925 | train loss 0.5557729326933623\n",
      "Epoch1926 | train loss 0.5557690767943859\n",
      "Epoch1927 | train loss 0.5557679757848382\n",
      "Epoch1928 | train loss 0.555765969529748\n",
      "Epoch1929 | train loss 0.5557659398019313\n",
      "Epoch1930 | train loss 0.5557604290917516\n",
      "Epoch1931 | train loss 0.5557610268518328\n",
      "Epoch1932 | train loss 0.5557594910264015\n",
      "Epoch1933 | train loss 0.5557572319544852\n",
      "Epoch1934 | train loss 0.555754859521985\n",
      "Epoch1935 | train loss 0.5557530825212598\n",
      "Epoch1936 | train loss 0.5557520297914743\n",
      "Epoch1937 | train loss 0.5557507827691733\n",
      "Epoch1938 | train loss 0.5557466245815158\n",
      "Epoch1939 | train loss 0.5557480770163238\n",
      "Epoch1940 | train loss 0.555743503253907\n",
      "Epoch1941 | train loss 0.5557437039166689\n",
      "Epoch1942 | train loss 0.5557413696311414\n",
      "Epoch1943 | train loss 0.5557392415776848\n",
      "Epoch1944 | train loss 0.5557377574034035\n",
      "Epoch1945 | train loss 0.5557362216152251\n",
      "Epoch1946 | train loss 0.5557342872954905\n",
      "Epoch1947 | train loss 0.5557329717837274\n",
      "Epoch1948 | train loss 0.5557308189757169\n",
      "Epoch1949 | train loss 0.5557293659634888\n",
      "Epoch1950 | train loss 0.5557289286330342\n",
      "Epoch1951 | train loss 0.5557269418984652\n",
      "Epoch1952 | train loss 0.5557241640426218\n",
      "Epoch1953 | train loss 0.5557256526499986\n",
      "Epoch1954 | train loss 0.5557228057086467\n",
      "Epoch1955 | train loss 0.5557196290045977\n",
      "Epoch1956 | train loss 0.5557193881459535\n",
      "Epoch1957 | train loss 0.5557175314798951\n",
      "Epoch1958 | train loss 0.5557157960347832\n",
      "Epoch1959 | train loss 0.5557133351638913\n",
      "Epoch1960 | train loss 0.5557117704674601\n",
      "Epoch1961 | train loss 0.5557118469104171\n",
      "Epoch1962 | train loss 0.5557086330279708\n",
      "Epoch1963 | train loss 0.5557074508816003\n",
      "Epoch1964 | train loss 0.5557072683610023\n",
      "Epoch1965 | train loss 0.5557062661089003\n",
      "Epoch1966 | train loss 0.5557031400315463\n",
      "Epoch1967 | train loss 0.5556999801285565\n",
      "Epoch1968 | train loss 0.5557008474878967\n",
      "Epoch1969 | train loss 0.5556977750733495\n",
      "Epoch1970 | train loss 0.5556981403008103\n",
      "Epoch1971 | train loss 0.5556940370053053\n",
      "Epoch1972 | train loss 0.5556941666640342\n",
      "Epoch1973 | train loss 0.5556911041215062\n",
      "Epoch1974 | train loss 0.555691990815103\n",
      "Epoch1975 | train loss 0.5556875232979656\n",
      "Epoch1976 | train loss 0.5556884416565299\n",
      "Epoch1977 | train loss 0.5556848150119186\n",
      "Epoch1978 | train loss 0.5556868610158563\n",
      "Epoch1979 | train loss 0.5556823595613242\n",
      "Epoch1980 | train loss 0.5556819852441549\n",
      "Epoch1981 | train loss 0.555681817010045\n",
      "Epoch1982 | train loss 0.55567830812186\n",
      "Epoch1983 | train loss 0.5556785352900624\n",
      "Epoch1984 | train loss 0.5556759334541858\n",
      "Epoch1985 | train loss 0.5556753074377775\n",
      "Epoch1986 | train loss 0.5556734070554376\n",
      "Epoch1987 | train loss 0.5556708138622344\n",
      "Epoch1988 | train loss 0.5556711106002331\n",
      "Epoch1989 | train loss 0.5556674198620022\n",
      "Epoch1990 | train loss 0.555668742954731\n",
      "Epoch1991 | train loss 0.5556658791936934\n",
      "Epoch1992 | train loss 0.5556640054285527\n",
      "Epoch1993 | train loss 0.5556631554476916\n",
      "Epoch1994 | train loss 0.5556627059727908\n",
      "Epoch1995 | train loss 0.5556590905040503\n",
      "Epoch1996 | train loss 0.5556592446751892\n",
      "Epoch1997 | train loss 0.5556564168818295\n",
      "Epoch1998 | train loss 0.5556557496637106\n",
      "Epoch1999 | train loss 0.5556545877084136\n",
      "Epoch2000 | train loss 0.5556537341326475\n",
      "Epoch2001 | train loss 0.5556523633748293\n",
      "Epoch2002 | train loss 0.5556522845476866\n",
      "Epoch2003 | train loss 0.5556492466293276\n",
      "Epoch2004 | train loss 0.5556469426676631\n",
      "Epoch2005 | train loss 0.55564686415717\n",
      "Epoch2006 | train loss 0.5556465992890298\n",
      "Epoch2007 | train loss 0.5556441219709813\n",
      "Epoch2008 | train loss 0.5556430217064917\n",
      "Epoch2009 | train loss 0.5556410812027752\n",
      "Epoch2010 | train loss 0.5556394359283149\n",
      "Epoch2011 | train loss 0.5556410724855959\n",
      "Epoch2012 | train loss 0.5556353701278567\n",
      "Epoch2013 | train loss 0.5556362324766815\n",
      "Epoch2014 | train loss 0.5556357086077333\n",
      "Epoch2015 | train loss 0.5556321315467357\n",
      "Epoch2016 | train loss 0.5556323431432247\n",
      "Epoch2017 | train loss 0.555630261991173\n",
      "Epoch2018 | train loss 0.5556304702721536\n",
      "Epoch2019 | train loss 0.555627024807036\n",
      "Epoch2020 | train loss 0.555627328492701\n",
      "Epoch2021 | train loss 0.5556258558481931\n",
      "Epoch2022 | train loss 0.5556232915632426\n",
      "Epoch2023 | train loss 0.5556227341294289\n",
      "Epoch2024 | train loss 0.5556231839209795\n",
      "Epoch2025 | train loss 0.5556225591152907\n",
      "Epoch2026 | train loss 0.5556189342588186\n",
      "Epoch2027 | train loss 0.555618757866323\n",
      "Epoch2028 | train loss 0.5556160785257817\n",
      "Epoch2029 | train loss 0.5556145679950714\n",
      "Epoch2030 | train loss 0.5556143812462687\n",
      "Epoch2031 | train loss 0.5556118285097181\n",
      "Epoch2032 | train loss 0.5556111002713442\n",
      "Epoch2033 | train loss 0.5556096216663718\n",
      "Epoch2034 | train loss 0.555608088336885\n",
      "Epoch2035 | train loss 0.5556067341566086\n",
      "Epoch2036 | train loss 0.555607299618423\n",
      "Epoch2037 | train loss 0.5556042403914034\n",
      "Epoch2038 | train loss 0.5556049173884093\n",
      "Epoch2039 | train loss 0.5556018405593932\n",
      "Epoch2040 | train loss 0.5556016713753342\n",
      "Epoch2041 | train loss 0.5556002506799996\n",
      "Epoch2042 | train loss 0.5555991354770958\n",
      "Epoch2043 | train loss 0.5555989803001284\n",
      "Epoch2044 | train loss 0.5555956356041133\n",
      "Epoch2045 | train loss 0.5555959568358958\n",
      "Epoch2046 | train loss 0.5555930824764073\n",
      "Epoch2047 | train loss 0.5555934928357601\n",
      "Epoch2048 | train loss 0.555591534934938\n",
      "Epoch2049 | train loss 0.5555909024178982\n",
      "Epoch2050 | train loss 0.5555882304720581\n",
      "Epoch2051 | train loss 0.555589322000742\n",
      "Epoch2052 | train loss 0.5555848128907382\n",
      "Epoch2053 | train loss 0.5555854308977723\n",
      "Epoch2054 | train loss 0.55558528855443\n",
      "Epoch2055 | train loss 0.5555839847028256\n",
      "Epoch2056 | train loss 0.5555811366811395\n",
      "Epoch2057 | train loss 0.5555798816122115\n",
      "Epoch2058 | train loss 0.5555786840617657\n",
      "Epoch2059 | train loss 0.5555779815465212\n",
      "Epoch2060 | train loss 0.5555762104690075\n",
      "Epoch2061 | train loss 0.5555744464322925\n",
      "Epoch2062 | train loss 0.5555731860734522\n",
      "Epoch2063 | train loss 0.5555729926377535\n",
      "Epoch2064 | train loss 0.5555707500874996\n",
      "Epoch2065 | train loss 0.5555709496885538\n",
      "Epoch2066 | train loss 0.5555694092065095\n",
      "Epoch2067 | train loss 0.5555670578405261\n",
      "Epoch2068 | train loss 0.5555655537731945\n",
      "Epoch2069 | train loss 0.5555636609904469\n",
      "Epoch2070 | train loss 0.5555640603043139\n",
      "Epoch2071 | train loss 0.5555621862784028\n",
      "Epoch2072 | train loss 0.5555602797493339\n",
      "Epoch2073 | train loss 0.5555603794381022\n",
      "Epoch2074 | train loss 0.5555583787336945\n",
      "Epoch2075 | train loss 0.5555572031810879\n",
      "Epoch2076 | train loss 0.5555563316680491\n",
      "Epoch2077 | train loss 0.5555549219809472\n",
      "Epoch2078 | train loss 0.555554144885391\n",
      "Epoch2079 | train loss 0.5555518982373178\n",
      "Epoch2080 | train loss 0.5555515966191887\n",
      "Epoch2081 | train loss 0.5555502717383206\n",
      "Epoch2082 | train loss 0.555549134965986\n",
      "Epoch2083 | train loss 0.5555481185391545\n",
      "Epoch2084 | train loss 0.5555469692870975\n",
      "Epoch2085 | train loss 0.5555457211844623\n",
      "Epoch2086 | train loss 0.5555442799627781\n",
      "Epoch2087 | train loss 0.5555426182039082\n",
      "Epoch2088 | train loss 0.5555426210351289\n",
      "Epoch2089 | train loss 0.5555411843396724\n",
      "Epoch2090 | train loss 0.5555384060554206\n",
      "Epoch2091 | train loss 0.5555388813465834\n",
      "Epoch2092 | train loss 0.5555386086925864\n",
      "Epoch2093 | train loss 0.5555352657660841\n",
      "Epoch2094 | train loss 0.5555350527912378\n",
      "Epoch2095 | train loss 0.5555333547480404\n",
      "Epoch2096 | train loss 0.555531709510833\n",
      "Epoch2097 | train loss 0.5555304404906929\n",
      "Epoch2098 | train loss 0.5555305759236217\n",
      "Epoch2099 | train loss 0.555528968796134\n",
      "Epoch2100 | train loss 0.5555276383832097\n",
      "Epoch2101 | train loss 0.5555260092392564\n",
      "Epoch2102 | train loss 0.5555252257362008\n",
      "Epoch2103 | train loss 0.5555239123106003\n",
      "Epoch2104 | train loss 0.5555230840854347\n",
      "Epoch2105 | train loss 0.5555211569555104\n",
      "Epoch2106 | train loss 0.555520893111825\n",
      "Epoch2107 | train loss 0.5555188186094164\n",
      "Epoch2108 | train loss 0.5555180369876325\n",
      "Epoch2109 | train loss 0.5555166246369481\n",
      "Epoch2110 | train loss 0.5555161204747856\n",
      "Epoch2111 | train loss 0.5555144278891384\n",
      "Epoch2112 | train loss 0.5555145177617669\n",
      "Epoch2113 | train loss 0.5555116304010153\n",
      "Epoch2114 | train loss 0.5555114266835153\n",
      "Epoch2115 | train loss 0.5555088664405048\n",
      "Epoch2116 | train loss 0.5555087424628437\n",
      "Epoch2117 | train loss 0.5555067934468388\n",
      "Epoch2118 | train loss 0.5555067526735366\n",
      "Epoch2119 | train loss 0.5555038936808705\n",
      "Epoch2120 | train loss 0.555504507124424\n",
      "Epoch2121 | train loss 0.5555011635832489\n",
      "Epoch2122 | train loss 0.5555011744610965\n",
      "Epoch2123 | train loss 0.5554990422539413\n",
      "Epoch2124 | train loss 0.5554989277385175\n",
      "Epoch2125 | train loss 0.5554974160343409\n",
      "Epoch2126 | train loss 0.5554953876882791\n",
      "Epoch2127 | train loss 0.5554949281923472\n",
      "Epoch2128 | train loss 0.5554924800246954\n",
      "Epoch2129 | train loss 0.5554923575930297\n",
      "Epoch2130 | train loss 0.5554913810826838\n",
      "Epoch2131 | train loss 0.555489676296711\n",
      "Epoch2132 | train loss 0.5554889123141765\n",
      "Epoch2133 | train loss 0.5554870946705341\n",
      "Epoch2134 | train loss 0.5554851470701396\n",
      "Epoch2135 | train loss 0.5554851885885\n",
      "Epoch2136 | train loss 0.5554832009598613\n",
      "Epoch2137 | train loss 0.5554827670753002\n",
      "Epoch2138 | train loss 0.5554808071069419\n",
      "Epoch2139 | train loss 0.555480355899781\n",
      "Epoch2140 | train loss 0.5554784915782511\n",
      "Epoch2141 | train loss 0.5554773259162903\n",
      "Epoch2142 | train loss 0.5554762358218431\n",
      "Epoch2143 | train loss 0.5554745316877961\n",
      "Epoch2144 | train loss 0.5554739310964942\n",
      "Epoch2145 | train loss 0.5554726632870733\n",
      "Epoch2146 | train loss 0.5554710200242698\n",
      "Epoch2147 | train loss 0.5554703040607274\n",
      "Epoch2148 | train loss 0.5554698720760644\n",
      "Epoch2149 | train loss 0.5554674111679196\n",
      "Epoch2150 | train loss 0.5554668224789202\n",
      "Epoch2151 | train loss 0.5554664156772197\n",
      "Epoch2152 | train loss 0.5554641347378493\n",
      "Epoch2153 | train loss 0.5554638925753533\n",
      "Epoch2154 | train loss 0.5554616686329246\n",
      "Epoch2155 | train loss 0.5554619514755905\n",
      "Epoch2156 | train loss 0.5554599319584668\n",
      "Epoch2157 | train loss 0.5554596387036145\n",
      "Epoch2158 | train loss 0.5554570356197656\n",
      "Epoch2159 | train loss 0.5554567536897957\n",
      "Epoch2160 | train loss 0.5554568415135145\n",
      "Epoch2161 | train loss 0.5554548172838986\n",
      "Epoch2162 | train loss 0.5554543883912265\n",
      "Epoch2163 | train loss 0.5554523735679686\n",
      "Epoch2164 | train loss 0.5554528024792671\n",
      "Epoch2165 | train loss 0.5554502586647868\n",
      "Epoch2166 | train loss 0.5554502202756703\n",
      "Epoch2167 | train loss 0.555448565594852\n",
      "Epoch2168 | train loss 0.5554483475163579\n",
      "Epoch2169 | train loss 0.5554463933221996\n",
      "Epoch2170 | train loss 0.5554464003443718\n",
      "Epoch2171 | train loss 0.5554456606134772\n",
      "Epoch2172 | train loss 0.5554437881521881\n",
      "Epoch2173 | train loss 0.5554433103278279\n",
      "Epoch2174 | train loss 0.5554422917217017\n",
      "Epoch2175 | train loss 0.5554412535019219\n",
      "Epoch2176 | train loss 0.5554404220916331\n",
      "Epoch2177 | train loss 0.555438658092171\n",
      "Epoch2178 | train loss 0.5554384088143707\n",
      "Epoch2179 | train loss 0.555436398703605\n",
      "Epoch2180 | train loss 0.555436706803739\n",
      "Epoch2181 | train loss 0.5554357264004648\n",
      "Epoch2182 | train loss 0.5554346675798297\n",
      "Epoch2183 | train loss 0.5554335407726466\n",
      "Epoch2184 | train loss 0.5554314134269953\n",
      "Epoch2185 | train loss 0.5554304098337889\n",
      "Epoch2186 | train loss 0.5554288516007364\n",
      "Epoch2187 | train loss 0.5554272899217904\n",
      "Epoch2188 | train loss 0.5554269492253661\n",
      "Epoch2189 | train loss 0.5554252918437124\n",
      "Epoch2190 | train loss 0.5554250049963594\n",
      "Epoch2191 | train loss 0.5554235439375043\n",
      "Epoch2192 | train loss 0.5554224939271808\n",
      "Epoch2193 | train loss 0.5554219668917358\n",
      "Epoch2194 | train loss 0.5554206551983952\n",
      "Epoch2195 | train loss 0.5554208447411656\n",
      "Epoch2196 | train loss 0.5554193207249045\n",
      "Epoch2197 | train loss 0.5554177479445934\n",
      "Epoch2198 | train loss 0.5554159855656325\n",
      "Epoch2199 | train loss 0.5554146245494485\n",
      "Epoch2200 | train loss 0.5554136173799634\n",
      "Epoch2201 | train loss 0.5554108077287674\n",
      "Epoch2202 | train loss 0.555409698151052\n",
      "Epoch2203 | train loss 0.5554072065651416\n",
      "Epoch2204 | train loss 0.5554048852436244\n",
      "Epoch2205 | train loss 0.5554047458618879\n",
      "Epoch2206 | train loss 0.5554027098231018\n",
      "Epoch2207 | train loss 0.5554022273235023\n",
      "Epoch2208 | train loss 0.5554002443142235\n",
      "Epoch2209 | train loss 0.5554004228115081\n",
      "Epoch2210 | train loss 0.5553994894213975\n",
      "Epoch2211 | train loss 0.5553974783793092\n",
      "Epoch2212 | train loss 0.5553967019915581\n",
      "Epoch2213 | train loss 0.5553955101966858\n",
      "Epoch2214 | train loss 0.555394586827606\n",
      "Epoch2215 | train loss 0.5553936907276511\n",
      "Epoch2216 | train loss 0.5553915453888476\n",
      "Epoch2217 | train loss 0.5553914001211524\n",
      "Epoch2218 | train loss 0.5553908416070044\n",
      "Epoch2219 | train loss 0.5553868351504206\n",
      "Epoch2220 | train loss 0.5553842994198203\n",
      "Epoch2221 | train loss 0.5553817822597921\n",
      "Epoch2222 | train loss 0.5553799377009273\n",
      "Epoch2223 | train loss 0.5553775619156659\n",
      "Epoch2224 | train loss 0.5553755193389952\n",
      "Epoch2225 | train loss 0.5553735565766692\n",
      "Epoch2226 | train loss 0.5553715856932103\n",
      "Epoch2227 | train loss 0.555369923133403\n",
      "Epoch2228 | train loss 0.5553682325966656\n",
      "Epoch2229 | train loss 0.5553666309826076\n",
      "Epoch2230 | train loss 0.5553654649481178\n",
      "Epoch2231 | train loss 0.5553635249100626\n",
      "Epoch2232 | train loss 0.5553618768043816\n",
      "Epoch2233 | train loss 0.5553608064353466\n",
      "Epoch2234 | train loss 0.555358064211905\n",
      "Epoch2235 | train loss 0.5553562115691603\n",
      "Epoch2236 | train loss 0.5553533636964858\n",
      "Epoch2237 | train loss 0.5553514104522764\n",
      "Epoch2238 | train loss 0.5553497962839902\n",
      "Epoch2239 | train loss 0.5553476555459201\n",
      "Epoch2240 | train loss 0.5553458402678371\n",
      "Epoch2241 | train loss 0.5553437495604158\n",
      "Epoch2242 | train loss 0.5553425842523575\n",
      "Epoch2243 | train loss 0.5553412345796823\n",
      "Epoch2244 | train loss 0.5553392845951021\n",
      "Epoch2245 | train loss 0.5553375995345413\n",
      "Epoch2246 | train loss 0.5553363640233875\n",
      "Epoch2247 | train loss 0.5553335618413985\n",
      "Epoch2248 | train loss 0.5553307891264558\n",
      "Epoch2249 | train loss 0.5553283061832189\n",
      "Epoch2250 | train loss 0.5553275596164167\n",
      "Epoch2251 | train loss 0.5553251873143017\n",
      "Epoch2252 | train loss 0.5553245031088591\n",
      "Epoch2253 | train loss 0.5553228241577745\n",
      "Epoch2254 | train loss 0.5553209269791841\n",
      "Epoch2255 | train loss 0.5553195579722524\n",
      "Epoch2256 | train loss 0.5553180831484497\n",
      "Epoch2257 | train loss 0.5553168237023055\n",
      "Epoch2258 | train loss 0.5553157110698521\n",
      "Epoch2259 | train loss 0.5553141947090626\n",
      "Epoch2260 | train loss 0.5553131150826812\n",
      "Epoch2261 | train loss 0.5553119479492307\n",
      "Epoch2262 | train loss 0.5553101317584515\n",
      "Epoch2263 | train loss 0.5553087607398629\n",
      "Epoch2264 | train loss 0.5553075592219829\n",
      "Epoch2265 | train loss 0.5553069004788995\n",
      "Epoch2266 | train loss 0.5553051049634814\n",
      "Epoch2267 | train loss 0.5553048016689718\n",
      "Epoch2268 | train loss 0.5553037343174219\n",
      "Epoch2269 | train loss 0.555302456151694\n",
      "Epoch2270 | train loss 0.5553017057292163\n",
      "Epoch2271 | train loss 0.5552996507100761\n",
      "Epoch2272 | train loss 0.5552995662018657\n",
      "Epoch2273 | train loss 0.55529750790447\n",
      "Epoch2274 | train loss 0.5552973920106887\n",
      "Epoch2275 | train loss 0.5552952744066715\n",
      "Epoch2276 | train loss 0.5552951252274215\n",
      "Epoch2277 | train loss 0.5552938505448402\n",
      "Epoch2278 | train loss 0.555292758718133\n",
      "Epoch2279 | train loss 0.5552916926331818\n",
      "Epoch2280 | train loss 0.5552899776212871\n",
      "Epoch2281 | train loss 0.555289920270443\n",
      "Epoch2282 | train loss 0.5552881560102105\n",
      "Epoch2283 | train loss 0.555287425480783\n",
      "Epoch2284 | train loss 0.5552865963429212\n",
      "Epoch2285 | train loss 0.555285410284996\n",
      "Epoch2286 | train loss 0.5552843500487507\n",
      "Epoch2287 | train loss 0.5552835724316537\n",
      "Epoch2288 | train loss 0.5552824120409787\n",
      "Epoch2289 | train loss 0.5552810424380005\n",
      "Epoch2290 | train loss 0.5552803172171116\n",
      "Epoch2291 | train loss 0.5552792683243751\n",
      "Epoch2292 | train loss 0.5552788938581944\n",
      "Epoch2293 | train loss 0.555276256557554\n",
      "Epoch2294 | train loss 0.5552762368135155\n",
      "Epoch2295 | train loss 0.5552756478637457\n",
      "Epoch2296 | train loss 0.5552746573463082\n",
      "Epoch2297 | train loss 0.5552722814679146\n",
      "Epoch2298 | train loss 0.5552726705931127\n",
      "Epoch2299 | train loss 0.5552715723961592\n",
      "Epoch2300 | train loss 0.5552718775905668\n",
      "Epoch2301 | train loss 0.5552690292894841\n",
      "Epoch2302 | train loss 0.5552675584331155\n",
      "Epoch2303 | train loss 0.55526661535725\n",
      "Epoch2304 | train loss 0.5552657341584564\n",
      "Epoch2305 | train loss 0.5552660545147955\n",
      "Epoch2306 | train loss 0.5552648954838514\n",
      "Epoch2307 | train loss 0.555263788215816\n",
      "Epoch2308 | train loss 0.5552627772651613\n",
      "Epoch2309 | train loss 0.5552610489726066\n",
      "Epoch2310 | train loss 0.5552608346194029\n",
      "Epoch2311 | train loss 0.5552587202563882\n",
      "Epoch2312 | train loss 0.5552574409171939\n",
      "Epoch2313 | train loss 0.5552579620853066\n",
      "Epoch2314 | train loss 0.5552569420821964\n",
      "Epoch2315 | train loss 0.5552555221505463\n",
      "Epoch2316 | train loss 0.555255009289831\n",
      "Epoch2317 | train loss 0.5552542150765657\n",
      "Epoch2318 | train loss 0.5552528209984302\n",
      "Epoch2319 | train loss 0.5552520227245986\n",
      "Epoch2320 | train loss 0.555251723434776\n",
      "Epoch2321 | train loss 0.5552505301125348\n",
      "Epoch2322 | train loss 0.5552485743537545\n",
      "Epoch2323 | train loss 0.5552485764026642\n",
      "Epoch2324 | train loss 0.5552476271241903\n",
      "Epoch2325 | train loss 0.5552469065599144\n",
      "Epoch2326 | train loss 0.5552456425502896\n",
      "Epoch2327 | train loss 0.5552449586242437\n",
      "Epoch2328 | train loss 0.5552440774068237\n",
      "Epoch2329 | train loss 0.5552430161088705\n",
      "Epoch2330 | train loss 0.5552423084899784\n",
      "Epoch2331 | train loss 0.5552414096146822\n",
      "Epoch2332 | train loss 0.5552403642982244\n",
      "Epoch2333 | train loss 0.5552396815642715\n",
      "Epoch2334 | train loss 0.5552389374002814\n",
      "Epoch2335 | train loss 0.5552380338869989\n",
      "Epoch2336 | train loss 0.555237099584192\n",
      "Epoch2337 | train loss 0.5552361170575023\n",
      "Epoch2338 | train loss 0.5552352439984679\n",
      "Epoch2339 | train loss 0.5552345590479671\n",
      "Epoch2340 | train loss 0.5552338498830796\n",
      "Epoch2341 | train loss 0.5552325803786516\n",
      "Epoch2342 | train loss 0.5552321634814144\n",
      "Epoch2343 | train loss 0.5552313261292875\n",
      "Epoch2344 | train loss 0.5552301944233478\n",
      "Epoch2345 | train loss 0.5552297532372177\n",
      "Epoch2346 | train loss 0.5552283238805831\n",
      "Epoch2347 | train loss 0.5552278615906835\n",
      "Epoch2348 | train loss 0.5552269086055458\n",
      "Epoch2349 | train loss 0.5552262233011425\n",
      "Epoch2350 | train loss 0.5552251150272787\n",
      "Epoch2351 | train loss 0.555224917717278\n",
      "Epoch2352 | train loss 0.5552241858467459\n",
      "Epoch2353 | train loss 0.5552241598814726\n",
      "Epoch2354 | train loss 0.5552220560051501\n",
      "Epoch2355 | train loss 0.5552216614037753\n",
      "Epoch2356 | train loss 0.5552207187190652\n",
      "Epoch2357 | train loss 0.5552197011373937\n",
      "Epoch2358 | train loss 0.5552191347256303\n",
      "Epoch2359 | train loss 0.5552174032106996\n",
      "Epoch2360 | train loss 0.5552169422060251\n",
      "Epoch2361 | train loss 0.5552168117836118\n",
      "Epoch2362 | train loss 0.5552176196314395\n",
      "Epoch2363 | train loss 0.5552145940624178\n",
      "Epoch2364 | train loss 0.5552138700522482\n",
      "Epoch2365 | train loss 0.5552132800966502\n",
      "Epoch2366 | train loss 0.5552128565125167\n",
      "Epoch2367 | train loss 0.5552133848704398\n",
      "Epoch2368 | train loss 0.5552110716700553\n",
      "Epoch2369 | train loss 0.5552100228331983\n",
      "Epoch2370 | train loss 0.555209988951683\n",
      "Epoch2371 | train loss 0.5552100015617907\n",
      "Epoch2372 | train loss 0.5552077582478523\n",
      "Epoch2373 | train loss 0.5552076964639128\n",
      "Epoch2374 | train loss 0.5552062351629138\n",
      "Epoch2375 | train loss 0.5552057369612158\n",
      "Epoch2376 | train loss 0.5552053958922625\n",
      "Epoch2377 | train loss 0.5552040475979447\n",
      "Epoch2378 | train loss 0.5552030669339001\n",
      "Epoch2379 | train loss 0.5552044000662864\n",
      "Epoch2380 | train loss 0.5552002605050802\n",
      "Epoch2381 | train loss 0.5552016169391573\n",
      "Epoch2382 | train loss 0.5552003612183034\n",
      "Epoch2383 | train loss 0.5551997892186046\n",
      "Epoch2384 | train loss 0.5551984122395516\n",
      "Epoch2385 | train loss 0.5551979581266642\n",
      "Epoch2386 | train loss 0.5551973021775484\n",
      "Epoch2387 | train loss 0.5551967023126781\n",
      "Epoch2388 | train loss 0.5551955652795733\n",
      "Epoch2389 | train loss 0.5551948729157448\n",
      "Epoch2390 | train loss 0.5551942178606987\n",
      "Epoch2391 | train loss 0.5551926743239164\n",
      "Epoch2392 | train loss 0.555192157421261\n",
      "Epoch2393 | train loss 0.5551914631202817\n",
      "Epoch2394 | train loss 0.5551900700852275\n",
      "Epoch2395 | train loss 0.5551902589760721\n",
      "Epoch2396 | train loss 0.5551891305297613\n",
      "Epoch2397 | train loss 0.5551876548677683\n",
      "Epoch2398 | train loss 0.5551883190870285\n",
      "Epoch2399 | train loss 0.555185396913439\n",
      "Epoch2400 | train loss 0.5551849612593651\n",
      "Epoch2401 | train loss 0.5551852997392416\n",
      "Epoch2402 | train loss 0.555183220449835\n",
      "Epoch2403 | train loss 0.5551833250001073\n",
      "Epoch2404 | train loss 0.5551825212500989\n",
      "Epoch2405 | train loss 0.555182258207351\n",
      "Epoch2406 | train loss 0.5551803585328162\n",
      "Epoch2407 | train loss 0.5551793120615184\n",
      "Epoch2408 | train loss 0.5551793028414249\n",
      "Epoch2409 | train loss 0.5551784442551434\n",
      "Epoch2410 | train loss 0.555178379882127\n",
      "Epoch2411 | train loss 0.5551768381148576\n",
      "Epoch2412 | train loss 0.5551763221621513\n",
      "Epoch2413 | train loss 0.5551757062040269\n",
      "Epoch2414 | train loss 0.5551745301485062\n",
      "Epoch2415 | train loss 0.555174604151398\n",
      "Epoch2416 | train loss 0.5551719193905592\n",
      "Epoch2417 | train loss 0.5551715859398246\n",
      "Epoch2418 | train loss 0.5551692994497717\n",
      "Epoch2419 | train loss 0.555168856922537\n",
      "Epoch2420 | train loss 0.5551672199554741\n",
      "Epoch2421 | train loss 0.5551647610031069\n",
      "Epoch2422 | train loss 0.5551661977544426\n",
      "Epoch2423 | train loss 0.5551641007699072\n",
      "Epoch2424 | train loss 0.5551616550236941\n",
      "Epoch2425 | train loss 0.5551614774018526\n",
      "Epoch2426 | train loss 0.555160718653351\n",
      "Epoch2427 | train loss 0.5551594780758023\n",
      "Epoch2428 | train loss 0.555158416684717\n",
      "Epoch2429 | train loss 0.5551554359123111\n",
      "Epoch2430 | train loss 0.5551548095420002\n",
      "Epoch2431 | train loss 0.5551539388298988\n",
      "Epoch2432 | train loss 0.5551537022925913\n",
      "Epoch2433 | train loss 0.5551515585556627\n",
      "Epoch2434 | train loss 0.5551486979797482\n",
      "Epoch2435 | train loss 0.5551460999436677\n",
      "Epoch2436 | train loss 0.5551434653624893\n",
      "Epoch2437 | train loss 0.5551419503428042\n",
      "Epoch2438 | train loss 0.5551408942230046\n",
      "Epoch2439 | train loss 0.5551395428366959\n",
      "Epoch2440 | train loss 0.5551382058113813\n",
      "Epoch2441 | train loss 0.5551367438770831\n",
      "Epoch2442 | train loss 0.5551335427351296\n",
      "Epoch2443 | train loss 0.5551343649998307\n",
      "Epoch2444 | train loss 0.5551318789459765\n",
      "Epoch2445 | train loss 0.5551310201175511\n",
      "Epoch2446 | train loss 0.5551292882300913\n",
      "Epoch2447 | train loss 0.5551271932013333\n",
      "Epoch2448 | train loss 0.5551243611052632\n",
      "Epoch2449 | train loss 0.5551219908148051\n",
      "Epoch2450 | train loss 0.5551183194108308\n",
      "Epoch2451 | train loss 0.5551133701205253\n",
      "Epoch2452 | train loss 0.5551100407168269\n",
      "Epoch2453 | train loss 0.5551071308739484\n",
      "Epoch2454 | train loss 0.5551030831970274\n",
      "Epoch2455 | train loss 0.5551009092852474\n",
      "Epoch2456 | train loss 0.5550985424406827\n",
      "Epoch2457 | train loss 0.5550947687774896\n",
      "Epoch2458 | train loss 0.555094157755375\n",
      "Epoch2459 | train loss 0.5550911218114197\n",
      "Epoch2460 | train loss 0.5550882741063833\n",
      "Epoch2461 | train loss 0.5550868391618132\n",
      "Epoch2462 | train loss 0.5550855059735477\n",
      "Epoch2463 | train loss 0.5550828948244453\n",
      "Epoch2464 | train loss 0.5550820417702198\n",
      "Epoch2465 | train loss 0.5550793365947903\n",
      "Epoch2466 | train loss 0.5550781340152026\n",
      "Epoch2467 | train loss 0.5550773657485842\n",
      "Epoch2468 | train loss 0.555075151771307\n",
      "Epoch2469 | train loss 0.5550737307593226\n",
      "Epoch2470 | train loss 0.5550727481767536\n",
      "Epoch2471 | train loss 0.5550721381232142\n",
      "Epoch2472 | train loss 0.5550697086751462\n",
      "Epoch2473 | train loss 0.5550688580051064\n",
      "Epoch2474 | train loss 0.5550672390125692\n",
      "Epoch2475 | train loss 0.5550651363097131\n",
      "Epoch2476 | train loss 0.5550635478645564\n",
      "Epoch2477 | train loss 0.55506252521649\n",
      "Epoch2478 | train loss 0.5550607155449688\n",
      "Epoch2479 | train loss 0.5550590052083134\n",
      "Epoch2480 | train loss 0.5550582323409617\n",
      "Epoch2481 | train loss 0.5550564824417233\n",
      "Epoch2482 | train loss 0.5550559530407191\n",
      "Epoch2483 | train loss 0.5550536719895899\n",
      "Epoch2484 | train loss 0.5550532500818371\n",
      "Epoch2485 | train loss 0.5550513174198568\n",
      "Epoch2486 | train loss 0.5550495989806951\n",
      "Epoch2487 | train loss 0.5550490759313107\n",
      "Epoch2488 | train loss 0.5550463934242725\n",
      "Epoch2489 | train loss 0.5550460437312722\n",
      "Epoch2490 | train loss 0.5550447032041848\n",
      "Epoch2491 | train loss 0.5550407102145255\n",
      "Epoch2492 | train loss 0.5550419626012445\n",
      "Epoch2493 | train loss 0.5550373159535229\n",
      "Epoch2494 | train loss 0.5550305188260972\n",
      "Epoch2495 | train loss 0.5550236428715288\n",
      "Epoch2496 | train loss 0.5550180511921644\n",
      "Epoch2497 | train loss 0.5550151092559099\n",
      "Epoch2498 | train loss 0.555007359571755\n",
      "Epoch2499 | train loss 0.5550024550780654\n",
      "Epoch2500 | train loss 0.5549953766167164\n",
      "Epoch2501 | train loss 0.5549902826920152\n",
      "Epoch2502 | train loss 0.5549830008670688\n",
      "Epoch2503 | train loss 0.5549765402637422\n",
      "Epoch2504 | train loss 0.5549689796380699\n",
      "Epoch2505 | train loss 0.5549637703970075\n",
      "Epoch2506 | train loss 0.5549566372856498\n",
      "Epoch2507 | train loss 0.554949631113559\n",
      "Epoch2508 | train loss 0.554942365642637\n",
      "Epoch2509 | train loss 0.5549360723420977\n",
      "Epoch2510 | train loss 0.5549263962730765\n",
      "Epoch2511 | train loss 0.5549168889783322\n",
      "Epoch2512 | train loss 0.554911266155541\n",
      "Epoch2513 | train loss 0.5549041109718382\n",
      "Epoch2514 | train loss 0.5548972297459841\n",
      "Epoch2515 | train loss 0.5548888740316034\n",
      "Epoch2516 | train loss 0.5548792197927832\n",
      "Epoch2517 | train loss 0.5548716549016536\n",
      "Epoch2518 | train loss 0.5548642627894879\n",
      "Epoch2519 | train loss 0.5548586325906217\n",
      "Epoch2520 | train loss 0.5548531886190176\n",
      "Epoch2521 | train loss 0.5548463888280094\n",
      "Epoch2522 | train loss 0.5548429425805808\n",
      "Epoch2523 | train loss 0.5548364548385143\n",
      "Epoch2524 | train loss 0.5548314258828759\n",
      "Epoch2525 | train loss 0.5548268073610961\n",
      "Epoch2526 | train loss 0.5548231777176261\n",
      "Epoch2527 | train loss 0.5548183250054717\n",
      "Epoch2528 | train loss 0.5548131173849106\n",
      "Epoch2529 | train loss 0.554809307269752\n",
      "Epoch2530 | train loss 0.5548044104501605\n",
      "Epoch2531 | train loss 0.5547999633476138\n",
      "Epoch2532 | train loss 0.5547959470376372\n",
      "Epoch2533 | train loss 0.5547924051061273\n",
      "Epoch2534 | train loss 0.5547887869179249\n",
      "Epoch2535 | train loss 0.554786164034158\n",
      "Epoch2536 | train loss 0.5547828249633312\n",
      "Epoch2537 | train loss 0.5547784095816314\n",
      "Epoch2538 | train loss 0.5547732300683856\n",
      "Epoch2539 | train loss 0.554769991915673\n",
      "Epoch2540 | train loss 0.5547667188569904\n",
      "Epoch2541 | train loss 0.5547634401544929\n",
      "Epoch2542 | train loss 0.5547606071829796\n",
      "Epoch2543 | train loss 0.55475605327636\n",
      "Epoch2544 | train loss 0.5547536781616509\n",
      "Epoch2545 | train loss 0.5547499582543969\n",
      "Epoch2546 | train loss 0.5547463062778115\n",
      "Epoch2547 | train loss 0.5547430724091827\n",
      "Epoch2548 | train loss 0.5547400965169073\n",
      "Epoch2549 | train loss 0.554736664518714\n",
      "Epoch2550 | train loss 0.5547338100150228\n",
      "Epoch2551 | train loss 0.5547319066524505\n",
      "Epoch2552 | train loss 0.554728607647121\n",
      "Epoch2553 | train loss 0.5547259422391653\n",
      "Epoch2554 | train loss 0.5547227745689451\n",
      "Epoch2555 | train loss 0.5547214803099633\n",
      "Epoch2556 | train loss 0.554718166962266\n",
      "Epoch2557 | train loss 0.5547160281054676\n",
      "Epoch2558 | train loss 0.5547139547020197\n",
      "Epoch2559 | train loss 0.5547118176147342\n",
      "Epoch2560 | train loss 0.554709496255964\n",
      "Epoch2561 | train loss 0.5547064151056111\n",
      "Epoch2562 | train loss 0.554701456669718\n",
      "Epoch2563 | train loss 0.554699223395437\n",
      "Epoch2564 | train loss 0.5546956085599959\n",
      "Epoch2565 | train loss 0.554693038277328\n",
      "Epoch2566 | train loss 0.5546893490850926\n",
      "Epoch2567 | train loss 0.5546863405592739\n",
      "Epoch2568 | train loss 0.5546841402351856\n",
      "Epoch2569 | train loss 0.5546811564825476\n",
      "Epoch2570 | train loss 0.5546785805374383\n",
      "Epoch2571 | train loss 0.5546760892681778\n",
      "Epoch2572 | train loss 0.5546736105903983\n",
      "Epoch2573 | train loss 0.5546713283285498\n",
      "Epoch2574 | train loss 0.5546688398718834\n",
      "Epoch2575 | train loss 0.5546667055040598\n",
      "Epoch2576 | train loss 0.5546643700636923\n",
      "Epoch2577 | train loss 0.5546620716899633\n",
      "Epoch2578 | train loss 0.5546597989089787\n",
      "Epoch2579 | train loss 0.5546574345603585\n",
      "Epoch2580 | train loss 0.5546553956717253\n",
      "Epoch2581 | train loss 0.5546532128565014\n",
      "Epoch2582 | train loss 0.5546515044756234\n",
      "Epoch2583 | train loss 0.5546496440283954\n",
      "Epoch2584 | train loss 0.5546474893018604\n",
      "Epoch2585 | train loss 0.5546453006379306\n",
      "Epoch2586 | train loss 0.5546437465772033\n",
      "Epoch2587 | train loss 0.5546419529058039\n",
      "Epoch2588 | train loss 0.5546400120668113\n",
      "Epoch2589 | train loss 0.5546376753970981\n",
      "Epoch2590 | train loss 0.5546358642540872\n",
      "Epoch2591 | train loss 0.55463328467682\n",
      "Epoch2592 | train loss 0.5546305701136589\n",
      "Epoch2593 | train loss 0.554627842605114\n",
      "Epoch2594 | train loss 0.5546265155263245\n",
      "Epoch2595 | train loss 0.5546247249655426\n",
      "Epoch2596 | train loss 0.5546222593262792\n",
      "Epoch2597 | train loss 0.5546204002201557\n",
      "Epoch2598 | train loss 0.5546189389377832\n",
      "Epoch2599 | train loss 0.5546168432757258\n",
      "Epoch2600 | train loss 0.5546144222840667\n",
      "Epoch2601 | train loss 0.554611778743565\n",
      "Epoch2602 | train loss 0.5546091753058136\n",
      "Epoch2603 | train loss 0.5546050948090852\n",
      "Epoch2604 | train loss 0.5546032303757965\n",
      "Epoch2605 | train loss 0.5546011504530907\n",
      "Epoch2606 | train loss 0.5545977247320115\n",
      "Epoch2607 | train loss 0.5545937081612646\n",
      "Epoch2608 | train loss 0.5545907482691109\n",
      "Epoch2609 | train loss 0.5545894177444279\n",
      "Epoch2610 | train loss 0.5545856783911586\n",
      "Epoch2611 | train loss 0.5545798877626658\n",
      "Epoch2612 | train loss 0.5545752704702318\n",
      "Epoch2613 | train loss 0.5545707975327968\n",
      "Epoch2614 | train loss 0.5545662800595165\n",
      "Epoch2615 | train loss 0.5545623858273029\n",
      "Epoch2616 | train loss 0.5545580639317632\n",
      "Epoch2617 | train loss 0.5545544733293355\n",
      "Epoch2618 | train loss 0.5545513042993844\n",
      "Epoch2619 | train loss 0.5545483529381454\n",
      "Epoch2620 | train loss 0.554545240662992\n",
      "Epoch2621 | train loss 0.5545434336736799\n",
      "Epoch2622 | train loss 0.5545392338559032\n",
      "Epoch2623 | train loss 0.5545376483909785\n",
      "Epoch2624 | train loss 0.5545335426554083\n",
      "Epoch2625 | train loss 0.5545328481867909\n",
      "Epoch2626 | train loss 0.5545288532041013\n",
      "Epoch2627 | train loss 0.55452805807814\n",
      "Epoch2628 | train loss 0.5545257402583956\n",
      "Epoch2629 | train loss 0.5545234625786543\n",
      "Epoch2630 | train loss 0.5545208756066858\n",
      "Epoch2631 | train loss 0.5545189132913947\n",
      "Epoch2632 | train loss 0.5545149263180792\n",
      "Epoch2633 | train loss 0.5545143285766244\n",
      "Epoch2634 | train loss 0.5545119709149003\n",
      "Epoch2635 | train loss 0.5545097263343632\n",
      "Epoch2636 | train loss 0.5545070621743798\n",
      "Epoch2637 | train loss 0.55450609235093\n",
      "Epoch2638 | train loss 0.5545041000656784\n",
      "Epoch2639 | train loss 0.5545013741403818\n",
      "Epoch2640 | train loss 0.5544969226792454\n",
      "Epoch2641 | train loss 0.5544949881359935\n",
      "Epoch2642 | train loss 0.554494411945343\n",
      "Epoch2643 | train loss 0.5544903265684843\n",
      "Epoch2644 | train loss 0.5544903246685863\n",
      "Epoch2645 | train loss 0.5544871620647609\n",
      "Epoch2646 | train loss 0.554487014003098\n",
      "Epoch2647 | train loss 0.5544848474673927\n",
      "Epoch2648 | train loss 0.5544811573624611\n",
      "Epoch2649 | train loss 0.5544809271767736\n",
      "Epoch2650 | train loss 0.5544783793389797\n",
      "Epoch2651 | train loss 0.5544739927910268\n",
      "Epoch2652 | train loss 0.5544741329364479\n",
      "Epoch2653 | train loss 0.5544717481918633\n",
      "Epoch2654 | train loss 0.554470196813345\n",
      "Epoch2655 | train loss 0.5544679773971438\n",
      "Epoch2656 | train loss 0.5544664595834911\n",
      "Epoch2657 | train loss 0.5544645160622895\n",
      "Epoch2658 | train loss 0.5544624648801982\n",
      "Epoch2659 | train loss 0.5544607415236533\n",
      "Epoch2660 | train loss 0.5544587719067932\n",
      "Epoch2661 | train loss 0.5544573763385415\n",
      "Epoch2662 | train loss 0.5544549398683012\n",
      "Epoch2663 | train loss 0.5544538822211326\n",
      "Epoch2664 | train loss 0.5544517729058862\n",
      "Epoch2665 | train loss 0.5544501694664359\n",
      "Epoch2666 | train loss 0.5544481265544892\n",
      "Epoch2667 | train loss 0.554446417633444\n",
      "Epoch2668 | train loss 0.5544446153566241\n",
      "Epoch2669 | train loss 0.5544428526610136\n",
      "Epoch2670 | train loss 0.554441479574889\n",
      "Epoch2671 | train loss 0.5544394174031914\n",
      "Epoch2672 | train loss 0.5544381908327342\n",
      "Epoch2673 | train loss 0.5544362502358854\n",
      "Epoch2674 | train loss 0.5544342020899058\n",
      "Epoch2675 | train loss 0.5544327816739678\n",
      "Epoch2676 | train loss 0.5544306496344507\n",
      "Epoch2677 | train loss 0.5544299660809338\n",
      "Epoch2678 | train loss 0.554428005926311\n",
      "Epoch2679 | train loss 0.5544259376078844\n",
      "Epoch2680 | train loss 0.5544245915301144\n",
      "Epoch2681 | train loss 0.554424375295639\n",
      "Epoch2682 | train loss 0.5544214873202145\n",
      "Epoch2683 | train loss 0.55441968543455\n",
      "Epoch2684 | train loss 0.5544187366217375\n",
      "Epoch2685 | train loss 0.5544139655679464\n",
      "Epoch2686 | train loss 0.5544133543036878\n",
      "Epoch2687 | train loss 0.5544105081260204\n",
      "Epoch2688 | train loss 0.5544066160544753\n",
      "Epoch2689 | train loss 0.5544055243209004\n",
      "Epoch2690 | train loss 0.554404408633709\n",
      "Epoch2691 | train loss 0.5544014953263104\n",
      "Epoch2692 | train loss 0.554400153234601\n",
      "Epoch2693 | train loss 0.5543996726348996\n",
      "Epoch2694 | train loss 0.5543970216065646\n",
      "Epoch2695 | train loss 0.5543950469233095\n",
      "Epoch2696 | train loss 0.5543940202333033\n",
      "Epoch2697 | train loss 0.5543917600996793\n",
      "Epoch2698 | train loss 0.5543904997035861\n",
      "Epoch2699 | train loss 0.5543895561806857\n",
      "Epoch2700 | train loss 0.554387535378337\n",
      "Epoch2701 | train loss 0.5543860957957805\n",
      "Epoch2702 | train loss 0.5543845337629318\n",
      "Epoch2703 | train loss 0.554383358526975\n",
      "Epoch2704 | train loss 0.5543819858878851\n",
      "Epoch2705 | train loss 0.5543809087015689\n",
      "Epoch2706 | train loss 0.5543786421045661\n",
      "Epoch2707 | train loss 0.554377454277128\n",
      "Epoch2708 | train loss 0.5543756296485662\n",
      "Epoch2709 | train loss 0.5543741742521524\n",
      "Epoch2710 | train loss 0.554372425712645\n",
      "Epoch2711 | train loss 0.5543695033341646\n",
      "Epoch2712 | train loss 0.5543674314953386\n",
      "Epoch2713 | train loss 0.554365427289158\n",
      "Epoch2714 | train loss 0.5543634109012783\n",
      "Epoch2715 | train loss 0.5543614917434752\n",
      "Epoch2716 | train loss 0.5543605392053723\n",
      "Epoch2717 | train loss 0.5543589640595019\n",
      "Epoch2718 | train loss 0.5543573818355799\n",
      "Epoch2719 | train loss 0.5543562220595777\n",
      "Epoch2720 | train loss 0.5543545010313392\n",
      "Epoch2721 | train loss 0.5543533658608795\n",
      "Epoch2722 | train loss 0.5543519856780768\n",
      "Epoch2723 | train loss 0.5543503728881478\n",
      "Epoch2724 | train loss 0.5543492217548192\n",
      "Epoch2725 | train loss 0.5543479952961207\n",
      "Epoch2726 | train loss 0.5543468217737972\n",
      "Epoch2727 | train loss 0.5543448477238416\n",
      "Epoch2728 | train loss 0.5543441406451166\n",
      "Epoch2729 | train loss 0.5543430784344673\n",
      "Epoch2730 | train loss 0.5543416448496282\n",
      "Epoch2731 | train loss 0.5543393807299435\n",
      "Epoch2732 | train loss 0.5543369914032519\n",
      "Epoch2733 | train loss 0.5543353587761521\n",
      "Epoch2734 | train loss 0.5543343115784228\n",
      "Epoch2735 | train loss 0.554332171715796\n",
      "Epoch2736 | train loss 0.5543303198739886\n",
      "Epoch2737 | train loss 0.5543285257928073\n",
      "Epoch2738 | train loss 0.5543282125145197\n",
      "Epoch2739 | train loss 0.5543255151249469\n",
      "Epoch2740 | train loss 0.5543244352936745\n",
      "Epoch2741 | train loss 0.554322212524712\n",
      "Epoch2742 | train loss 0.5543205259554088\n",
      "Epoch2743 | train loss 0.5543195921555162\n",
      "Epoch2744 | train loss 0.5543177115730942\n",
      "Epoch2745 | train loss 0.5543163882941008\n",
      "Epoch2746 | train loss 0.5543148630857467\n",
      "Epoch2747 | train loss 0.5543128550238907\n",
      "Epoch2748 | train loss 0.5543123979493976\n",
      "Epoch2749 | train loss 0.5543094846606255\n",
      "Epoch2750 | train loss 0.5543096379190683\n",
      "Epoch2751 | train loss 0.5543110711686313\n",
      "Epoch2752 | train loss 0.554305649921298\n",
      "Epoch2753 | train loss 0.5543045265041292\n",
      "Epoch2754 | train loss 0.5543043382652104\n",
      "Epoch2755 | train loss 0.5543058318644762\n",
      "Epoch2756 | train loss 0.5543003938160836\n",
      "Epoch2757 | train loss 0.5543003889918328\n",
      "Epoch2758 | train loss 0.5543016640283167\n",
      "Epoch2759 | train loss 0.5542966968007386\n",
      "Epoch2760 | train loss 0.5542975207976997\n",
      "Epoch2761 | train loss 0.5542954556457699\n",
      "Epoch2762 | train loss 0.554294485040009\n",
      "Epoch2763 | train loss 0.5542963934876025\n",
      "Epoch2764 | train loss 0.5542912940494716\n",
      "Epoch2765 | train loss 0.554291518367827\n",
      "Epoch2766 | train loss 0.55428929772228\n",
      "Epoch2767 | train loss 0.5542921428382397\n",
      "Epoch2768 | train loss 0.5542863185890019\n",
      "Epoch2769 | train loss 0.5542865275405348\n",
      "Epoch2770 | train loss 0.5542883489467204\n",
      "Epoch2771 | train loss 0.5542829705961049\n",
      "Epoch2772 | train loss 0.5542831874452532\n",
      "Epoch2773 | train loss 0.5542854538187385\n",
      "Epoch2774 | train loss 0.5542795414291323\n",
      "Epoch2775 | train loss 0.5542790542170405\n",
      "Epoch2776 | train loss 0.5542830975167453\n",
      "Epoch2777 | train loss 0.5542758890800178\n",
      "Epoch2778 | train loss 0.5542756715044379\n",
      "Epoch2779 | train loss 0.5542794021591544\n",
      "Epoch2780 | train loss 0.554272977784276\n",
      "Epoch2781 | train loss 0.5542727573029697\n",
      "Epoch2782 | train loss 0.5542753687314689\n",
      "Epoch2783 | train loss 0.5542693717777729\n",
      "Epoch2784 | train loss 0.5542738461494445\n",
      "Epoch2785 | train loss 0.5542674427852035\n",
      "Epoch2786 | train loss 0.5542707967199385\n",
      "Epoch2787 | train loss 0.5542647178284824\n",
      "Epoch2788 | train loss 0.5542678229510785\n",
      "Epoch2789 | train loss 0.5542655756883323\n",
      "Epoch2790 | train loss 0.5542639509402215\n",
      "Epoch2791 | train loss 0.5542623329348862\n",
      "Epoch2792 | train loss 0.5542572163417936\n",
      "Epoch2793 | train loss 0.5542595308460295\n",
      "Epoch2794 | train loss 0.5542579859681428\n",
      "Epoch2795 | train loss 0.5542526124045253\n",
      "Epoch2796 | train loss 0.5542543317750096\n",
      "Epoch2797 | train loss 0.5542491000331938\n",
      "Epoch2798 | train loss 0.5542501346580684\n",
      "Epoch2799 | train loss 0.5542444608360529\n",
      "Epoch2800 | train loss 0.5542437320575118\n",
      "Epoch2801 | train loss 0.5542440561577677\n",
      "Epoch2802 | train loss 0.5542416694387794\n",
      "Epoch2803 | train loss 0.5542401770502329\n",
      "Epoch2804 | train loss 0.554238264542073\n",
      "Epoch2805 | train loss 0.5542350222356618\n",
      "Epoch2806 | train loss 0.5542325418069959\n",
      "Epoch2807 | train loss 0.5542260358668863\n",
      "Epoch2808 | train loss 0.5542286439612508\n",
      "Epoch2809 | train loss 0.5542256260849535\n",
      "Epoch2810 | train loss 0.5542237129434944\n",
      "Epoch2811 | train loss 0.5542229758016766\n",
      "Epoch2812 | train loss 0.5542188930138946\n",
      "Epoch2813 | train loss 0.5542178865335882\n",
      "Epoch2814 | train loss 0.5542169697396457\n",
      "Epoch2815 | train loss 0.5542117735557258\n",
      "Epoch2816 | train loss 0.5542132023349404\n",
      "Epoch2817 | train loss 0.5542114984616637\n",
      "Epoch2818 | train loss 0.5542098424397409\n",
      "Epoch2819 | train loss 0.5542092630639672\n",
      "Epoch2820 | train loss 0.5542027287371457\n",
      "Epoch2821 | train loss 0.5542057063989341\n",
      "Epoch2822 | train loss 0.5542036748863757\n",
      "Epoch2823 | train loss 0.5541987574286759\n",
      "Epoch2824 | train loss 0.554201990570873\n",
      "Epoch2825 | train loss 0.5541958658955991\n",
      "Epoch2826 | train loss 0.5541972672007978\n",
      "Epoch2827 | train loss 0.554195553008467\n",
      "Epoch2828 | train loss 0.5541947539523244\n",
      "Epoch2829 | train loss 0.5541929525323213\n",
      "Epoch2830 | train loss 0.5541920760087669\n",
      "Epoch2831 | train loss 0.5541899514012039\n",
      "Epoch2832 | train loss 0.5541856523044407\n",
      "Epoch2833 | train loss 0.5541881449893117\n",
      "Epoch2834 | train loss 0.5541854161210358\n",
      "Epoch2835 | train loss 0.5541854380071163\n",
      "Epoch2836 | train loss 0.5541845832206309\n",
      "Epoch2837 | train loss 0.5541814061254263\n",
      "Epoch2838 | train loss 0.554181521628052\n",
      "Epoch2839 | train loss 0.5541798862628639\n",
      "Epoch2840 | train loss 0.5541783939488232\n",
      "Epoch2841 | train loss 0.5541778515465557\n",
      "Epoch2842 | train loss 0.5541749822907149\n",
      "Epoch2843 | train loss 0.5541749512776732\n",
      "Epoch2844 | train loss 0.5541737153381109\n",
      "Epoch2845 | train loss 0.5541713748686016\n",
      "Epoch2846 | train loss 0.55417087206617\n",
      "Epoch2847 | train loss 0.5541701026633382\n",
      "Epoch2848 | train loss 0.5541684490069747\n",
      "Epoch2849 | train loss 0.5541667412035167\n",
      "Epoch2850 | train loss 0.5541666123829782\n",
      "Epoch2851 | train loss 0.5541655302792787\n",
      "Epoch2852 | train loss 0.5541626407019794\n",
      "Epoch2853 | train loss 0.5541628255695105\n",
      "Epoch2854 | train loss 0.5541615605354309\n",
      "Epoch2855 | train loss 0.5541600425541401\n",
      "Epoch2856 | train loss 0.5541588221117855\n",
      "Epoch2857 | train loss 0.5541578068956733\n",
      "Epoch2858 | train loss 0.5541564638912678\n",
      "Epoch2859 | train loss 0.5541553836502134\n",
      "Epoch2860 | train loss 0.5541544711589813\n",
      "Epoch2861 | train loss 0.5541528586670756\n",
      "Epoch2862 | train loss 0.5541521245799959\n",
      "Epoch2863 | train loss 0.5541505791060627\n",
      "Epoch2864 | train loss 0.5541502505168319\n",
      "Epoch2865 | train loss 0.5541487010382116\n",
      "Epoch2866 | train loss 0.5541478406637907\n",
      "Epoch2867 | train loss 0.5541462080925703\n",
      "Epoch2868 | train loss 0.5541457056440413\n",
      "Epoch2869 | train loss 0.5541441314294935\n",
      "Epoch2870 | train loss 0.5541434337757528\n",
      "Epoch2871 | train loss 0.5541426850855351\n",
      "Epoch2872 | train loss 0.5541416261903942\n",
      "Epoch2873 | train loss 0.5541399365291\n",
      "Epoch2874 | train loss 0.5541389200091362\n",
      "Epoch2875 | train loss 0.5541384565830231\n",
      "Epoch2876 | train loss 0.5541372140683234\n",
      "Epoch2877 | train loss 0.5541365779377521\n",
      "Epoch2878 | train loss 0.5541350758634508\n",
      "Epoch2879 | train loss 0.5541347209364176\n",
      "Epoch2880 | train loss 0.5541330794245005\n",
      "Epoch2881 | train loss 0.554132076650858\n",
      "Epoch2882 | train loss 0.554131575152278\n",
      "Epoch2883 | train loss 0.5541301071643829\n",
      "Epoch2884 | train loss 0.5541298944875598\n",
      "Epoch2885 | train loss 0.5541281622089446\n",
      "Epoch2886 | train loss 0.5541272279061377\n",
      "Epoch2887 | train loss 0.554126729182899\n",
      "Epoch2888 | train loss 0.5541252246312797\n",
      "Epoch2889 | train loss 0.5541242542490363\n",
      "Epoch2890 | train loss 0.5541238272190094\n",
      "Epoch2891 | train loss 0.5541228198073804\n",
      "Epoch2892 | train loss 0.5541219344176352\n",
      "Epoch2893 | train loss 0.5541205593012273\n",
      "Epoch2894 | train loss 0.5541201956570149\n",
      "Epoch2895 | train loss 0.5541190169937908\n",
      "Epoch2896 | train loss 0.5541183710098266\n",
      "Epoch2897 | train loss 0.5541169460117817\n",
      "Epoch2898 | train loss 0.5541164174675941\n",
      "Epoch2899 | train loss 0.5541147638857364\n",
      "Epoch2900 | train loss 0.5541137384064495\n",
      "Epoch2901 | train loss 0.554112270977348\n",
      "Epoch2902 | train loss 0.5541115535795689\n",
      "Epoch2903 | train loss 0.554110134318471\n",
      "Epoch2904 | train loss 0.5541098135523498\n",
      "Epoch2905 | train loss 0.5541084390133619\n",
      "Epoch2906 | train loss 0.5541078899800778\n",
      "Epoch2907 | train loss 0.5541062812879681\n",
      "Epoch2908 | train loss 0.5541054823249578\n",
      "Epoch2909 | train loss 0.5541050842776895\n",
      "Epoch2910 | train loss 0.5541040269099176\n",
      "Epoch2911 | train loss 0.5541027541272342\n",
      "Epoch2912 | train loss 0.5541014120914042\n",
      "Epoch2913 | train loss 0.5541010115295648\n",
      "Epoch2914 | train loss 0.5540996045991778\n",
      "Epoch2915 | train loss 0.5540991612337529\n",
      "Epoch2916 | train loss 0.5540979245118797\n",
      "Epoch2917 | train loss 0.5540970130637288\n",
      "Epoch2918 | train loss 0.5540958899818361\n",
      "Epoch2919 | train loss 0.554095133189112\n",
      "Epoch2920 | train loss 0.5540943199954927\n",
      "Epoch2921 | train loss 0.5540932112187147\n",
      "Epoch2922 | train loss 0.5540930387564004\n",
      "Epoch2923 | train loss 0.5540918222814798\n",
      "Epoch2924 | train loss 0.5540904324315489\n",
      "Epoch2925 | train loss 0.5540908449701964\n",
      "Epoch2926 | train loss 0.5540891879051923\n",
      "Epoch2927 | train loss 0.5540889297425747\n",
      "Epoch2928 | train loss 0.5540874733775855\n",
      "Epoch2929 | train loss 0.5540872101671994\n",
      "Epoch2930 | train loss 0.5540868058428168\n",
      "Epoch2931 | train loss 0.5540849477611482\n",
      "Epoch2932 | train loss 0.5540848647989333\n",
      "Epoch2933 | train loss 0.5540831010974944\n",
      "Epoch2934 | train loss 0.5540819009579718\n",
      "Epoch2935 | train loss 0.5540818410366773\n",
      "Epoch2936 | train loss 0.554081085473299\n",
      "Epoch2937 | train loss 0.5540796719305218\n",
      "Epoch2938 | train loss 0.554078822452575\n",
      "Epoch2939 | train loss 0.5540778066776693\n",
      "Epoch2940 | train loss 0.5540771255455911\n",
      "Epoch2941 | train loss 0.5540764813125133\n",
      "Epoch2942 | train loss 0.5540750684775412\n",
      "Epoch2943 | train loss 0.5540747161395848\n",
      "Epoch2944 | train loss 0.5540735636092723\n",
      "Epoch2945 | train loss 0.5540721581690013\n",
      "Epoch2946 | train loss 0.5540719558484852\n",
      "Epoch2947 | train loss 0.5540710428357124\n",
      "Epoch2948 | train loss 0.5540694753080606\n",
      "Epoch2949 | train loss 0.5540657822042704\n",
      "Epoch2950 | train loss 0.5540643773414194\n",
      "Epoch2951 | train loss 0.5540646856836975\n",
      "Epoch2952 | train loss 0.5540645639225841\n",
      "Epoch2953 | train loss 0.5540632188692689\n",
      "Epoch2954 | train loss 0.5540637593530119\n",
      "Epoch2955 | train loss 0.554060955569148\n",
      "Epoch2956 | train loss 0.5540613265149296\n",
      "Epoch2957 | train loss 0.5540600677207113\n",
      "Epoch2958 | train loss 0.5540596443414688\n",
      "Epoch2959 | train loss 0.5540586405992508\n",
      "Epoch2960 | train loss 0.5540570380538702\n",
      "Epoch2961 | train loss 0.5540570777282119\n",
      "Epoch2962 | train loss 0.5540556992590427\n",
      "Epoch2963 | train loss 0.5540555298142135\n",
      "Epoch2964 | train loss 0.5540539213642478\n",
      "Epoch2965 | train loss 0.5540529611520469\n",
      "Epoch2966 | train loss 0.554053190741688\n",
      "Epoch2967 | train loss 0.5540524601750075\n",
      "Epoch2968 | train loss 0.5540502029471099\n",
      "Epoch2969 | train loss 0.5540499502234161\n",
      "Epoch2970 | train loss 0.5540494772419333\n",
      "Epoch2971 | train loss 0.5540480531565845\n",
      "Epoch2972 | train loss 0.554047803003341\n",
      "Epoch2973 | train loss 0.5540464269556105\n",
      "Epoch2974 | train loss 0.5540462762489915\n",
      "Epoch2975 | train loss 0.5540466636605561\n",
      "Epoch2976 | train loss 0.5540441900491715\n",
      "Epoch2977 | train loss 0.554043155964464\n",
      "Epoch2978 | train loss 0.5540428091958165\n",
      "Epoch2979 | train loss 0.5540420505031943\n",
      "Epoch2980 | train loss 0.5540425151959062\n",
      "Epoch2981 | train loss 0.5540410869196057\n",
      "Epoch2982 | train loss 0.5540392533689737\n",
      "Epoch2983 | train loss 0.5540398567728698\n",
      "Epoch2984 | train loss 0.5540383884124458\n",
      "Epoch2985 | train loss 0.5540379799157381\n",
      "Epoch2986 | train loss 0.5540365997701884\n",
      "Epoch2987 | train loss 0.5540357126668095\n",
      "Epoch2988 | train loss 0.5540352895669639\n",
      "Epoch2989 | train loss 0.5540338856726885\n",
      "Epoch2990 | train loss 0.5540347165428102\n",
      "Epoch2991 | train loss 0.5540333590842783\n",
      "Epoch2992 | train loss 0.5540319619327784\n",
      "Epoch2993 | train loss 0.5540312199853361\n",
      "Epoch2994 | train loss 0.5540303074009717\n",
      "Epoch2995 | train loss 0.5540302641317248\n",
      "Epoch2996 | train loss 0.5540288001298904\n",
      "Epoch2997 | train loss 0.5540283328481018\n",
      "Epoch2998 | train loss 0.554027396403253\n",
      "Epoch2999 | train loss 0.5540266957320273\n",
      "Epoch3000 | train loss 0.5540263689868152\n",
      "Epoch3001 | train loss 0.554025550018996\n",
      "Epoch3002 | train loss 0.5540244143083691\n",
      "Epoch3003 | train loss 0.5540247735008598\n",
      "Epoch3004 | train loss 0.5540232110768557\n",
      "Epoch3005 | train loss 0.5540227416530251\n",
      "Epoch3006 | train loss 0.5540213900059462\n",
      "Epoch3007 | train loss 0.5540218959748745\n",
      "Epoch3008 | train loss 0.5540202197432518\n",
      "Epoch3009 | train loss 0.5540190353617072\n",
      "Epoch3010 | train loss 0.5540189452655614\n",
      "Epoch3011 | train loss 0.554017769638449\n",
      "Epoch3012 | train loss 0.5540179594606162\n",
      "Epoch3013 | train loss 0.5540165876038372\n",
      "Epoch3014 | train loss 0.5540155991353095\n",
      "Epoch3015 | train loss 0.554015544783324\n",
      "Epoch3016 | train loss 0.554015311356634\n",
      "Epoch3017 | train loss 0.5540138957463205\n",
      "Epoch3018 | train loss 0.5540130580589175\n",
      "Epoch3019 | train loss 0.5540121601335705\n",
      "Epoch3020 | train loss 0.5540131095051766\n",
      "Epoch3021 | train loss 0.5540106803365051\n",
      "Epoch3022 | train loss 0.5540108569152653\n",
      "Epoch3023 | train loss 0.5540101135894656\n",
      "Epoch3024 | train loss 0.5540090760961175\n",
      "Epoch3025 | train loss 0.5540086075104773\n",
      "Epoch3026 | train loss 0.554007898364216\n",
      "Epoch3027 | train loss 0.5540089526027441\n",
      "Epoch3028 | train loss 0.5540062424913049\n",
      "Epoch3029 | train loss 0.5540058369189501\n",
      "Epoch3030 | train loss 0.5540053907036782\n",
      "Epoch3031 | train loss 0.5540046254359186\n",
      "Epoch3032 | train loss 0.5540037526190281\n",
      "Epoch3033 | train loss 0.5540038049407303\n",
      "Epoch3034 | train loss 0.5540027971379459\n",
      "Epoch3035 | train loss 0.5540016652457416\n",
      "Epoch3036 | train loss 0.5540011334605515\n",
      "Epoch3037 | train loss 0.5540014017000794\n",
      "Epoch3038 | train loss 0.5539987755939364\n",
      "Epoch3039 | train loss 0.5539985792711377\n",
      "Epoch3040 | train loss 0.5539986093342304\n",
      "Epoch3041 | train loss 0.5539979992993176\n",
      "Epoch3042 | train loss 0.5539973014779389\n",
      "Epoch3043 | train loss 0.5539965919032693\n",
      "Epoch3044 | train loss 0.5539958639629186\n",
      "Epoch3045 | train loss 0.5539947731606663\n",
      "Epoch3046 | train loss 0.553995250351727\n",
      "Epoch3047 | train loss 0.5539947499334812\n",
      "Epoch3048 | train loss 0.5539931689016521\n",
      "Epoch3049 | train loss 0.553992766328156\n",
      "Epoch3050 | train loss 0.5539915316551923\n",
      "Epoch3051 | train loss 0.5539907537400722\n",
      "Epoch3052 | train loss 0.5539910059422255\n",
      "Epoch3053 | train loss 0.5539893666654825\n",
      "Epoch3054 | train loss 0.553989532329142\n",
      "Epoch3055 | train loss 0.5539882456697524\n",
      "Epoch3056 | train loss 0.5539873493649066\n",
      "Epoch3057 | train loss 0.5539869269914925\n",
      "Epoch3058 | train loss 0.5539867991767824\n",
      "Epoch3059 | train loss 0.5539855664037168\n",
      "Epoch3060 | train loss 0.5539848490059376\n",
      "Epoch3061 | train loss 0.5539844867959619\n",
      "Epoch3062 | train loss 0.5539846682362258\n",
      "Epoch3063 | train loss 0.5539829075336457\n",
      "Epoch3064 | train loss 0.5539819447509945\n",
      "Epoch3065 | train loss 0.5539822596497834\n",
      "Epoch3066 | train loss 0.553981029316783\n",
      "Epoch3067 | train loss 0.5539809255860746\n",
      "Epoch3068 | train loss 0.5539802241325379\n",
      "Epoch3069 | train loss 0.5539792304113508\n",
      "Epoch3070 | train loss 0.553979031033814\n",
      "Epoch3071 | train loss 0.5539781768247485\n",
      "Epoch3072 | train loss 0.5539768041856586\n",
      "Epoch3073 | train loss 0.5539768284931779\n",
      "Epoch3074 | train loss 0.5539770442992449\n",
      "Epoch3075 | train loss 0.5539757602103055\n",
      "Epoch3076 | train loss 0.5539745903946459\n",
      "Epoch3077 | train loss 0.5539744932204484\n",
      "Epoch3078 | train loss 0.5539730981737375\n",
      "Epoch3079 | train loss 0.5539732599817216\n",
      "Epoch3080 | train loss 0.5539725309051573\n",
      "Epoch3081 | train loss 0.553971477933228\n",
      "Epoch3082 | train loss 0.5539714227430522\n",
      "Epoch3083 | train loss 0.5539702314324677\n",
      "Epoch3084 | train loss 0.5539699542708695\n",
      "Epoch3085 | train loss 0.5539694099500775\n",
      "Epoch3086 | train loss 0.5539688776433468\n",
      "Epoch3087 | train loss 0.5539676859043539\n",
      "Epoch3088 | train loss 0.5539675784111023\n",
      "Epoch3089 | train loss 0.5539667119272054\n",
      "Epoch3090 | train loss 0.5539663479477167\n",
      "Epoch3091 | train loss 0.5539655748941005\n",
      "Epoch3092 | train loss 0.5539644208177924\n",
      "Epoch3093 | train loss 0.5539646459370852\n",
      "Epoch3094 | train loss 0.5539634857326746\n",
      "Epoch3095 | train loss 0.5539628246985376\n",
      "Epoch3096 | train loss 0.5539621549658478\n",
      "Epoch3097 | train loss 0.5539621273055673\n",
      "Epoch3098 | train loss 0.5539607238769532\n",
      "Epoch3099 | train loss 0.5539599637314677\n",
      "Epoch3100 | train loss 0.5539605227671563\n",
      "Epoch3101 | train loss 0.5539595928415656\n",
      "Epoch3102 | train loss 0.5539583558216691\n",
      "Epoch3103 | train loss 0.553958759829402\n",
      "Epoch3104 | train loss 0.5539569393545389\n",
      "Epoch3105 | train loss 0.5539571800455451\n",
      "Epoch3106 | train loss 0.5539566359110176\n",
      "Epoch3107 | train loss 0.5539560372941196\n",
      "Epoch3108 | train loss 0.553954924698919\n",
      "Epoch3109 | train loss 0.5539548372291029\n",
      "Epoch3110 | train loss 0.5539543891884386\n",
      "Epoch3111 | train loss 0.5539532235451042\n",
      "Epoch3112 | train loss 0.553953244742006\n",
      "Epoch3113 | train loss 0.5539526382833719\n",
      "Epoch3114 | train loss 0.5539516140148044\n",
      "Epoch3115 | train loss 0.5539517417736352\n",
      "Epoch3116 | train loss 0.553950570076704\n",
      "Epoch3117 | train loss 0.5539500927738845\n",
      "Epoch3118 | train loss 0.5539493938162923\n",
      "Epoch3119 | train loss 0.5539490686543286\n",
      "Epoch3120 | train loss 0.5539482987485826\n",
      "Epoch3121 | train loss 0.5539483302645385\n",
      "Epoch3122 | train loss 0.5539470724575222\n",
      "Epoch3123 | train loss 0.5539467786252499\n",
      "Epoch3124 | train loss 0.553946099858731\n",
      "Epoch3125 | train loss 0.5539459289610386\n",
      "Epoch3126 | train loss 0.5539450321160256\n",
      "Epoch3127 | train loss 0.5539446268230677\n",
      "Epoch3128 | train loss 0.5539442985132337\n",
      "Epoch3129 | train loss 0.553943545948714\n",
      "Epoch3130 | train loss 0.5539429466798902\n",
      "Epoch3131 | train loss 0.5539416216686368\n",
      "Epoch3132 | train loss 0.5539419173076748\n",
      "Epoch3133 | train loss 0.5539418702945114\n",
      "Epoch3134 | train loss 0.5539409201033414\n",
      "Epoch3135 | train loss 0.553940269742161\n",
      "Epoch3136 | train loss 0.5539391894824803\n",
      "Epoch3137 | train loss 0.5539393477886915\n",
      "Epoch3138 | train loss 0.5539392689615488\n",
      "Epoch3139 | train loss 0.5539375590346753\n",
      "Epoch3140 | train loss 0.5539371979609132\n",
      "Epoch3141 | train loss 0.5539371952973307\n",
      "Epoch3142 | train loss 0.5539364998228848\n",
      "Epoch3143 | train loss 0.5539358930848539\n",
      "Epoch3144 | train loss 0.5539353777095676\n",
      "Epoch3145 | train loss 0.5539344737306238\n",
      "Epoch3146 | train loss 0.5539342604205012\n",
      "Epoch3147 | train loss 0.5539335004612803\n",
      "Epoch3148 | train loss 0.5539324243925512\n",
      "Epoch3149 | train loss 0.5539325562864542\n",
      "Epoch3150 | train loss 0.5539311774261296\n",
      "Epoch3151 | train loss 0.5539311888627708\n",
      "Epoch3152 | train loss 0.5539304789341987\n",
      "Epoch3153 | train loss 0.5539294409193098\n",
      "Epoch3154 | train loss 0.5539293638803064\n",
      "Epoch3155 | train loss 0.5539290498383344\n",
      "Epoch3156 | train loss 0.5539276410825551\n",
      "Epoch3157 | train loss 0.5539270911738277\n",
      "Epoch3158 | train loss 0.553927638605237\n",
      "Epoch3159 | train loss 0.5539265801943839\n",
      "Epoch3160 | train loss 0.5539251400902867\n",
      "Epoch3161 | train loss 0.553925520721823\n",
      "Epoch3162 | train loss 0.5539250751771033\n",
      "Epoch3163 | train loss 0.5539247108064592\n",
      "Epoch3164 | train loss 0.5539232946559787\n",
      "Epoch3165 | train loss 0.5539235348813236\n",
      "Epoch3166 | train loss 0.5539225467666984\n",
      "Epoch3167 | train loss 0.5539225264079869\n",
      "Epoch3168 | train loss 0.5539215402118862\n",
      "Epoch3169 | train loss 0.5539216568507254\n",
      "Epoch3170 | train loss 0.553920357748866\n",
      "Epoch3171 | train loss 0.553920567817986\n",
      "Epoch3172 | train loss 0.5539194645732641\n",
      "Epoch3173 | train loss 0.5539197298325598\n",
      "Epoch3174 | train loss 0.5539179671928287\n",
      "Epoch3175 | train loss 0.5539159170538187\n",
      "Epoch3176 | train loss 0.5539145430922509\n",
      "Epoch3177 | train loss 0.5539136387780309\n",
      "Epoch3178 | train loss 0.5539135555550456\n",
      "Epoch3179 | train loss 0.5539129711687565\n",
      "Epoch3180 | train loss 0.5539122497476637\n",
      "Epoch3181 | train loss 0.5539122416824103\n",
      "Epoch3182 | train loss 0.5539113646931946\n",
      "Epoch3183 | train loss 0.5539108017273248\n",
      "Epoch3184 | train loss 0.5539106279797852\n",
      "Epoch3185 | train loss 0.5539096291735768\n",
      "Epoch3186 | train loss 0.553909960873425\n",
      "Epoch3187 | train loss 0.5539080772921443\n",
      "Epoch3188 | train loss 0.5539075687900186\n",
      "Epoch3189 | train loss 0.5539084058441222\n",
      "Epoch3190 | train loss 0.5539065739698708\n",
      "Epoch3191 | train loss 0.5539075409434736\n",
      "Epoch3192 | train loss 0.553906135391444\n",
      "Epoch3193 | train loss 0.5539056602306665\n",
      "Epoch3194 | train loss 0.5539049181342125\n",
      "Epoch3195 | train loss 0.5539044840633869\n",
      "Epoch3196 | train loss 0.553903661314398\n",
      "Epoch3197 | train loss 0.5539036000333727\n",
      "Epoch3198 | train loss 0.5539030944555998\n",
      "Epoch3199 | train loss 0.5539019820839166\n",
      "Epoch3200 | train loss 0.5539030207879841\n",
      "Epoch3201 | train loss 0.5539015822298825\n",
      "Epoch3202 | train loss 0.5539011122845113\n",
      "Epoch3203 | train loss 0.5539006048440933\n",
      "Epoch3204 | train loss 0.5539001067727805\n",
      "Epoch3205 | train loss 0.5538995430059731\n",
      "Epoch3206 | train loss 0.55389908824116\n",
      "Epoch3207 | train loss 0.5538984882831574\n",
      "Epoch3208 | train loss 0.5538977211713791\n",
      "Epoch3209 | train loss 0.5538976956531405\n",
      "Epoch3210 | train loss 0.5538973673246801\n",
      "Epoch3211 | train loss 0.553896727412939\n",
      "Epoch3212 | train loss 0.5538961670733988\n",
      "Epoch3213 | train loss 0.5538960540667176\n",
      "Epoch3214 | train loss 0.5538952418975532\n",
      "Epoch3215 | train loss 0.5538944807648659\n",
      "Epoch3216 | train loss 0.5538942817598581\n",
      "Epoch3217 | train loss 0.5538938026316464\n",
      "Epoch3218 | train loss 0.5538931193388998\n",
      "Epoch3219 | train loss 0.5538923556171358\n",
      "Epoch3220 | train loss 0.553892340734601\n",
      "Epoch3221 | train loss 0.5538928720541298\n",
      "Epoch3222 | train loss 0.5538906517997384\n",
      "Epoch3223 | train loss 0.5538906988501549\n",
      "Epoch3224 | train loss 0.5538902454264462\n",
      "Epoch3225 | train loss 0.5538901521638036\n",
      "Epoch3226 | train loss 0.5538895621150732\n",
      "Epoch3227 | train loss 0.5538891276530922\n",
      "Epoch3228 | train loss 0.5538881852850318\n",
      "Epoch3229 | train loss 0.5538875181600451\n",
      "Epoch3230 | train loss 0.5538873642124236\n",
      "Epoch3231 | train loss 0.5538873452506959\n",
      "Epoch3232 | train loss 0.5538858829624951\n",
      "Epoch3233 | train loss 0.5538859982043505\n",
      "Epoch3234 | train loss 0.5538853468559682\n",
      "Epoch3235 | train loss 0.5538850131072104\n",
      "Epoch3236 | train loss 0.5538844448328019\n",
      "Epoch3237 | train loss 0.553883980307728\n",
      "Epoch3238 | train loss 0.5538835365511477\n",
      "Epoch3239 | train loss 0.5538829430006444\n",
      "Epoch3240 | train loss 0.5538826063461602\n",
      "Epoch3241 | train loss 0.5538821553066373\n",
      "Epoch3242 | train loss 0.5538815515674651\n",
      "Epoch3243 | train loss 0.5538810838572681\n",
      "Epoch3244 | train loss 0.5538806497305632\n",
      "Epoch3245 | train loss 0.5538801015913486\n",
      "Epoch3246 | train loss 0.5538796274922788\n",
      "Epoch3247 | train loss 0.5538795266859233\n",
      "Epoch3248 | train loss 0.5538781662285328\n",
      "Epoch3249 | train loss 0.5538781354017556\n",
      "Epoch3250 | train loss 0.5538780591636896\n",
      "Epoch3251 | train loss 0.5538766286149621\n",
      "Epoch3252 | train loss 0.553877118434757\n",
      "Epoch3253 | train loss 0.5538756049238145\n",
      "Epoch3254 | train loss 0.5538768957555295\n",
      "Epoch3255 | train loss 0.5538746042363346\n",
      "Epoch3256 | train loss 0.5538750520534813\n",
      "Epoch3257 | train loss 0.5538736960478127\n",
      "Epoch3258 | train loss 0.5538740568980575\n",
      "Epoch3259 | train loss 0.5538725601136685\n",
      "Epoch3260 | train loss 0.5538726929388941\n",
      "Epoch3261 | train loss 0.5538725079782307\n",
      "Epoch3262 | train loss 0.5538709720782936\n",
      "Epoch3263 | train loss 0.5538715458102524\n",
      "Epoch3264 | train loss 0.5538700203225017\n",
      "Epoch3265 | train loss 0.5538704243861139\n",
      "Epoch3266 | train loss 0.5538695880025625\n",
      "Epoch3267 | train loss 0.5538701947405934\n",
      "Epoch3268 | train loss 0.553868479654193\n",
      "Epoch3269 | train loss 0.5538680331781507\n",
      "Epoch3270 | train loss 0.5538675848022103\n",
      "Epoch3271 | train loss 0.5538672403246164\n",
      "Epoch3272 | train loss 0.5538664343953132\n",
      "Epoch3273 | train loss 0.5538662942871452\n",
      "Epoch3274 | train loss 0.553866006154567\n",
      "Epoch3275 | train loss 0.5538643102347851\n",
      "Epoch3276 | train loss 0.5538651386089622\n",
      "Epoch3277 | train loss 0.5538639191351831\n",
      "Epoch3278 | train loss 0.553863329552114\n",
      "Epoch3279 | train loss 0.553863449729979\n",
      "Epoch3280 | train loss 0.5538629974424839\n",
      "Epoch3281 | train loss 0.5538619970530272\n",
      "Epoch3282 | train loss 0.5538622226193547\n",
      "Epoch3283 | train loss 0.5538605763576925\n",
      "Epoch3284 | train loss 0.5538615061528981\n",
      "Epoch3285 | train loss 0.5538596352934837\n",
      "Epoch3286 | train loss 0.5538599899597466\n",
      "Epoch3287 | train loss 0.5538585741072893\n",
      "Epoch3288 | train loss 0.5538583477586507\n",
      "Epoch3289 | train loss 0.5538586785271764\n",
      "Epoch3290 | train loss 0.5538571600988508\n",
      "Epoch3291 | train loss 0.553856632001698\n",
      "Epoch3292 | train loss 0.5538560504093766\n",
      "Epoch3293 | train loss 0.5538559058867395\n",
      "Epoch3294 | train loss 0.5538550100289286\n",
      "Epoch3295 | train loss 0.5538544634729624\n",
      "Epoch3296 | train loss 0.5538543551042676\n",
      "Epoch3297 | train loss 0.5538544009439648\n",
      "Epoch3298 | train loss 0.5538526338338852\n",
      "Epoch3299 | train loss 0.5538522229529917\n",
      "Epoch3300 | train loss 0.5538522763736546\n",
      "Epoch3301 | train loss 0.5538528354465961\n",
      "Epoch3302 | train loss 0.5538501003943384\n",
      "Epoch3303 | train loss 0.5538494877889752\n",
      "Epoch3304 | train loss 0.5538507273048162\n",
      "Epoch3305 | train loss 0.5538486038148404\n",
      "Epoch3306 | train loss 0.5538486432656646\n",
      "Epoch3307 | train loss 0.5538484420068562\n",
      "Epoch3308 | train loss 0.5538492065668106\n",
      "Epoch3309 | train loss 0.5538469599559903\n",
      "Epoch3310 | train loss 0.5538469430804253\n",
      "Epoch3311 | train loss 0.5538459325954318\n",
      "Epoch3312 | train loss 0.5538460443913936\n",
      "Epoch3313 | train loss 0.5538450620509684\n",
      "Epoch3314 | train loss 0.5538454076647759\n",
      "Epoch3315 | train loss 0.5538427412323653\n",
      "Epoch3316 | train loss 0.5538420314900577\n",
      "Epoch3317 | train loss 0.5538415013626218\n",
      "Epoch3318 | train loss 0.5538411365449428\n",
      "Epoch3319 | train loss 0.5538410323299467\n",
      "Epoch3320 | train loss 0.5538398435898125\n",
      "Epoch3321 | train loss 0.5538378202542663\n",
      "Epoch3322 | train loss 0.5538382847048342\n",
      "Epoch3323 | train loss 0.5538379270583391\n",
      "Epoch3324 | train loss 0.5538369321450591\n",
      "Epoch3325 | train loss 0.5538351429253816\n",
      "Epoch3326 | train loss 0.5538333139754832\n",
      "Epoch3327 | train loss 0.553828820437193\n",
      "Epoch3328 | train loss 0.5538270778954029\n",
      "Epoch3329 | train loss 0.5538266027718782\n",
      "Epoch3330 | train loss 0.5538232633844018\n",
      "Epoch3331 | train loss 0.5538217463903129\n",
      "Epoch3332 | train loss 0.553819276522845\n",
      "Epoch3333 | train loss 0.5538179538585246\n",
      "Epoch3334 | train loss 0.5538173512928188\n",
      "Epoch3335 | train loss 0.5538156891427934\n",
      "Epoch3336 | train loss 0.5538150729611516\n",
      "Epoch3337 | train loss 0.5538135462068021\n",
      "Epoch3338 | train loss 0.5538129178993404\n",
      "Epoch3339 | train loss 0.5538112607039511\n",
      "Epoch3340 | train loss 0.553810594715178\n",
      "Epoch3341 | train loss 0.5538096627779305\n",
      "Epoch3342 | train loss 0.5538091604970395\n",
      "Epoch3343 | train loss 0.5538077725656331\n",
      "Epoch3344 | train loss 0.5538069363497198\n",
      "Epoch3345 | train loss 0.5538059771433472\n",
      "Epoch3346 | train loss 0.55380515800789\n",
      "Epoch3347 | train loss 0.5538043100573122\n",
      "Epoch3348 | train loss 0.5538032918050885\n",
      "Epoch3349 | train loss 0.5538028530031442\n",
      "Epoch3350 | train loss 0.5538019777461887\n",
      "Epoch3351 | train loss 0.5538004742376507\n",
      "Epoch3352 | train loss 0.5537992022000253\n",
      "Epoch3353 | train loss 0.5537996367365122\n",
      "Epoch3354 | train loss 0.5537983341328799\n",
      "Epoch3355 | train loss 0.5537983199208975\n",
      "Epoch3356 | train loss 0.5537965413928032\n",
      "Epoch3357 | train loss 0.5537969591468572\n",
      "Epoch3358 | train loss 0.5537954495102168\n",
      "Epoch3359 | train loss 0.5537958022207021\n",
      "Epoch3360 | train loss 0.5537954029813409\n",
      "Epoch3361 | train loss 0.5537942283973097\n",
      "Epoch3362 | train loss 0.5537927824631333\n",
      "Epoch3363 | train loss 0.5537926109135151\n",
      "Epoch3364 | train loss 0.5537924387678504\n",
      "Epoch3365 | train loss 0.5537913087196649\n",
      "Epoch3366 | train loss 0.5537918085977435\n",
      "Epoch3367 | train loss 0.5537912782095372\n",
      "Epoch3368 | train loss 0.5537895459868014\n",
      "Epoch3369 | train loss 0.5537894104979932\n",
      "Epoch3370 | train loss 0.5537892421334982\n",
      "Epoch3371 | train loss 0.5537887189537287\n",
      "Epoch3372 | train loss 0.5537870624102652\n",
      "Epoch3373 | train loss 0.5537875429913401\n",
      "Epoch3374 | train loss 0.5537870916165412\n",
      "Epoch3375 | train loss 0.5537862513586879\n",
      "Epoch3376 | train loss 0.5537862003035844\n",
      "Epoch3377 | train loss 0.5537844570353627\n",
      "Epoch3378 | train loss 0.553784044124186\n",
      "Epoch3379 | train loss 0.5537832674570382\n",
      "Epoch3380 | train loss 0.5537830350361764\n",
      "Epoch3381 | train loss 0.5537826347351075\n",
      "Epoch3382 | train loss 0.5537826459854841\n",
      "Epoch3383 | train loss 0.5537814777344465\n",
      "Epoch3384 | train loss 0.5537809650599956\n",
      "Epoch3385 | train loss 0.5537803476117551\n",
      "Epoch3386 | train loss 0.5537799489498139\n",
      "Epoch3387 | train loss 0.5537804466858506\n",
      "Epoch3388 | train loss 0.5537795870751142\n",
      "Epoch3389 | train loss 0.5537784878723323\n",
      "Epoch3390 | train loss 0.5537769974023103\n",
      "Epoch3391 | train loss 0.5537783241271973\n",
      "Epoch3392 | train loss 0.5537777984142304\n",
      "Epoch3393 | train loss 0.5537764836475253\n",
      "Epoch3394 | train loss 0.553776026237756\n",
      "Epoch3395 | train loss 0.5537753607518971\n",
      "Epoch3396 | train loss 0.5537756133638322\n",
      "Epoch3397 | train loss 0.5537745682522655\n",
      "Epoch3398 | train loss 0.5537739366106689\n",
      "Epoch3399 | train loss 0.5537736639939248\n",
      "Epoch3400 | train loss 0.5537738629803062\n",
      "Epoch3401 | train loss 0.5537725447304547\n",
      "Epoch3402 | train loss 0.5537719614803791\n",
      "Epoch3403 | train loss 0.5537724896147848\n",
      "Epoch3404 | train loss 0.5537719041295349\n",
      "Epoch3405 | train loss 0.5537695541419089\n",
      "Epoch3406 | train loss 0.5537710576504469\n",
      "Epoch3407 | train loss 0.5537687077000737\n",
      "Epoch3408 | train loss 0.553769762404263\n",
      "Epoch3409 | train loss 0.5537677652388812\n",
      "Epoch3410 | train loss 0.5537681300751864\n",
      "Epoch3411 | train loss 0.553767839372158\n",
      "Epoch3412 | train loss 0.5537676990777254\n",
      "Epoch3413 | train loss 0.553766801059246\n",
      "Epoch3414 | train loss 0.5537681652233004\n",
      "Epoch3415 | train loss 0.5537642462179064\n",
      "Epoch3416 | train loss 0.5537637872435153\n",
      "Epoch3417 | train loss 0.5537636863067746\n",
      "Epoch3418 | train loss 0.5537623963877558\n",
      "Epoch3419 | train loss 0.5537616163305938\n",
      "Epoch3420 | train loss 0.5537602591142058\n",
      "Epoch3421 | train loss 0.5537595964968205\n",
      "Epoch3422 | train loss 0.553759232647717\n",
      "Epoch3423 | train loss 0.5537575589492917\n",
      "Epoch3424 | train loss 0.5537592941708863\n",
      "Epoch3425 | train loss 0.553757962398231\n",
      "Epoch3426 | train loss 0.5537568526528776\n",
      "Epoch3427 | train loss 0.5537557573057711\n",
      "Epoch3428 | train loss 0.5537564302049577\n",
      "Epoch3429 | train loss 0.5537543721683323\n",
      "Epoch3430 | train loss 0.5537552362121642\n",
      "Epoch3431 | train loss 0.553753362596035\n",
      "Epoch3432 | train loss 0.5537536690384149\n",
      "Epoch3433 | train loss 0.5537531353905797\n",
      "Epoch3434 | train loss 0.5537528571672737\n",
      "Epoch3435 | train loss 0.5537519774585963\n",
      "Epoch3436 | train loss 0.5537516926974058\n",
      "Epoch3437 | train loss 0.5537527025490999\n",
      "Epoch3438 | train loss 0.5537504458799958\n",
      "Epoch3439 | train loss 0.5537506891600787\n",
      "Epoch3440 | train loss 0.5537491908110678\n",
      "Epoch3441 | train loss 0.5537491866014898\n",
      "Epoch3442 | train loss 0.5537502545490861\n",
      "Epoch3443 | train loss 0.5537495373561978\n",
      "Epoch3444 | train loss 0.5537478725984692\n",
      "Epoch3445 | train loss 0.5537480290606618\n",
      "Epoch3446 | train loss 0.5537478461302817\n",
      "Epoch3447 | train loss 0.553746832460165\n",
      "Epoch3448 | train loss 0.5537467655539513\n",
      "Epoch3449 | train loss 0.5537457773089409\n",
      "Epoch3450 | train loss 0.5537459618411958\n",
      "Epoch3451 | train loss 0.553745768032968\n",
      "Epoch3452 | train loss 0.5537456576526165\n",
      "Epoch3453 | train loss 0.5537440499663353\n",
      "Epoch3454 | train loss 0.5537442355044186\n",
      "Epoch3455 | train loss 0.5537435060553253\n",
      "Epoch3456 | train loss 0.5537427873909473\n",
      "Epoch3457 | train loss 0.5537430731207132\n",
      "Epoch3458 | train loss 0.5537425085529685\n",
      "Epoch3459 | train loss 0.553742215000093\n",
      "Epoch3460 | train loss 0.553741665109992\n",
      "Epoch3461 | train loss 0.5537420092150569\n",
      "Epoch3462 | train loss 0.5537415409646929\n",
      "Epoch3463 | train loss 0.5537404130585492\n",
      "Epoch3464 | train loss 0.5537401857413351\n",
      "Epoch3465 | train loss 0.5537404082156718\n",
      "Epoch3466 | train loss 0.5537407563999295\n",
      "Epoch3467 | train loss 0.5537388595379888\n",
      "Epoch3468 | train loss 0.5537391332350672\n",
      "Epoch3469 | train loss 0.5537388547323644\n",
      "Epoch3470 | train loss 0.5537377855367959\n",
      "Epoch3471 | train loss 0.5537377078086138\n",
      "Epoch3472 | train loss 0.5537366529926657\n",
      "Epoch3473 | train loss 0.5537370868399739\n",
      "Epoch3474 | train loss 0.5537359430082143\n",
      "Epoch3475 | train loss 0.5537356694042682\n",
      "Epoch3476 | train loss 0.5537349622696638\n",
      "Epoch3477 | train loss 0.5537346850149334\n",
      "Epoch3478 | train loss 0.553734785374254\n",
      "Epoch3479 | train loss 0.5537337806820869\n",
      "Epoch3480 | train loss 0.5537336664274335\n",
      "Epoch3481 | train loss 0.5537328483350575\n",
      "Epoch3482 | train loss 0.5537334258668125\n",
      "Epoch3483 | train loss 0.5537328321486712\n",
      "Epoch3484 | train loss 0.5537315461598337\n",
      "Epoch3485 | train loss 0.5537312301434576\n",
      "Epoch3486 | train loss 0.5537307212501764\n",
      "Epoch3487 | train loss 0.5537304341606796\n",
      "Epoch3488 | train loss 0.5537305215001106\n",
      "Epoch3489 | train loss 0.5537295766919851\n",
      "Epoch3490 | train loss 0.5537292564846575\n",
      "Epoch3491 | train loss 0.5537288087420166\n",
      "Epoch3492 | train loss 0.5537286724895238\n",
      "Epoch3493 | train loss 0.5537278413027525\n",
      "Epoch3494 | train loss 0.5537275864928961\n",
      "Epoch3495 | train loss 0.5537271323241293\n",
      "Epoch3496 | train loss 0.5537274740077556\n",
      "Epoch3497 | train loss 0.5537266765162349\n",
      "Epoch3498 | train loss 0.5537258686497808\n",
      "Epoch3499 | train loss 0.5537264668568969\n",
      "Epoch3500 | train loss 0.5537251679413021\n",
      "Epoch3501 | train loss 0.5537251542508602\n",
      "Epoch3502 | train loss 0.5537251717969776\n",
      "Epoch3503 | train loss 0.5537239782698452\n",
      "Epoch3504 | train loss 0.5537239251285792\n",
      "Epoch3505 | train loss 0.5537222564034164\n",
      "Epoch3506 | train loss 0.5537234664335847\n",
      "Epoch3507 | train loss 0.5537214306928218\n",
      "Epoch3508 | train loss 0.5537224131822586\n",
      "Epoch3509 | train loss 0.5537216167151928\n",
      "Epoch3510 | train loss 0.5537213302962481\n",
      "Epoch3511 | train loss 0.553720958083868\n",
      "Epoch3512 | train loss 0.5537216401100159\n",
      "Epoch3513 | train loss 0.5537200066260993\n",
      "Epoch3514 | train loss 0.5537200234085321\n",
      "Epoch3515 | train loss 0.5537183878757059\n",
      "Epoch3516 | train loss 0.5537195924296975\n",
      "Epoch3517 | train loss 0.5537175723351538\n",
      "Epoch3518 | train loss 0.5537174616940319\n",
      "Epoch3519 | train loss 0.5537178236618638\n",
      "Epoch3520 | train loss 0.5537188336625696\n",
      "Epoch3521 | train loss 0.553717736247927\n",
      "Epoch3522 | train loss 0.5537164708599448\n",
      "Epoch3523 | train loss 0.5537163461185992\n",
      "Epoch3524 | train loss 0.5537148195691407\n",
      "Epoch3525 | train loss 0.553715434037149\n",
      "Epoch3526 | train loss 0.5537147211842239\n",
      "Epoch3527 | train loss 0.5537158087641001\n",
      "Epoch3528 | train loss 0.5537142829038203\n",
      "Epoch3529 | train loss 0.5537138862721622\n",
      "Epoch3530 | train loss 0.5537138954736293\n",
      "Epoch3531 | train loss 0.5537140396796167\n",
      "Epoch3532 | train loss 0.55371303062886\n",
      "Epoch3533 | train loss 0.5537132714316249\n",
      "Epoch3534 | train loss 0.5537126511149109\n",
      "Epoch3535 | train loss 0.5537110234238207\n",
      "Epoch3536 | train loss 0.5537112528830767\n",
      "Epoch3537 | train loss 0.5537111012265086\n",
      "Epoch3538 | train loss 0.5537112503126264\n",
      "Epoch3539 | train loss 0.5537105255201459\n",
      "Epoch3540 | train loss 0.5537092069350183\n",
      "Epoch3541 | train loss 0.553708467707038\n",
      "Epoch3542 | train loss 0.5537094502709806\n",
      "Epoch3543 | train loss 0.55370988573879\n",
      "Epoch3544 | train loss 0.5537087268382311\n",
      "Epoch3545 | train loss 0.5537072614766657\n",
      "Epoch3546 | train loss 0.5537073302641511\n",
      "Epoch3547 | train loss 0.5537066482566297\n",
      "Epoch3548 | train loss 0.5537068041227758\n",
      "Epoch3549 | train loss 0.5537065792083741\n",
      "Epoch3550 | train loss 0.5537065048515797\n",
      "Epoch3551 | train loss 0.5537054072879255\n",
      "Epoch3552 | train loss 0.5537049704790116\n",
      "Epoch3553 | train loss 0.5537057993933558\n",
      "Epoch3554 | train loss 0.5537046200409531\n",
      "Epoch3555 | train loss 0.5537046382203699\n",
      "Epoch3556 | train loss 0.553703301101923\n",
      "Epoch3557 | train loss 0.5537044470012188\n",
      "Epoch3558 | train loss 0.5537047532014548\n",
      "Epoch3559 | train loss 0.5537028832919896\n",
      "Epoch3560 | train loss 0.5537017661705613\n",
      "Epoch3561 | train loss 0.553702699020505\n",
      "Epoch3562 | train loss 0.5537024820223451\n",
      "Epoch3563 | train loss 0.5537013028934598\n",
      "Epoch3564 | train loss 0.5537006019614636\n",
      "Epoch3565 | train loss 0.5537011211179197\n",
      "Epoch3566 | train loss 0.5537005065195263\n",
      "Epoch3567 | train loss 0.5536997295543551\n",
      "Epoch3568 | train loss 0.553699927907437\n",
      "Epoch3569 | train loss 0.553700442109257\n",
      "Epoch3570 | train loss 0.5536986429803074\n",
      "Epoch3571 | train loss 0.5536991498619318\n",
      "Epoch3572 | train loss 0.553698524273932\n",
      "Epoch3573 | train loss 0.5536982499621809\n",
      "Epoch3574 | train loss 0.5536967838928103\n",
      "Epoch3575 | train loss 0.5536974086239934\n",
      "Epoch3576 | train loss 0.5536973486840725\n",
      "Epoch3577 | train loss 0.5536961744539439\n",
      "Epoch3578 | train loss 0.5536972734332085\n",
      "Epoch3579 | train loss 0.5536960284970701\n",
      "Epoch3580 | train loss 0.5536958952620625\n",
      "Epoch3581 | train loss 0.553696009889245\n",
      "Epoch3582 | train loss 0.5536946436204017\n",
      "Epoch3583 | train loss 0.5536950031295419\n",
      "Epoch3584 | train loss 0.5536945309489966\n",
      "Epoch3585 | train loss 0.5536930937878788\n",
      "Epoch3586 | train loss 0.5536939203366638\n",
      "Epoch3587 | train loss 0.5536938404850662\n",
      "Epoch3588 | train loss 0.5536934861913323\n",
      "Epoch3589 | train loss 0.5536932786926627\n",
      "Epoch3590 | train loss 0.5536909593455493\n",
      "Epoch3591 | train loss 0.5536928976327181\n",
      "Epoch3592 | train loss 0.5536916502937674\n",
      "Epoch3593 | train loss 0.5536913619376719\n",
      "Epoch3594 | train loss 0.5536919698491692\n",
      "Epoch3595 | train loss 0.5536902148090302\n",
      "Epoch3596 | train loss 0.5536909789219499\n",
      "Epoch3597 | train loss 0.553688999786973\n",
      "Epoch3598 | train loss 0.5536899047158659\n",
      "Epoch3599 | train loss 0.5536903030052781\n",
      "Epoch3600 | train loss 0.5536900675669313\n",
      "Epoch3601 | train loss 0.5536873297207058\n",
      "Epoch3602 | train loss 0.5536893782950938\n",
      "Epoch3603 | train loss 0.5536890969797968\n",
      "Epoch3604 | train loss 0.5536875474639237\n",
      "Epoch3605 | train loss 0.5536873619444669\n",
      "Epoch3606 | train loss 0.5536863508448004\n",
      "Epoch3607 | train loss 0.5536874524690211\n",
      "Epoch3608 | train loss 0.5536877009645105\n",
      "Epoch3609 | train loss 0.5536851153522729\n",
      "Epoch3610 | train loss 0.5536864776909352\n",
      "Epoch3611 | train loss 0.5536860745958984\n",
      "Epoch3612 | train loss 0.5536857687868177\n",
      "Epoch3613 | train loss 0.5536857793480158\n",
      "Epoch3614 | train loss 0.5536843702197075\n",
      "Epoch3615 | train loss 0.5536843180283904\n",
      "Epoch3616 | train loss 0.5536849197931588\n",
      "Epoch3617 | train loss 0.5536846856214106\n",
      "Epoch3618 | train loss 0.553682020008564\n",
      "Epoch3619 | train loss 0.5536818433180452\n",
      "Epoch3620 | train loss 0.5536837162822486\n",
      "Epoch3621 | train loss 0.5536834753863513\n",
      "Epoch3622 | train loss 0.5536825348995627\n",
      "Epoch3623 | train loss 0.553682965375483\n",
      "Epoch3624 | train loss 0.5536819918826222\n",
      "Epoch3625 | train loss 0.5536821677163243\n",
      "Epoch3626 | train loss 0.5536797530762851\n",
      "Epoch3627 | train loss 0.5536811593174934\n",
      "Epoch3628 | train loss 0.5536809114739298\n",
      "Epoch3629 | train loss 0.5536803548596799\n",
      "Epoch3630 | train loss 0.5536802128329873\n",
      "Epoch3631 | train loss 0.5536800602078438\n",
      "Epoch3632 | train loss 0.5536783501878381\n",
      "Epoch3633 | train loss 0.5536793124489486\n",
      "Epoch3634 | train loss 0.5536778632178903\n",
      "Epoch3635 | train loss 0.5536793201230467\n",
      "Epoch3636 | train loss 0.5536782863922417\n",
      "Epoch3637 | train loss 0.5536781926825642\n",
      "Epoch3638 | train loss 0.553675763271749\n",
      "Epoch3639 | train loss 0.5536779735982418\n",
      "Epoch3640 | train loss 0.5536766195297241\n",
      "Epoch3641 | train loss 0.553677279110998\n",
      "Epoch3642 | train loss 0.5536760125309229\n",
      "Epoch3643 | train loss 0.5536754706501961\n",
      "Epoch3644 | train loss 0.553675574939698\n",
      "Epoch3645 | train loss 0.5536759153194726\n",
      "Epoch3646 | train loss 0.5536753493361175\n",
      "Epoch3647 | train loss 0.5536729308217764\n",
      "Epoch3648 | train loss 0.5536745877377689\n",
      "Epoch3649 | train loss 0.5536739096604287\n",
      "Epoch3650 | train loss 0.5536728070303798\n",
      "Epoch3651 | train loss 0.5536737021245063\n",
      "Epoch3652 | train loss 0.5536717568896711\n",
      "Epoch3653 | train loss 0.5536726032570004\n",
      "Epoch3654 | train loss 0.5536729026958347\n",
      "Epoch3655 | train loss 0.553671939149499\n",
      "Epoch3656 | train loss 0.5536713156290353\n",
      "Epoch3657 | train loss 0.5536719385161996\n",
      "Epoch3658 | train loss 0.5536707896925509\n",
      "Epoch3659 | train loss 0.5536713132075965\n",
      "Epoch3660 | train loss 0.553670892957598\n",
      "Epoch3661 | train loss 0.55366834865883\n",
      "Epoch3662 | train loss 0.5536707265116274\n",
      "Epoch3663 | train loss 0.5536693017370999\n",
      "Epoch3664 | train loss 0.5536680324375629\n",
      "Epoch3665 | train loss 0.5536686473153531\n",
      "Epoch3666 | train loss 0.5536686166748405\n",
      "Epoch3667 | train loss 0.5536671608686448\n",
      "Epoch3668 | train loss 0.5536674928106368\n",
      "Epoch3669 | train loss 0.5536685907840728\n",
      "Epoch3670 | train loss 0.5536670955270528\n",
      "Epoch3671 | train loss 0.5536669729463756\n",
      "Epoch3672 | train loss 0.5536666081100702\n",
      "Epoch3673 | train loss 0.553667001016438\n",
      "Epoch3674 | train loss 0.553665061686188\n",
      "Epoch3675 | train loss 0.5536657144501805\n",
      "Epoch3676 | train loss 0.5536655956879258\n",
      "Epoch3677 | train loss 0.5536646698787808\n",
      "Epoch3678 | train loss 0.5536661607213318\n",
      "Epoch3679 | train loss 0.5536642679385841\n",
      "Epoch3680 | train loss 0.5536645822972059\n",
      "Epoch3681 | train loss 0.5536627250351012\n",
      "Epoch3682 | train loss 0.5536639177054167\n",
      "Epoch3683 | train loss 0.5536629612743854\n",
      "Epoch3684 | train loss 0.5536639985442161\n",
      "Epoch3685 | train loss 0.5536635572463274\n",
      "Epoch3686 | train loss 0.553663684874773\n",
      "Epoch3687 | train loss 0.5536622142232954\n",
      "Epoch3688 | train loss 0.553662607204169\n",
      "Epoch3689 | train loss 0.553661456219852\n",
      "Epoch3690 | train loss 0.5536612107418477\n",
      "Epoch3691 | train loss 0.5536622763983905\n",
      "Epoch3692 | train loss 0.5536611347459257\n",
      "Epoch3693 | train loss 0.5536615102365613\n",
      "Epoch3694 | train loss 0.5536609257571399\n",
      "Epoch3695 | train loss 0.5536614533141255\n",
      "Epoch3696 | train loss 0.5536598660424352\n",
      "Epoch3697 | train loss 0.5536595114506782\n",
      "Epoch3698 | train loss 0.5536587112024427\n",
      "Epoch3699 | train loss 0.5536597855389118\n",
      "Epoch3700 | train loss 0.5536590878106654\n",
      "Epoch3701 | train loss 0.5536592383310199\n",
      "Epoch3702 | train loss 0.553657930996269\n",
      "Epoch3703 | train loss 0.5536591918393969\n",
      "Epoch3704 | train loss 0.553657875303179\n",
      "Epoch3705 | train loss 0.5536580655723811\n",
      "Epoch3706 | train loss 0.55365658454597\n",
      "Epoch3707 | train loss 0.5536585204303265\n",
      "Epoch3708 | train loss 0.5536565570905805\n",
      "Epoch3709 | train loss 0.5536570305190981\n",
      "Epoch3710 | train loss 0.553657506313175\n",
      "Epoch3711 | train loss 0.5536550300195813\n",
      "Epoch3712 | train loss 0.5536568325012923\n",
      "Epoch3713 | train loss 0.5536548037827015\n",
      "Epoch3714 | train loss 0.5536550568044185\n",
      "Epoch3715 | train loss 0.5536552873812616\n",
      "Epoch3716 | train loss 0.5536527154222131\n",
      "Epoch3717 | train loss 0.5536566891521215\n",
      "Epoch3718 | train loss 0.5536532297730445\n",
      "Epoch3719 | train loss 0.5536542824283243\n",
      "Epoch3720 | train loss 0.5536527675949037\n",
      "Epoch3721 | train loss 0.5536547455005347\n",
      "Epoch3722 | train loss 0.5536534727551043\n",
      "Epoch3723 | train loss 0.553652376551181\n",
      "Epoch3724 | train loss 0.5536527454108\n",
      "Epoch3725 | train loss 0.5536536800675094\n",
      "Epoch3726 | train loss 0.5536509704403579\n",
      "Epoch3727 | train loss 0.5536515543423594\n",
      "Epoch3728 | train loss 0.5536516361869872\n",
      "Epoch3729 | train loss 0.5536528426408768\n",
      "Epoch3730 | train loss 0.5536512292921543\n",
      "Epoch3731 | train loss 0.5536511006765068\n",
      "Epoch3732 | train loss 0.5536511222273112\n",
      "Epoch3733 | train loss 0.5536502582952381\n",
      "Epoch3734 | train loss 0.5536483488418162\n",
      "Epoch3735 | train loss 0.553650011792779\n",
      "Epoch3736 | train loss 0.5536509933136403\n",
      "Epoch3737 | train loss 0.5536486771516502\n",
      "Epoch3738 | train loss 0.5536497328057886\n",
      "Epoch3739 | train loss 0.5536479085683823\n",
      "Epoch3740 | train loss 0.5536483667604625\n",
      "Epoch3741 | train loss 0.5536492805369199\n",
      "Epoch3742 | train loss 0.5536473594233393\n",
      "Epoch3743 | train loss 0.5536489398777484\n",
      "Epoch3744 | train loss 0.5536474532075226\n",
      "Epoch3745 | train loss 0.553647808674723\n",
      "Epoch3746 | train loss 0.5536454268544913\n",
      "Epoch3747 | train loss 0.5536466871760786\n",
      "Epoch3748 | train loss 0.5536471639946103\n",
      "Epoch3749 | train loss 0.5536465139128268\n",
      "Epoch3750 | train loss 0.5536464334651828\n",
      "Epoch3751 | train loss 0.553644806239754\n",
      "Epoch3752 | train loss 0.5536446499638259\n",
      "Epoch3753 | train loss 0.5536456896178424\n",
      "Epoch3754 | train loss 0.5536450480297208\n",
      "Epoch3755 | train loss 0.5536443712562322\n",
      "Epoch3756 | train loss 0.5536442634649574\n",
      "Epoch3757 | train loss 0.5536443731933832\n",
      "Epoch3758 | train loss 0.5536452192440628\n",
      "Epoch3759 | train loss 0.5536443606764078\n",
      "Epoch3760 | train loss 0.5536429814435542\n",
      "Epoch3761 | train loss 0.5536416218802332\n",
      "Epoch3762 | train loss 0.5536433406919241\n",
      "Epoch3763 | train loss 0.553643678240478\n",
      "Epoch3764 | train loss 0.5536434214562178\n",
      "Epoch3765 | train loss 0.5536419495381415\n",
      "Epoch3766 | train loss 0.5536416893824935\n",
      "Epoch3767 | train loss 0.5536406444571912\n",
      "Epoch3768 | train loss 0.5536414570733905\n",
      "Epoch3769 | train loss 0.5536413328535855\n",
      "Epoch3770 | train loss 0.5536406884156168\n",
      "Epoch3771 | train loss 0.5536408751085401\n",
      "Epoch3772 | train loss 0.5536408675462008\n",
      "Epoch3773 | train loss 0.5536402011848987\n",
      "Epoch3774 | train loss 0.5536384916491807\n",
      "Epoch3775 | train loss 0.5536398478597403\n",
      "Epoch3776 | train loss 0.5536403409577906\n",
      "Epoch3777 | train loss 0.5536386032029986\n",
      "Epoch3778 | train loss 0.5536384776234626\n",
      "Epoch3779 | train loss 0.5536396074853838\n",
      "Epoch3780 | train loss 0.5536366723105312\n",
      "Epoch3781 | train loss 0.5536378212273121\n",
      "Epoch3782 | train loss 0.5536389327980578\n",
      "Epoch3783 | train loss 0.5536380917392671\n",
      "Epoch3784 | train loss 0.5536375438421964\n",
      "Epoch3785 | train loss 0.5536359536647797\n",
      "Epoch3786 | train loss 0.5536368498392403\n",
      "Epoch3787 | train loss 0.5536366747319699\n",
      "Epoch3788 | train loss 0.5536373372934759\n",
      "Epoch3789 | train loss 0.5536360473185777\n",
      "Epoch3790 | train loss 0.5536356452666223\n",
      "Epoch3791 | train loss 0.5536358838528395\n",
      "Epoch3792 | train loss 0.5536360397003591\n",
      "Epoch3793 | train loss 0.5536345409043133\n",
      "Epoch3794 | train loss 0.5536348117701709\n",
      "Epoch3795 | train loss 0.5536359585262836\n",
      "Epoch3796 | train loss 0.553634209819138\n",
      "Epoch3797 | train loss 0.5536338414624333\n",
      "Epoch3798 | train loss 0.553633918594569\n",
      "Epoch3799 | train loss 0.5536335409618914\n",
      "Epoch3800 | train loss 0.5536347242631018\n",
      "Epoch3801 | train loss 0.5536331022158265\n",
      "Epoch3802 | train loss 0.5536332386918366\n",
      "Epoch3803 | train loss 0.5536321181245148\n",
      "Epoch3804 | train loss 0.553632533363998\n",
      "Epoch3805 | train loss 0.5536336586996913\n",
      "Epoch3806 | train loss 0.5536313920840621\n",
      "Epoch3807 | train loss 0.5536320094577968\n",
      "Epoch3808 | train loss 0.5536313677765429\n",
      "Epoch3809 | train loss 0.5536313696950674\n",
      "Epoch3810 | train loss 0.5536310674063861\n",
      "Epoch3811 | train loss 0.5536315770819783\n",
      "Epoch3812 | train loss 0.5536309785954654\n",
      "Epoch3813 | train loss 0.5536310249753297\n",
      "Epoch3814 | train loss 0.5536294816806913\n",
      "Epoch3815 | train loss 0.553630157802254\n",
      "Epoch3816 | train loss 0.5536310742422939\n",
      "Epoch3817 | train loss 0.5536298069544137\n",
      "Epoch3818 | train loss 0.5536304749548435\n",
      "Epoch3819 | train loss 0.5536291385628282\n",
      "Epoch3820 | train loss 0.553629578705877\n",
      "Epoch3821 | train loss 0.5536300983279944\n",
      "Epoch3822 | train loss 0.5536286311596632\n",
      "Epoch3823 | train loss 0.5536285926960409\n",
      "Epoch3824 | train loss 0.5536299053393304\n",
      "Epoch3825 | train loss 0.5536277640424668\n",
      "Epoch3826 | train loss 0.5536286550946534\n",
      "Epoch3827 | train loss 0.5536287997476756\n",
      "Epoch3828 | train loss 0.5536267131008208\n",
      "Epoch3829 | train loss 0.5536270588077605\n",
      "Epoch3830 | train loss 0.5536279441602528\n",
      "Epoch3831 | train loss 0.5536257792636752\n",
      "Epoch3832 | train loss 0.5536278836987912\n",
      "Epoch3833 | train loss 0.5536273954249918\n",
      "Epoch3834 | train loss 0.5536279087141156\n",
      "Epoch3835 | train loss 0.5536274047382176\n",
      "Epoch3836 | train loss 0.5536279448866844\n",
      "Epoch3837 | train loss 0.5536254285648465\n",
      "Epoch3838 | train loss 0.5536241604946553\n",
      "Epoch3839 | train loss 0.5536249063909053\n",
      "Epoch3840 | train loss 0.5536254162713885\n",
      "Epoch3841 | train loss 0.5536230364069342\n",
      "Epoch3842 | train loss 0.5536226005665958\n",
      "Epoch3843 | train loss 0.5536225788109005\n",
      "Epoch3844 | train loss 0.553621475175023\n",
      "Epoch3845 | train loss 0.5536214394122362\n",
      "Epoch3846 | train loss 0.553620633110404\n",
      "Epoch3847 | train loss 0.5536200512759387\n",
      "Epoch3848 | train loss 0.5536205954477191\n",
      "Epoch3849 | train loss 0.5536188105866313\n",
      "Epoch3850 | train loss 0.5536169589683414\n",
      "Epoch3851 | train loss 0.5536177460849285\n",
      "Epoch3852 | train loss 0.5536166385561228\n",
      "Epoch3853 | train loss 0.5536190217919648\n",
      "Epoch3854 | train loss 0.5536164959706366\n",
      "Epoch3855 | train loss 0.5536174103617668\n",
      "Epoch3856 | train loss 0.5536162707768381\n",
      "Epoch3857 | train loss 0.5536161372996866\n",
      "Epoch3858 | train loss 0.553614570517093\n",
      "Epoch3859 | train loss 0.5536152684316039\n",
      "Epoch3860 | train loss 0.553615381270647\n",
      "Epoch3861 | train loss 0.5536139055341482\n",
      "Epoch3862 | train loss 0.5536137391999364\n",
      "Epoch3863 | train loss 0.5536151274852454\n",
      "Epoch3864 | train loss 0.5536144838854671\n",
      "Epoch3865 | train loss 0.553613090030849\n",
      "Epoch3866 | train loss 0.5536133351922036\n",
      "Epoch3867 | train loss 0.5536127243563533\n",
      "Epoch3868 | train loss 0.5536135857924819\n",
      "Epoch3869 | train loss 0.5536119042336941\n",
      "Epoch3870 | train loss 0.5536131545901298\n",
      "Epoch3871 | train loss 0.5536121424846351\n",
      "Epoch3872 | train loss 0.5536119380220771\n",
      "Epoch3873 | train loss 0.5536117542162537\n",
      "Epoch3874 | train loss 0.5536102414876223\n",
      "Epoch3875 | train loss 0.5536108007095755\n",
      "Epoch3876 | train loss 0.5536097747832537\n",
      "Epoch3877 | train loss 0.5536103839054703\n",
      "Epoch3878 | train loss 0.5536108366213739\n",
      "Epoch3879 | train loss 0.5536094618029892\n",
      "Epoch3880 | train loss 0.5536088539101184\n",
      "Epoch3881 | train loss 0.5536098621785641\n",
      "Epoch3882 | train loss 0.5536090268939734\n",
      "Epoch3883 | train loss 0.5536080795526505\n",
      "Epoch3884 | train loss 0.5536089199967682\n",
      "Epoch3885 | train loss 0.5536082956381142\n",
      "Epoch3886 | train loss 0.5536078348010779\n",
      "Epoch3887 | train loss 0.5536075127497315\n",
      "Epoch3888 | train loss 0.5536076584272087\n",
      "Epoch3889 | train loss 0.5536075757443905\n",
      "Epoch3890 | train loss 0.553604405876249\n",
      "Epoch3891 | train loss 0.5536037452705205\n",
      "Epoch3892 | train loss 0.5536029572784901\n",
      "Epoch3893 | train loss 0.5536024147458375\n",
      "Epoch3894 | train loss 0.5536010461300611\n",
      "Epoch3895 | train loss 0.5536014614999294\n",
      "Epoch3896 | train loss 0.5535998785495758\n",
      "Epoch3897 | train loss 0.5535991506837309\n",
      "Epoch3898 | train loss 0.5535977058298885\n",
      "Epoch3899 | train loss 0.5535985855199397\n",
      "Epoch3900 | train loss 0.5535972814634442\n",
      "Epoch3901 | train loss 0.5535950614139438\n",
      "Epoch3902 | train loss 0.5535943471640349\n",
      "Epoch3903 | train loss 0.5535949409194291\n",
      "Epoch3904 | train loss 0.5535933469980955\n",
      "Epoch3905 | train loss 0.5535930550470948\n",
      "Epoch3906 | train loss 0.5535926977358758\n",
      "Epoch3907 | train loss 0.5535921733640135\n",
      "Epoch3908 | train loss 0.5535907757468521\n",
      "Epoch3909 | train loss 0.5535899856872857\n",
      "Epoch3910 | train loss 0.5535895537771285\n",
      "Epoch3911 | train loss 0.5535888311639429\n",
      "Epoch3912 | train loss 0.55358931876719\n",
      "Epoch3913 | train loss 0.5535849571041763\n",
      "Epoch3914 | train loss 0.5535868065059185\n",
      "Epoch3915 | train loss 0.5535838342085481\n",
      "Epoch3916 | train loss 0.5535849053040147\n",
      "Epoch3917 | train loss 0.5535839736834168\n",
      "Epoch3918 | train loss 0.5535804672911763\n",
      "Epoch3919 | train loss 0.5535786645300687\n",
      "Epoch3920 | train loss 0.5535776396654546\n",
      "Epoch3921 | train loss 0.5535752447322011\n",
      "Epoch3922 | train loss 0.5535754960216582\n",
      "Epoch3923 | train loss 0.553573306016624\n",
      "Epoch3924 | train loss 0.5535731782205403\n",
      "Epoch3925 | train loss 0.5535735757090151\n",
      "Epoch3926 | train loss 0.553570779003203\n",
      "Epoch3927 | train loss 0.553569325953722\n",
      "Epoch3928 | train loss 0.5535684841871261\n",
      "Epoch3929 | train loss 0.5535676401667297\n",
      "Epoch3930 | train loss 0.5535670267231763\n",
      "Epoch3931 | train loss 0.5535680969990789\n",
      "Epoch3932 | train loss 0.5535661104880273\n",
      "Epoch3933 | train loss 0.5535663578845561\n",
      "Epoch3934 | train loss 0.5535650459863245\n",
      "Epoch3935 | train loss 0.5535640315338969\n",
      "Epoch3936 | train loss 0.5535644043982029\n",
      "Epoch3937 | train loss 0.5535633202828467\n",
      "Epoch3938 | train loss 0.553562432192266\n",
      "Epoch3939 | train loss 0.5535616688989102\n",
      "Epoch3940 | train loss 0.5535611232742668\n",
      "Epoch3941 | train loss 0.5535612672753633\n",
      "Epoch3942 | train loss 0.5535602154582739\n",
      "Epoch3943 | train loss 0.5535585531964898\n",
      "Epoch3944 | train loss 0.5535597073659301\n",
      "Epoch3945 | train loss 0.5535586783476174\n",
      "Epoch3946 | train loss 0.5535583014599978\n",
      "Epoch3947 | train loss 0.5535584309324623\n",
      "Epoch3948 | train loss 0.5535563236102462\n",
      "Epoch3949 | train loss 0.5535561737045646\n",
      "Epoch3950 | train loss 0.5535565593838692\n",
      "Epoch3951 | train loss 0.5535555875301361\n",
      "Epoch3952 | train loss 0.5535542231611907\n",
      "Epoch3953 | train loss 0.5535534651391208\n",
      "Epoch3954 | train loss 0.5535546687245368\n",
      "Epoch3955 | train loss 0.553553716223687\n",
      "Epoch3956 | train loss 0.5535522220097482\n",
      "Epoch3957 | train loss 0.553552801143378\n",
      "Epoch3958 | train loss 0.5535518736764788\n",
      "Epoch3959 | train loss 0.5535519406199455\n",
      "Epoch3960 | train loss 0.5535505422204733\n",
      "Epoch3961 | train loss 0.5535483430512249\n",
      "Epoch3962 | train loss 0.553548841997981\n",
      "Epoch3963 | train loss 0.5535469577088952\n",
      "Epoch3964 | train loss 0.553548762127757\n",
      "Epoch3965 | train loss 0.5535467976890505\n",
      "Epoch3966 | train loss 0.5535453607141971\n",
      "Epoch3967 | train loss 0.5535457091033459\n",
      "Epoch3968 | train loss 0.5535444048978388\n",
      "Epoch3969 | train loss 0.5535426953434944\n",
      "Epoch3970 | train loss 0.5535435486026108\n",
      "Epoch3971 | train loss 0.5535421634465456\n",
      "Epoch3972 | train loss 0.5535425031743944\n",
      "Epoch3973 | train loss 0.5535409401915967\n",
      "Epoch3974 | train loss 0.5535408531874418\n",
      "Epoch3975 | train loss 0.553539849370718\n",
      "Epoch3976 | train loss 0.5535411455854774\n",
      "Epoch3977 | train loss 0.5535390263609589\n",
      "Epoch3978 | train loss 0.5535375503450632\n",
      "Epoch3979 | train loss 0.5535395409725606\n",
      "Epoch3980 | train loss 0.5535386761836708\n",
      "Epoch3981 | train loss 0.553535940144211\n",
      "Epoch3982 | train loss 0.5535365211591124\n",
      "Epoch3983 | train loss 0.5535369313508273\n",
      "Epoch3984 | train loss 0.553536254875362\n",
      "Epoch3985 | train loss 0.553535122461617\n",
      "Epoch3986 | train loss 0.5535359940677881\n",
      "Epoch3987 | train loss 0.5535343421064317\n",
      "Epoch3988 | train loss 0.5535344647057354\n",
      "Epoch3989 | train loss 0.5535345649719239\n",
      "Epoch3990 | train loss 0.5535333480127156\n",
      "Epoch3991 | train loss 0.5535323451645673\n",
      "Epoch3992 | train loss 0.5535330721177161\n",
      "Epoch3993 | train loss 0.5535306384600699\n",
      "Epoch3994 | train loss 0.5535301957093179\n",
      "Epoch3995 | train loss 0.5535318828187883\n",
      "Epoch3996 | train loss 0.5535313490964472\n",
      "Epoch3997 | train loss 0.5535299309715629\n",
      "Epoch3998 | train loss 0.5535303346253931\n",
      "Epoch3999 | train loss 0.5535278175398708\n",
      "Epoch4000 | train loss 0.5535292279534042\n",
      "Epoch4001 | train loss 0.5535278278030455\n",
      "Epoch4002 | train loss 0.5535296414978802\n",
      "Epoch4003 | train loss 0.5535271510109305\n",
      "Epoch4004 | train loss 0.5535286703705787\n",
      "Epoch4005 | train loss 0.5535279439017177\n",
      "Epoch4006 | train loss 0.5535270141810179\n",
      "Epoch4007 | train loss 0.5535259342379868\n",
      "Epoch4008 | train loss 0.5535272184386849\n",
      "Epoch4009 | train loss 0.5535260164178908\n",
      "Epoch4010 | train loss 0.5535249044932425\n",
      "Epoch4011 | train loss 0.5535264688357711\n",
      "Epoch4012 | train loss 0.5535263145342469\n",
      "Epoch4013 | train loss 0.5535255247727037\n",
      "Epoch4014 | train loss 0.5535235497541726\n",
      "Epoch4015 | train loss 0.5535235283337534\n",
      "Epoch4016 | train loss 0.5535229902900756\n",
      "Epoch4017 | train loss 0.5535236715897918\n",
      "Epoch4018 | train loss 0.5535227714292705\n",
      "Epoch4019 | train loss 0.5535231067985297\n",
      "Epoch4020 | train loss 0.5535213185288012\n",
      "Epoch4021 | train loss 0.5535215068422258\n",
      "Epoch4022 | train loss 0.553520396091044\n",
      "Epoch4023 | train loss 0.5535225122794509\n",
      "Epoch4024 | train loss 0.5535204925201833\n",
      "Epoch4025 | train loss 0.5535205303505063\n",
      "Epoch4026 | train loss 0.5535203959979117\n",
      "Epoch4027 | train loss 0.5535191677138209\n",
      "Epoch4028 | train loss 0.5535193299502135\n",
      "Epoch4029 | train loss 0.5535204656794668\n",
      "Epoch4030 | train loss 0.553519156165421\n",
      "Epoch4031 | train loss 0.5535202503576875\n",
      "Epoch4032 | train loss 0.5535188636742532\n",
      "Epoch4033 | train loss 0.5535176300443709\n",
      "Epoch4034 | train loss 0.5535182742960751\n",
      "Epoch4035 | train loss 0.553517441470176\n",
      "Epoch4036 | train loss 0.5535186341777444\n",
      "Epoch4037 | train loss 0.5535165461339057\n",
      "Epoch4038 | train loss 0.5535166207142175\n",
      "Epoch4039 | train loss 0.5535164662264287\n",
      "Epoch4040 | train loss 0.5535190027579665\n",
      "Epoch4041 | train loss 0.5535177487321198\n",
      "Epoch4042 | train loss 0.5535150510445237\n",
      "Epoch4043 | train loss 0.5535131007991732\n",
      "Epoch4044 | train loss 0.5535118996351958\n",
      "Epoch4045 | train loss 0.5535132832638919\n",
      "Epoch4046 | train loss 0.5535131324827671\n",
      "Epoch4047 | train loss 0.5535142050869762\n",
      "Epoch4048 | train loss 0.5535121711716056\n",
      "Epoch4049 | train loss 0.5535114414617419\n",
      "Epoch4050 | train loss 0.553509959615767\n",
      "Epoch4051 | train loss 0.553512257579714\n",
      "Epoch4052 | train loss 0.5535081060230732\n",
      "Epoch4053 | train loss 0.5535072677955032\n",
      "Epoch4054 | train loss 0.5535086837597192\n",
      "Epoch4055 | train loss 0.5535089731030166\n",
      "Epoch4056 | train loss 0.5535059956647456\n",
      "Epoch4057 | train loss 0.5535042800754308\n",
      "Epoch4058 | train loss 0.5535045336559414\n",
      "Epoch4059 | train loss 0.5535042161680758\n",
      "Epoch4060 | train loss 0.553507197778672\n",
      "Epoch4061 | train loss 0.5535035607405007\n",
      "Epoch4062 | train loss 0.5535032586939633\n",
      "Epoch4063 | train loss 0.5535040008835495\n",
      "Epoch4064 | train loss 0.5535023500025272\n",
      "Epoch4065 | train loss 0.553503248039633\n",
      "Epoch4066 | train loss 0.5534993497468531\n",
      "Epoch4067 | train loss 0.5535025865770876\n",
      "Epoch4068 | train loss 0.5535026320442558\n",
      "Epoch4069 | train loss 0.5535009250789881\n",
      "Epoch4070 | train loss 0.5535013381950558\n",
      "Epoch4071 | train loss 0.5534990938566625\n",
      "Epoch4072 | train loss 0.5534989536367356\n",
      "Epoch4073 | train loss 0.5534987838566303\n",
      "Epoch4074 | train loss 0.5535013117454946\n",
      "Epoch4075 | train loss 0.5534998541325331\n",
      "Epoch4076 | train loss 0.5534992364048957\n",
      "Epoch4077 | train loss 0.5534991111978889\n",
      "Epoch4078 | train loss 0.5534971284307539\n",
      "Epoch4079 | train loss 0.5534985289350152\n",
      "Epoch4080 | train loss 0.5534978290833533\n",
      "Epoch4081 | train loss 0.5534969765134156\n",
      "Epoch4082 | train loss 0.5534965720959008\n",
      "Epoch4083 | train loss 0.5534963847510517\n",
      "Epoch4084 | train loss 0.5534985283389687\n",
      "Epoch4085 | train loss 0.5534956896677613\n",
      "Epoch4086 | train loss 0.5534974684007465\n",
      "Epoch4087 | train loss 0.5534964580833912\n",
      "Epoch4088 | train loss 0.5534973547421396\n",
      "Epoch4089 | train loss 0.5534944315068424\n",
      "Epoch4090 | train loss 0.5534943372011185\n",
      "Epoch4091 | train loss 0.5534951304271817\n",
      "Epoch4092 | train loss 0.5534936348721385\n",
      "Epoch4093 | train loss 0.5534945554845035\n",
      "Epoch4094 | train loss 0.5534941220842302\n",
      "Epoch4095 | train loss 0.553492753636092\n",
      "Epoch4096 | train loss 0.5534920487366617\n",
      "Epoch4097 | train loss 0.5534944791160524\n",
      "Epoch4098 | train loss 0.5534915408305824\n",
      "Epoch4099 | train loss 0.5534923044405877\n",
      "Epoch4100 | train loss 0.5534920619241893\n",
      "Epoch4101 | train loss 0.5534897424839437\n",
      "Epoch4102 | train loss 0.5534901970811188\n",
      "Epoch4103 | train loss 0.5534897458553314\n",
      "Epoch4104 | train loss 0.5534914404526353\n",
      "Epoch4105 | train loss 0.5534907144494354\n",
      "Epoch4106 | train loss 0.5534907489456237\n",
      "Epoch4107 | train loss 0.5534890113584697\n",
      "Epoch4108 | train loss 0.5534886649437248\n",
      "Epoch4109 | train loss 0.5534895575232803\n",
      "Epoch4110 | train loss 0.5534892766363919\n",
      "Epoch4111 | train loss 0.553489175196737\n",
      "Epoch4112 | train loss 0.5534885085187853\n",
      "Epoch4113 | train loss 0.5534863130003214\n",
      "Epoch4114 | train loss 0.5534892788343132\n",
      "Epoch4115 | train loss 0.5534878253564238\n",
      "Epoch4116 | train loss 0.5534871599636972\n",
      "Epoch4117 | train loss 0.5534869559295476\n",
      "Epoch4118 | train loss 0.5534856658615172\n",
      "Epoch4119 | train loss 0.5534868745319546\n",
      "Epoch4120 | train loss 0.5534868141077459\n",
      "Epoch4121 | train loss 0.5534851468168199\n",
      "Epoch4122 | train loss 0.5534846758842469\n",
      "Epoch4123 | train loss 0.5534870790690184\n",
      "Epoch4124 | train loss 0.5534847396798432\n",
      "Epoch4125 | train loss 0.5534850177168846\n",
      "Epoch4126 | train loss 0.553485254123807\n",
      "Epoch4127 | train loss 0.5534834804199636\n",
      "Epoch4128 | train loss 0.5534844889305532\n",
      "Epoch4129 | train loss 0.553484282232821\n",
      "Epoch4130 | train loss 0.553481585085392\n",
      "Epoch4131 | train loss 0.5534850079379976\n",
      "Epoch4132 | train loss 0.5534809335693717\n",
      "Epoch4133 | train loss 0.5534821418300271\n",
      "Epoch4134 | train loss 0.553484834805131\n",
      "Epoch4135 | train loss 0.5534816851839424\n",
      "Epoch4136 | train loss 0.5534800437651575\n",
      "Epoch4137 | train loss 0.5534835268370807\n",
      "Epoch4138 | train loss 0.5534832378476858\n",
      "Epoch4139 | train loss 0.5534794322028757\n",
      "Epoch4140 | train loss 0.5534812399372459\n",
      "Epoch4141 | train loss 0.5534814318083227\n",
      "Epoch4142 | train loss 0.5534805477783084\n",
      "Epoch4143 | train loss 0.5534808382205665\n",
      "Epoch4144 | train loss 0.5534798852913082\n",
      "Epoch4145 | train loss 0.5534803485497832\n",
      "Epoch4146 | train loss 0.5534795827977359\n",
      "Epoch4147 | train loss 0.5534768407233059\n",
      "Epoch4148 | train loss 0.5534792738594114\n",
      "Epoch4149 | train loss 0.5534791554510593\n",
      "Epoch4150 | train loss 0.5534791005030274\n",
      "Epoch4151 | train loss 0.5534790068678558\n",
      "Epoch4152 | train loss 0.5534784411452711\n",
      "Epoch4153 | train loss 0.5534783903323114\n",
      "Epoch4154 | train loss 0.5534776115603744\n",
      "Epoch4155 | train loss 0.5534787533245981\n",
      "Epoch4156 | train loss 0.5534763229265809\n",
      "Epoch4157 | train loss 0.5534733623079956\n",
      "Epoch4158 | train loss 0.5534768218360842\n",
      "Epoch4159 | train loss 0.5534767254255712\n",
      "Epoch4160 | train loss 0.5534751271642745\n",
      "Epoch4161 | train loss 0.5534762292541564\n",
      "Epoch4162 | train loss 0.5534752213768661\n",
      "Epoch4163 | train loss 0.5534746071882546\n",
      "Epoch4164 | train loss 0.5534722844697535\n",
      "Epoch4165 | train loss 0.5534747389890253\n",
      "Epoch4166 | train loss 0.5534768629819155\n",
      "Epoch4167 | train loss 0.5534737783670426\n",
      "Epoch4168 | train loss 0.553473532218486\n",
      "Epoch4169 | train loss 0.5534741422906518\n",
      "Epoch4170 | train loss 0.5534729995392262\n",
      "Epoch4171 | train loss 0.5534716654568911\n",
      "Epoch4172 | train loss 0.5534731789492071\n",
      "Epoch4173 | train loss 0.55347184214741\n",
      "Epoch4174 | train loss 0.5534693279862404\n",
      "Epoch4175 | train loss 0.5534732500649988\n",
      "Epoch4176 | train loss 0.5534710063226521\n",
      "Epoch4177 | train loss 0.5534726495482027\n",
      "Epoch4178 | train loss 0.5534691566973925\n",
      "Epoch4179 | train loss 0.5534706111066043\n",
      "Epoch4180 | train loss 0.5534720891527831\n",
      "Epoch4181 | train loss 0.5534686214663088\n",
      "Epoch4182 | train loss 0.5534711473621428\n",
      "Epoch4183 | train loss 0.5534687761217356\n",
      "Epoch4184 | train loss 0.553468327857554\n",
      "Epoch4185 | train loss 0.5534700727276504\n",
      "Epoch4186 | train loss 0.5534691324084997\n",
      "Epoch4187 | train loss 0.55346855096519\n",
      "Epoch4188 | train loss 0.5534683666750788\n",
      "Epoch4189 | train loss 0.5534689881280065\n",
      "Epoch4190 | train loss 0.5534657028876245\n",
      "Epoch4191 | train loss 0.5534701684676111\n",
      "Epoch4192 | train loss 0.5534665683284402\n",
      "Epoch4193 | train loss 0.5534678440541029\n",
      "Epoch4194 | train loss 0.5534662288986146\n",
      "Epoch4195 | train loss 0.5534660730138421\n",
      "Epoch4196 | train loss 0.5534668249823153\n",
      "Epoch4197 | train loss 0.5534654705412686\n",
      "Epoch4198 | train loss 0.5534640765562654\n",
      "Epoch4199 | train loss 0.5534645310603082\n",
      "Epoch4200 | train loss 0.5534653688780964\n",
      "Epoch4201 | train loss 0.5534610678628087\n",
      "Epoch4202 | train loss 0.5534611110761761\n",
      "Epoch4203 | train loss 0.5534634382091462\n",
      "Epoch4204 | train loss 0.5534599727019668\n",
      "Epoch4205 | train loss 0.5534609952010214\n",
      "Epoch4206 | train loss 0.5534635162726045\n",
      "Epoch4207 | train loss 0.5534594900347293\n",
      "Epoch4208 | train loss 0.5534597401320934\n",
      "Epoch4209 | train loss 0.5534601720422506\n",
      "Epoch4210 | train loss 0.5534620120562613\n",
      "Epoch4211 | train loss 0.5534612284414471\n",
      "Epoch4212 | train loss 0.5534608778357506\n",
      "Epoch4213 | train loss 0.5534614156372846\n",
      "Epoch4214 | train loss 0.5534604225680232\n",
      "Epoch4215 | train loss 0.5534590839408338\n",
      "Epoch4216 | train loss 0.5534589892067016\n",
      "Epoch4217 | train loss 0.5534582890756429\n",
      "Epoch4218 | train loss 0.5534578297659755\n",
      "Epoch4219 | train loss 0.5534576737694442\n",
      "Epoch4220 | train loss 0.5534544430673123\n",
      "Epoch4221 | train loss 0.5534564250893891\n",
      "Epoch4222 | train loss 0.5534542768634856\n",
      "Epoch4223 | train loss 0.5534513631276786\n",
      "Epoch4224 | train loss 0.5534488355740905\n",
      "Epoch4225 | train loss 0.5534479987248778\n",
      "Epoch4226 | train loss 0.5534444834664464\n",
      "Epoch4227 | train loss 0.5534458189457655\n",
      "Epoch4228 | train loss 0.5534422854147851\n",
      "Epoch4229 | train loss 0.553440952822566\n",
      "Epoch4230 | train loss 0.5534410488605499\n",
      "Epoch4231 | train loss 0.5534416422247886\n",
      "Epoch4232 | train loss 0.5534398582205177\n",
      "Epoch4233 | train loss 0.5534387022070587\n",
      "Epoch4234 | train loss 0.5534366057254374\n",
      "Epoch4235 | train loss 0.5534357769042253\n",
      "Epoch4236 | train loss 0.5534330306574702\n",
      "Epoch4237 | train loss 0.5534325456991792\n",
      "Epoch4238 | train loss 0.5534308718889952\n",
      "Epoch4239 | train loss 0.5534311796724797\n",
      "Epoch4240 | train loss 0.5534292910993099\n",
      "Epoch4241 | train loss 0.5534286504425109\n",
      "Epoch4242 | train loss 0.5534284656494856\n",
      "Epoch4243 | train loss 0.5534292500838638\n",
      "Epoch4244 | train loss 0.55342922559008\n",
      "Epoch4245 | train loss 0.5534274508990348\n",
      "Epoch4246 | train loss 0.5534279091656208\n",
      "Epoch4247 | train loss 0.55342734541744\n",
      "Epoch4248 | train loss 0.5534262118674814\n",
      "Epoch4249 | train loss 0.5534250966459513\n",
      "Epoch4250 | train loss 0.5534261149726808\n",
      "Epoch4251 | train loss 0.5534253915585577\n",
      "Epoch4252 | train loss 0.5534246764145792\n",
      "Epoch4253 | train loss 0.5534238584898412\n",
      "Epoch4254 | train loss 0.5534253818355501\n",
      "Epoch4255 | train loss 0.55342329390347\n",
      "Epoch4256 | train loss 0.5534234149567783\n",
      "Epoch4257 | train loss 0.5534233452938497\n",
      "Epoch4258 | train loss 0.553422814309597\n",
      "Epoch4259 | train loss 0.5534227571450174\n",
      "Epoch4260 | train loss 0.5534220587462186\n",
      "Epoch4261 | train loss 0.5534211830049753\n",
      "Epoch4262 | train loss 0.5534206853248179\n",
      "Epoch4263 | train loss 0.5534205705858767\n",
      "Epoch4264 | train loss 0.5534203374199569\n",
      "Epoch4265 | train loss 0.5534201199561357\n",
      "Epoch4266 | train loss 0.5534196562878787\n",
      "Epoch4267 | train loss 0.5534174615330995\n",
      "Epoch4268 | train loss 0.5534188717789948\n",
      "Epoch4269 | train loss 0.5534188175946474\n",
      "Epoch4270 | train loss 0.553417992349714\n",
      "Epoch4271 | train loss 0.5534176950529218\n",
      "Epoch4272 | train loss 0.5534164133667946\n",
      "Epoch4273 | train loss 0.5534166342765093\n",
      "Epoch4274 | train loss 0.5534167529828846\n",
      "Epoch4275 | train loss 0.5534176709130406\n",
      "Epoch4276 | train loss 0.5534160641767084\n",
      "Epoch4277 | train loss 0.5534145496599376\n",
      "Epoch4278 | train loss 0.5534164194948972\n",
      "Epoch4279 | train loss 0.5534145350009203\n",
      "Epoch4280 | train loss 0.553415157198906\n",
      "Epoch4281 | train loss 0.5534144157730043\n",
      "Epoch4282 | train loss 0.553414279781282\n",
      "Epoch4283 | train loss 0.5534122630767524\n",
      "Epoch4284 | train loss 0.5534142886660993\n",
      "Epoch4285 | train loss 0.553413358181715\n",
      "Epoch4286 | train loss 0.5534120887517929\n",
      "Epoch4287 | train loss 0.553412676807493\n",
      "Epoch4288 | train loss 0.5534120728261769\n",
      "Epoch4289 | train loss 0.5534117478318512\n",
      "Epoch4290 | train loss 0.5534116402827203\n",
      "Epoch4291 | train loss 0.5534112020023167\n",
      "Epoch4292 | train loss 0.5534108156338334\n",
      "Epoch4293 | train loss 0.5534108652733266\n",
      "Epoch4294 | train loss 0.5534097163379192\n",
      "Epoch4295 | train loss 0.5534115472249687\n",
      "Epoch4296 | train loss 0.553410001154989\n",
      "Epoch4297 | train loss 0.5534088971838355\n",
      "Epoch4298 | train loss 0.5534097240492701\n",
      "Epoch4299 | train loss 0.5534088140167296\n",
      "Epoch4300 | train loss 0.5534086254611611\n",
      "Epoch4301 | train loss 0.553408754914999\n",
      "Epoch4302 | train loss 0.5534082006663084\n",
      "Epoch4303 | train loss 0.5534075945802033\n",
      "Epoch4304 | train loss 0.5534079324267804\n",
      "Epoch4305 | train loss 0.5534066899307072\n",
      "Epoch4306 | train loss 0.553407278265804\n",
      "Epoch4307 | train loss 0.5534071173705161\n",
      "Epoch4308 | train loss 0.5534065597504377\n",
      "Epoch4309 | train loss 0.5534060673601925\n",
      "Epoch4310 | train loss 0.553407006058842\n",
      "Epoch4311 | train loss 0.5534039434418082\n",
      "Epoch4312 | train loss 0.5534057413041592\n",
      "Epoch4313 | train loss 0.5534055482968688\n",
      "Epoch4314 | train loss 0.5534051172994077\n",
      "Epoch4315 | train loss 0.5534048944152892\n",
      "Epoch4316 | train loss 0.5534054776094854\n",
      "Epoch4317 | train loss 0.5534032066166401\n",
      "Epoch4318 | train loss 0.55340327039361\n",
      "Epoch4319 | train loss 0.5534054696373641\n",
      "Epoch4320 | train loss 0.5534042526222765\n",
      "Epoch4321 | train loss 0.5534032718837261\n",
      "Epoch4322 | train loss 0.5534031825140119\n",
      "Epoch4323 | train loss 0.5534036049246788\n",
      "Epoch4324 | train loss 0.5534016807936132\n",
      "Epoch4325 | train loss 0.553401799350977\n",
      "Epoch4326 | train loss 0.5534033650159835\n",
      "Epoch4327 | train loss 0.5534023595973849\n",
      "Epoch4328 | train loss 0.5534017752483487\n",
      "Epoch4329 | train loss 0.5534011926315725\n",
      "Epoch4330 | train loss 0.5534021561034024\n",
      "Epoch4331 | train loss 0.5534008050337433\n",
      "Epoch4332 | train loss 0.5534012151695787\n",
      "Epoch4333 | train loss 0.5534012311138212\n",
      "Epoch4334 | train loss 0.5533992569893599\n",
      "Epoch4335 | train loss 0.5534003166854382\n",
      "Epoch4336 | train loss 0.5533987906947732\n",
      "Epoch4337 | train loss 0.5534007512032986\n",
      "Epoch4338 | train loss 0.5533989525958896\n",
      "Epoch4339 | train loss 0.5533990899845957\n",
      "Epoch4340 | train loss 0.553399116024375\n",
      "Epoch4341 | train loss 0.5533983671665191\n",
      "Epoch4342 | train loss 0.55339962689206\n",
      "Epoch4343 | train loss 0.5533979497104883\n",
      "Epoch4344 | train loss 0.5533975549042225\n",
      "Epoch4345 | train loss 0.5533974439837038\n",
      "Epoch4346 | train loss 0.5533965114504099\n",
      "Epoch4347 | train loss 0.5533977674134075\n",
      "Epoch4348 | train loss 0.5533972683735192\n",
      "Epoch4349 | train loss 0.5533959155529737\n",
      "Epoch4350 | train loss 0.553396982792765\n",
      "Epoch4351 | train loss 0.5533954698033631\n",
      "Epoch4352 | train loss 0.5533960047923029\n",
      "Epoch4353 | train loss 0.5533959882706404\n",
      "Epoch4354 | train loss 0.5533949768356979\n",
      "Epoch4355 | train loss 0.5533961074240505\n",
      "Epoch4356 | train loss 0.5533948687836527\n",
      "Epoch4357 | train loss 0.5533948805555702\n",
      "Epoch4358 | train loss 0.5533958052285015\n",
      "Epoch4359 | train loss 0.5533940858766436\n",
      "Epoch4360 | train loss 0.5533939678966999\n",
      "Epoch4361 | train loss 0.553392918985337\n",
      "Epoch4362 | train loss 0.55339533502236\n",
      "Epoch4363 | train loss 0.5533917331881821\n",
      "Epoch4364 | train loss 0.5533950712531805\n",
      "Epoch4365 | train loss 0.5533926090970636\n",
      "Epoch4366 | train loss 0.5533931348286569\n",
      "Epoch4367 | train loss 0.5533940296806396\n",
      "Epoch4368 | train loss 0.5533925474993885\n",
      "Epoch4369 | train loss 0.5533934260159731\n",
      "Epoch4370 | train loss 0.5533920973539352\n",
      "Epoch4371 | train loss 0.5533928769081831\n",
      "Epoch4372 | train loss 0.553390607200563\n",
      "Epoch4373 | train loss 0.5533905121311545\n",
      "Epoch4374 | train loss 0.5533916704170406\n",
      "Epoch4375 | train loss 0.5533889342658221\n",
      "Epoch4376 | train loss 0.5533874671533704\n",
      "Epoch4377 | train loss 0.5533890527114272\n",
      "Epoch4378 | train loss 0.5533878078870476\n",
      "Epoch4379 | train loss 0.5533862688206136\n",
      "Epoch4380 | train loss 0.5533872713334859\n",
      "Epoch4381 | train loss 0.5533876109682023\n",
      "Epoch4382 | train loss 0.5533868862688541\n",
      "Epoch4383 | train loss 0.5533861966617405\n",
      "Epoch4384 | train loss 0.5533846123889089\n",
      "Epoch4385 | train loss 0.5533831757307053\n",
      "Epoch4386 | train loss 0.5533842988871038\n",
      "Epoch4387 | train loss 0.553381924033165\n",
      "Epoch4388 | train loss 0.5533822660520673\n",
      "Epoch4389 | train loss 0.5533794417232275\n",
      "Epoch4390 | train loss 0.5533772096596659\n",
      "Epoch4391 | train loss 0.5533771423995495\n",
      "Epoch4392 | train loss 0.5533772842213511\n",
      "Epoch4393 | train loss 0.5533758654259145\n",
      "Epoch4394 | train loss 0.5533745874464512\n",
      "Epoch4395 | train loss 0.5533734111860394\n",
      "Epoch4396 | train loss 0.5533706802874804\n",
      "Epoch4397 | train loss 0.5533711390011012\n",
      "Epoch4398 | train loss 0.5533701836131513\n",
      "Epoch4399 | train loss 0.5533705442398786\n",
      "Epoch4400 | train loss 0.5533689633198082\n",
      "Epoch4401 | train loss 0.5533670879900455\n",
      "Epoch4402 | train loss 0.5533693085610867\n",
      "Epoch4403 | train loss 0.5533676854893566\n",
      "Epoch4404 | train loss 0.5533668811991811\n",
      "Epoch4405 | train loss 0.5533654031157493\n",
      "Epoch4406 | train loss 0.553363447021693\n",
      "Epoch4407 | train loss 0.5533621022850275\n",
      "Epoch4408 | train loss 0.5533611105196178\n",
      "Epoch4409 | train loss 0.5533594819903374\n",
      "Epoch4410 | train loss 0.5533577279374003\n",
      "Epoch4411 | train loss 0.5533565388806164\n",
      "Epoch4412 | train loss 0.5533559093251824\n",
      "Epoch4413 | train loss 0.5533562636934221\n",
      "Epoch4414 | train loss 0.5533553173206747\n",
      "Epoch4415 | train loss 0.553354498334229\n",
      "Epoch4416 | train loss 0.5533534851484001\n",
      "Epoch4417 | train loss 0.5533524524234236\n",
      "Epoch4418 | train loss 0.5533517817221582\n",
      "Epoch4419 | train loss 0.5533513539284468\n",
      "Epoch4420 | train loss 0.5533507504314185\n",
      "Epoch4421 | train loss 0.5533498390391469\n",
      "Epoch4422 | train loss 0.553349850550294\n",
      "Epoch4423 | train loss 0.5533503054082394\n",
      "Epoch4424 | train loss 0.5533504068106413\n",
      "Epoch4425 | train loss 0.5533489855378866\n",
      "Epoch4426 | train loss 0.5533491536602377\n",
      "Epoch4427 | train loss 0.5533483995124697\n",
      "Epoch4428 | train loss 0.55334816403687\n",
      "Epoch4429 | train loss 0.5533489084802568\n",
      "Epoch4430 | train loss 0.5533460493385792\n",
      "Epoch4431 | train loss 0.5533469861373306\n",
      "Epoch4432 | train loss 0.5533470093458891\n",
      "Epoch4433 | train loss 0.5533462594263255\n",
      "Epoch4434 | train loss 0.5533462712727487\n",
      "Epoch4435 | train loss 0.553343799635768\n",
      "Epoch4436 | train loss 0.5533456196635962\n",
      "Epoch4437 | train loss 0.5533462410978973\n",
      "Epoch4438 | train loss 0.5533433005772531\n",
      "Epoch4439 | train loss 0.5533454116061329\n",
      "Epoch4440 | train loss 0.5533442919328809\n",
      "Epoch4441 | train loss 0.5533425717055798\n",
      "Epoch4442 | train loss 0.5533425188437104\n",
      "Epoch4443 | train loss 0.5533421288616955\n",
      "Epoch4444 | train loss 0.5533391723781824\n",
      "Epoch4445 | train loss 0.5533404076099395\n",
      "Epoch4446 | train loss 0.5533398618176579\n",
      "Epoch4447 | train loss 0.5533381699025631\n",
      "Epoch4448 | train loss 0.5533395290933549\n",
      "Epoch4449 | train loss 0.5533384165167808\n",
      "Epoch4450 | train loss 0.5533379308879376\n",
      "Epoch4451 | train loss 0.5533363250084221\n",
      "Epoch4452 | train loss 0.5533378979377449\n",
      "Epoch4453 | train loss 0.5533363045379519\n",
      "Epoch4454 | train loss 0.5533366394788026\n",
      "Epoch4455 | train loss 0.5533355557732285\n",
      "Epoch4456 | train loss 0.5533359150774777\n",
      "Epoch4457 | train loss 0.5533355692029\n",
      "Epoch4458 | train loss 0.5533349796198308\n",
      "Epoch4459 | train loss 0.5533345943316818\n",
      "Epoch4460 | train loss 0.5533333433046937\n",
      "Epoch4461 | train loss 0.5533343087509275\n",
      "Epoch4462 | train loss 0.5533329738676548\n",
      "Epoch4463 | train loss 0.5533335565030575\n",
      "Epoch4464 | train loss 0.5533346991799771\n",
      "Epoch4465 | train loss 0.5533332822471857\n",
      "Epoch4466 | train loss 0.5533329174108803\n",
      "Epoch4467 | train loss 0.5533308584801853\n",
      "Epoch4468 | train loss 0.5533320166170597\n",
      "Epoch4469 | train loss 0.5533328094705939\n",
      "Epoch4470 | train loss 0.5533315332233906\n",
      "Epoch4471 | train loss 0.5533322677016258\n",
      "Epoch4472 | train loss 0.5533311566896737\n",
      "Epoch4473 | train loss 0.5533322060480714\n",
      "Epoch4474 | train loss 0.5533285273425281\n",
      "Epoch4475 | train loss 0.5533303403109312\n",
      "Epoch4476 | train loss 0.5533300092257559\n",
      "Epoch4477 | train loss 0.5533286235108972\n",
      "Epoch4478 | train loss 0.553328544460237\n",
      "Epoch4479 | train loss 0.5533307079225779\n",
      "Epoch4480 | train loss 0.5533284936286509\n",
      "Epoch4481 | train loss 0.5533296089060604\n",
      "Epoch4482 | train loss 0.5533283647336066\n",
      "Epoch4483 | train loss 0.5533275280147791\n",
      "Epoch4484 | train loss 0.5533272433839739\n",
      "Epoch4485 | train loss 0.5533293294906616\n",
      "Epoch4486 | train loss 0.5533265522308648\n",
      "Epoch4487 | train loss 0.553326412346214\n",
      "Epoch4488 | train loss 0.5533274281211198\n",
      "Epoch4489 | train loss 0.5533276581950486\n",
      "Epoch4490 | train loss 0.5533255212008953\n",
      "Epoch4491 | train loss 0.5533277480490506\n",
      "Epoch4492 | train loss 0.5533258348889649\n",
      "Epoch4493 | train loss 0.5533242611773312\n",
      "Epoch4494 | train loss 0.5533261560089886\n",
      "Epoch4495 | train loss 0.5533240682631732\n",
      "Epoch4496 | train loss 0.553325986880809\n",
      "Epoch4497 | train loss 0.5533242681249976\n",
      "Epoch4498 | train loss 0.5533235573023557\n",
      "Epoch4499 | train loss 0.5533251344785094\n",
      "Epoch4500 | train loss 0.5533238273672759\n",
      "Epoch4501 | train loss 0.5533243064209818\n",
      "Epoch4502 | train loss 0.5533248974382877\n",
      "Epoch4503 | train loss 0.5533219609409571\n",
      "Epoch4504 | train loss 0.5533234807103873\n",
      "Epoch4505 | train loss 0.553323445469141\n",
      "Epoch4506 | train loss 0.5533223596028983\n",
      "Epoch4507 | train loss 0.5533230883814394\n",
      "Epoch4508 | train loss 0.5533232526667416\n",
      "Epoch4509 | train loss 0.5533220388740301\n",
      "Epoch4510 | train loss 0.5533207703195512\n",
      "Epoch4511 | train loss 0.5533224684558808\n",
      "Epoch4512 | train loss 0.5533221846446394\n",
      "Epoch4513 | train loss 0.5533211005106569\n",
      "Epoch4514 | train loss 0.5533219402842223\n",
      "Epoch4515 | train loss 0.5533191408216953\n",
      "Epoch4516 | train loss 0.5533213313855231\n",
      "Epoch4517 | train loss 0.553321220651269\n",
      "Epoch4518 | train loss 0.5533193873055279\n",
      "Epoch4519 | train loss 0.5533199829049409\n",
      "Epoch4520 | train loss 0.5533201273158193\n",
      "Epoch4521 | train loss 0.5533210011199117\n",
      "Epoch4522 | train loss 0.5533185769245028\n",
      "Epoch4523 | train loss 0.5533198251575232\n",
      "Epoch4524 | train loss 0.5533199923858046\n",
      "Epoch4525 | train loss 0.5533186531998218\n",
      "Epoch4526 | train loss 0.5533174201846123\n",
      "Epoch4527 | train loss 0.5533196950145066\n",
      "Epoch4528 | train loss 0.5533192694373429\n",
      "Epoch4529 | train loss 0.5533189740031957\n",
      "Epoch4530 | train loss 0.5533166030235589\n",
      "Epoch4531 | train loss 0.5533179412782192\n",
      "Epoch4532 | train loss 0.5533185293711722\n",
      "Epoch4533 | train loss 0.5533170146308839\n",
      "Epoch4534 | train loss 0.5533172599039972\n",
      "Epoch4535 | train loss 0.5533178092725575\n",
      "Epoch4536 | train loss 0.553315285537392\n",
      "Epoch4537 | train loss 0.5533166714012623\n",
      "Epoch4538 | train loss 0.5533173846453429\n",
      "Epoch4539 | train loss 0.553315458856523\n",
      "Epoch4540 | train loss 0.5533166861347855\n",
      "Epoch4541 | train loss 0.5533161838538945\n",
      "Epoch4542 | train loss 0.5533165988512337\n",
      "Epoch4543 | train loss 0.5533146397024393\n",
      "Epoch4544 | train loss 0.5533153106644749\n",
      "Epoch4545 | train loss 0.553315801769495\n",
      "Epoch4546 | train loss 0.5533134321682155\n",
      "Epoch4547 | train loss 0.5533153571002185\n",
      "Epoch4548 | train loss 0.553315171469003\n",
      "Epoch4549 | train loss 0.5533155798912048\n",
      "Epoch4550 | train loss 0.5533128064870835\n",
      "Epoch4551 | train loss 0.5533146009221673\n",
      "Epoch4552 | train loss 0.5533142016455531\n",
      "Epoch4553 | train loss 0.5533146305009723\n",
      "Epoch4554 | train loss 0.5533141329325736\n",
      "Epoch4555 | train loss 0.5533119985833764\n",
      "Epoch4556 | train loss 0.5533138737641274\n",
      "Epoch4557 | train loss 0.5533136314339936\n",
      "Epoch4558 | train loss 0.5533133941702545\n",
      "Epoch4559 | train loss 0.5533134621754289\n",
      "Epoch4560 | train loss 0.5533105806075036\n",
      "Epoch4561 | train loss 0.5533128257282078\n",
      "Epoch4562 | train loss 0.5533127399347723\n",
      "Epoch4563 | train loss 0.5533131076768041\n",
      "Epoch4564 | train loss 0.5533125890605152\n",
      "Epoch4565 | train loss 0.5533106369525194\n",
      "Epoch4566 | train loss 0.5533117212541402\n",
      "Epoch4567 | train loss 0.5533116763457656\n",
      "Epoch4568 | train loss 0.5533116933330894\n",
      "Epoch4569 | train loss 0.5533092571422458\n",
      "Epoch4570 | train loss 0.5533112899586559\n",
      "Epoch4571 | train loss 0.5533109581843019\n",
      "Epoch4572 | train loss 0.5533109723590315\n",
      "Epoch4573 | train loss 0.5533085691183806\n",
      "Epoch4574 | train loss 0.5533105995133519\n",
      "Epoch4575 | train loss 0.5533107379451394\n",
      "Epoch4576 | train loss 0.5533108098618686\n",
      "Epoch4577 | train loss 0.5533090990409255\n",
      "Epoch4578 | train loss 0.5533098167181015\n",
      "Epoch4579 | train loss 0.5533100336417556\n",
      "Epoch4580 | train loss 0.553309531249106\n",
      "Epoch4581 | train loss 0.5533095666766167\n",
      "Epoch4582 | train loss 0.5533094455860555\n",
      "Epoch4583 | train loss 0.5533079771697521\n",
      "Epoch4584 | train loss 0.5533086279407143\n",
      "Epoch4585 | train loss 0.5533086564950644\n",
      "Epoch4586 | train loss 0.5533087893947959\n",
      "Epoch4587 | train loss 0.5533064703829587\n",
      "Epoch4588 | train loss 0.553308483120054\n",
      "Epoch4589 | train loss 0.5533077823370696\n",
      "Epoch4590 | train loss 0.5533059822954237\n",
      "Epoch4591 | train loss 0.5533078452385962\n",
      "Epoch4592 | train loss 0.5533073555864394\n",
      "Epoch4593 | train loss 0.553308042474091\n",
      "Epoch4594 | train loss 0.5533073224313557\n",
      "Epoch4595 | train loss 0.5533069535344839\n",
      "Epoch4596 | train loss 0.5533052412606776\n",
      "Epoch4597 | train loss 0.5533069892041386\n",
      "Epoch4598 | train loss 0.5533068173751235\n",
      "Epoch4599 | train loss 0.5533047440834343\n",
      "Epoch4600 | train loss 0.5533060489594936\n",
      "Epoch4601 | train loss 0.5533063654787839\n",
      "Epoch4602 | train loss 0.5533058391883969\n",
      "Epoch4603 | train loss 0.553305606842041\n",
      "Epoch4604 | train loss 0.5533050433732569\n",
      "Epoch4605 | train loss 0.5533032700233161\n",
      "Epoch4606 | train loss 0.5533047511428595\n",
      "Epoch4607 | train loss 0.553305008802563\n",
      "Epoch4608 | train loss 0.553304933141917\n",
      "Epoch4609 | train loss 0.5533050160482526\n",
      "Epoch4610 | train loss 0.5533038668148219\n",
      "Epoch4611 | train loss 0.5533034587837755\n",
      "Epoch4612 | train loss 0.5533044900558889\n",
      "Epoch4613 | train loss 0.5533022174797952\n",
      "Epoch4614 | train loss 0.5533031080663204\n",
      "Epoch4615 | train loss 0.5533037904463708\n",
      "Epoch4616 | train loss 0.5533026698976755\n",
      "Epoch4617 | train loss 0.5533032097853721\n",
      "Epoch4618 | train loss 0.5533029704354704\n",
      "Epoch4619 | train loss 0.5533008025586605\n",
      "Epoch4620 | train loss 0.5533027091994882\n",
      "Epoch4621 | train loss 0.5533025965280831\n",
      "Epoch4622 | train loss 0.5533028590865433\n",
      "Epoch4623 | train loss 0.5533017550036311\n",
      "Epoch4624 | train loss 0.5533020726032555\n",
      "Epoch4625 | train loss 0.5533013994060457\n",
      "Epoch4626 | train loss 0.5533021325618028\n",
      "Epoch4627 | train loss 0.5533024307340384\n",
      "Epoch4628 | train loss 0.5533005068451167\n",
      "Epoch4629 | train loss 0.5533009541034698\n",
      "Epoch4630 | train loss 0.5533018614910543\n",
      "Epoch4631 | train loss 0.5533005565032363\n",
      "Epoch4632 | train loss 0.5533004132099449\n",
      "Epoch4633 | train loss 0.5533006137795746\n",
      "Epoch4634 | train loss 0.553300655465573\n",
      "Epoch4635 | train loss 0.5533007284812629\n",
      "Epoch4636 | train loss 0.553299940880388\n",
      "Epoch4637 | train loss 0.5533002134971321\n",
      "Epoch4638 | train loss 0.5533002266474069\n",
      "Epoch4639 | train loss 0.5533002743683756\n",
      "Epoch4640 | train loss 0.5532992184534669\n",
      "Epoch4641 | train loss 0.5532996566221118\n",
      "Epoch4642 | train loss 0.5532990287430585\n",
      "Epoch4643 | train loss 0.5532993075437844\n",
      "Epoch4644 | train loss 0.5532995255477726\n",
      "Epoch4645 | train loss 0.5532997321337462\n",
      "Epoch4646 | train loss 0.5532982550747693\n",
      "Epoch4647 | train loss 0.5532995826564729\n",
      "Epoch4648 | train loss 0.5532984203845263\n",
      "Epoch4649 | train loss 0.5532982744649053\n",
      "Epoch4650 | train loss 0.5532983556389809\n",
      "Epoch4651 | train loss 0.55329829454422\n",
      "Epoch4652 | train loss 0.5532981144264341\n",
      "Epoch4653 | train loss 0.5532985721342265\n",
      "Epoch4654 | train loss 0.5532981046289206\n",
      "Epoch4655 | train loss 0.5532973600551486\n",
      "Epoch4656 | train loss 0.5532974415831268\n",
      "Epoch4657 | train loss 0.5532971986383199\n",
      "Epoch4658 | train loss 0.5532973347045481\n",
      "Epoch4659 | train loss 0.5532979285158217\n",
      "Epoch4660 | train loss 0.5532972673140466\n",
      "Epoch4661 | train loss 0.5532968700677157\n",
      "Epoch4662 | train loss 0.5532975320890546\n",
      "Epoch4663 | train loss 0.5532961606606841\n",
      "Epoch4664 | train loss 0.5532963355258107\n",
      "Epoch4665 | train loss 0.5532966216094792\n",
      "Epoch4666 | train loss 0.5532968267798424\n",
      "Epoch4667 | train loss 0.5532960238866508\n",
      "Epoch4668 | train loss 0.5532952159829437\n",
      "Epoch4669 | train loss 0.553296208884567\n",
      "Epoch4670 | train loss 0.5532953188009561\n",
      "Epoch4671 | train loss 0.5532958216220141\n",
      "Epoch4672 | train loss 0.5532966159842908\n",
      "Epoch4673 | train loss 0.5532955276221037\n",
      "Epoch4674 | train loss 0.5532949527353048\n",
      "Epoch4675 | train loss 0.5532959633134306\n",
      "Epoch4676 | train loss 0.5532944155111909\n",
      "Epoch4677 | train loss 0.5532952608726919\n",
      "Epoch4678 | train loss 0.5532944530434907\n",
      "Epoch4679 | train loss 0.553295711055398\n",
      "Epoch4680 | train loss 0.5532946696691216\n",
      "Epoch4681 | train loss 0.5532945539988577\n",
      "Epoch4682 | train loss 0.5532934957556427\n",
      "Epoch4683 | train loss 0.553293908443302\n",
      "Epoch4684 | train loss 0.5532952464744448\n",
      "Epoch4685 | train loss 0.5532942811958492\n",
      "Epoch4686 | train loss 0.5532936132140458\n",
      "Epoch4687 | train loss 0.5532940299995244\n",
      "Epoch4688 | train loss 0.5532936950959265\n",
      "Epoch4689 | train loss 0.5532937899418175\n",
      "Epoch4690 | train loss 0.5532947295531631\n",
      "Epoch4691 | train loss 0.5532935687154531\n",
      "Epoch4692 | train loss 0.5532928050123155\n",
      "Epoch4693 | train loss 0.5532929032854735\n",
      "Epoch4694 | train loss 0.5532933084666729\n",
      "Epoch4695 | train loss 0.5532941005006432\n",
      "Epoch4696 | train loss 0.5532924742437899\n",
      "Epoch4697 | train loss 0.5532932505011559\n",
      "Epoch4698 | train loss 0.5532923073507845\n",
      "Epoch4699 | train loss 0.553292406462133\n",
      "Epoch4700 | train loss 0.5532928726449609\n",
      "Epoch4701 | train loss 0.5532932683452964\n",
      "Epoch4702 | train loss 0.5532930246554315\n",
      "Epoch4703 | train loss 0.5532927821204067\n",
      "Epoch4704 | train loss 0.5532922912016511\n",
      "Epoch4705 | train loss 0.5532924112118781\n",
      "Epoch4706 | train loss 0.5532918426021933\n",
      "Epoch4707 | train loss 0.5532905981130898\n",
      "Epoch4708 | train loss 0.5532906703278422\n",
      "Epoch4709 | train loss 0.5532916813343763\n",
      "Epoch4710 | train loss 0.5532906027697027\n",
      "Epoch4711 | train loss 0.5532911456376314\n",
      "Epoch4712 | train loss 0.5532902915589512\n",
      "Epoch4713 | train loss 0.5532905783690513\n",
      "Epoch4714 | train loss 0.5532900465093553\n",
      "Epoch4715 | train loss 0.5532910534739495\n",
      "Epoch4716 | train loss 0.5532908678986133\n",
      "Epoch4717 | train loss 0.5532900341413916\n",
      "Epoch4718 | train loss 0.5532895359024406\n",
      "Epoch4719 | train loss 0.5532895711436868\n",
      "Epoch4720 | train loss 0.5532898896001279\n",
      "Epoch4721 | train loss 0.5532894656807185\n",
      "Epoch4722 | train loss 0.5532891413010657\n",
      "Epoch4723 | train loss 0.553289991542697\n",
      "Epoch4724 | train loss 0.5532888761162758\n",
      "Epoch4725 | train loss 0.5532889129035174\n",
      "Epoch4726 | train loss 0.5532888892479241\n",
      "Epoch4727 | train loss 0.5532888806611299\n",
      "Epoch4728 | train loss 0.5532889167591929\n",
      "Epoch4729 | train loss 0.5532884034328163\n",
      "Epoch4730 | train loss 0.5532892201654613\n",
      "Epoch4731 | train loss 0.5532880426943302\n",
      "Epoch4732 | train loss 0.553288106508553\n",
      "Epoch4733 | train loss 0.5532890698499977\n",
      "Epoch4734 | train loss 0.5532878063991666\n",
      "Epoch4735 | train loss 0.5532878051325679\n",
      "Epoch4736 | train loss 0.5532882106676698\n",
      "Epoch4737 | train loss 0.5532871944271028\n",
      "Epoch4738 | train loss 0.5532874103076756\n",
      "Epoch4739 | train loss 0.5532871343381703\n",
      "Epoch4740 | train loss 0.5532880233600735\n",
      "Epoch4741 | train loss 0.5532872121036053\n",
      "Epoch4742 | train loss 0.5532870562560857\n",
      "Epoch4743 | train loss 0.5532861970365047\n",
      "Epoch4744 | train loss 0.5532873159833253\n",
      "Epoch4745 | train loss 0.5532866686955095\n",
      "Epoch4746 | train loss 0.5532874758914113\n",
      "Epoch4747 | train loss 0.5532865106314421\n",
      "Epoch4748 | train loss 0.5532866461016238\n",
      "Epoch4749 | train loss 0.5532868240214884\n",
      "Epoch4750 | train loss 0.5532860037498176\n",
      "Epoch4751 | train loss 0.5532858205586672\n",
      "Epoch4752 | train loss 0.5532859735004604\n",
      "Epoch4753 | train loss 0.5532862025313079\n",
      "Epoch4754 | train loss 0.5532865064963698\n",
      "Epoch4755 | train loss 0.5532860823348165\n",
      "Epoch4756 | train loss 0.5532854229025542\n",
      "Epoch4757 | train loss 0.5532859513536096\n",
      "Epoch4758 | train loss 0.5532852055132389\n",
      "Epoch4759 | train loss 0.5532853368297219\n",
      "Epoch4760 | train loss 0.5532857919484377\n",
      "Epoch4761 | train loss 0.553284812066704\n",
      "Epoch4762 | train loss 0.5532857546396553\n",
      "Epoch4763 | train loss 0.5532845543138682\n",
      "Epoch4764 | train loss 0.5532848173566163\n",
      "Epoch4765 | train loss 0.553284262008965\n",
      "Epoch4766 | train loss 0.5532852767035366\n",
      "Epoch4767 | train loss 0.5532843049243092\n",
      "Epoch4768 | train loss 0.5532850506342948\n",
      "Epoch4769 | train loss 0.5532842564582825\n",
      "Epoch4770 | train loss 0.5532834814116359\n",
      "Epoch4771 | train loss 0.5532840395532549\n",
      "Epoch4772 | train loss 0.5532847613096237\n",
      "Epoch4773 | train loss 0.553283602334559\n",
      "Epoch4774 | train loss 0.5532844286970794\n",
      "Epoch4775 | train loss 0.5532833559811116\n",
      "Epoch4776 | train loss 0.5532832986675202\n",
      "Epoch4777 | train loss 0.5532835342548788\n",
      "Epoch4778 | train loss 0.5532831906527281\n",
      "Epoch4779 | train loss 0.5532833630591631\n",
      "Epoch4780 | train loss 0.5532831254228949\n",
      "Epoch4781 | train loss 0.5532839152216912\n",
      "Epoch4782 | train loss 0.5532830461859704\n",
      "Epoch4783 | train loss 0.553282686918974\n",
      "Epoch4784 | train loss 0.5532835736498236\n",
      "Epoch4785 | train loss 0.5532828839495778\n",
      "Epoch4786 | train loss 0.5532817801833153\n",
      "Epoch4787 | train loss 0.5532832534611225\n",
      "Epoch4788 | train loss 0.5532816277258098\n",
      "Epoch4789 | train loss 0.553282118178904\n",
      "Epoch4790 | train loss 0.5532829564064741\n",
      "Epoch4791 | train loss 0.5532821276411414\n",
      "Epoch4792 | train loss 0.5532826018705964\n",
      "Epoch4793 | train loss 0.5532821558229625\n",
      "Epoch4794 | train loss 0.5532828372903168\n",
      "Epoch4795 | train loss 0.5532828904874623\n",
      "Epoch4796 | train loss 0.55328160578385\n",
      "Epoch4797 | train loss 0.5532816601172089\n",
      "Epoch4798 | train loss 0.5532820448465645\n",
      "Epoch4799 | train loss 0.5532822543941438\n",
      "Epoch4800 | train loss 0.5532819229736924\n",
      "Epoch4801 | train loss 0.5532820340432226\n",
      "Epoch4802 | train loss 0.5532821735739708\n",
      "Epoch4803 | train loss 0.5532820620760321\n",
      "Epoch4804 | train loss 0.5532809641771018\n",
      "Epoch4805 | train loss 0.5532812566682697\n",
      "Epoch4806 | train loss 0.5532810325734318\n",
      "Epoch4807 | train loss 0.5532815437950194\n",
      "Epoch4808 | train loss 0.5532811351120472\n",
      "Epoch4809 | train loss 0.55328090114519\n",
      "Epoch4810 | train loss 0.5532811726257205\n",
      "Epoch4811 | train loss 0.5532806142605842\n",
      "Epoch4812 | train loss 0.553280275799334\n",
      "Epoch4813 | train loss 0.5532809584960341\n",
      "Epoch4814 | train loss 0.5532811446487904\n",
      "Epoch4815 | train loss 0.5532808551564813\n",
      "Epoch4816 | train loss 0.5532801950909197\n",
      "Epoch4817 | train loss 0.5532796757668257\n",
      "Epoch4818 | train loss 0.5532799189165235\n",
      "Epoch4819 | train loss 0.55328043974936\n",
      "Epoch4820 | train loss 0.5532803956791759\n",
      "Epoch4821 | train loss 0.5532793978787959\n",
      "Epoch4822 | train loss 0.5532801881805063\n",
      "Epoch4823 | train loss 0.5532797895371914\n",
      "Epoch4824 | train loss 0.5532799414359033\n",
      "Epoch4825 | train loss 0.5532797381095588\n",
      "Epoch4826 | train loss 0.5532786316983401\n",
      "Epoch4827 | train loss 0.5532790233939886\n",
      "Epoch4828 | train loss 0.5532794288732111\n",
      "Epoch4829 | train loss 0.5532787410728633\n",
      "Epoch4830 | train loss 0.5532787638530136\n",
      "Epoch4831 | train loss 0.5532783172652125\n",
      "Epoch4832 | train loss 0.5532791606336832\n",
      "Epoch4833 | train loss 0.5532784757390619\n",
      "Epoch4834 | train loss 0.5532781948335469\n",
      "Epoch4835 | train loss 0.553279067389667\n",
      "Epoch4836 | train loss 0.5532779020257295\n",
      "Epoch4837 | train loss 0.5532790075056255\n",
      "Epoch4838 | train loss 0.5532786644995212\n",
      "Epoch4839 | train loss 0.5532772193849087\n",
      "Epoch4840 | train loss 0.5532781127467752\n",
      "Epoch4841 | train loss 0.5532778360694647\n",
      "Epoch4842 | train loss 0.5532781030423939\n",
      "Epoch4843 | train loss 0.5532779780775309\n",
      "Epoch4844 | train loss 0.5532770333997905\n",
      "Epoch4845 | train loss 0.5532770770974458\n",
      "Epoch4846 | train loss 0.5532782782614231\n",
      "Epoch4847 | train loss 0.5532777166366577\n",
      "Epoch4848 | train loss 0.5532764408364892\n",
      "Epoch4849 | train loss 0.5532772738859058\n",
      "Epoch4850 | train loss 0.5532760754041374\n",
      "Epoch4851 | train loss 0.5532761837728322\n",
      "Epoch4852 | train loss 0.5532759696803987\n",
      "Epoch4853 | train loss 0.5532773976400495\n",
      "Epoch4854 | train loss 0.553276303075254\n",
      "Epoch4855 | train loss 0.5532749450020492\n",
      "Epoch4856 | train loss 0.553276724498719\n",
      "Epoch4857 | train loss 0.5532764493301511\n",
      "Epoch4858 | train loss 0.5532755591161549\n",
      "Epoch4859 | train loss 0.5532755426131188\n",
      "Epoch4860 | train loss 0.5532749372534453\n",
      "Epoch4861 | train loss 0.5532766865938902\n",
      "Epoch4862 | train loss 0.5532758725620807\n",
      "Epoch4863 | train loss 0.5532750503346324\n",
      "Epoch4864 | train loss 0.5532751081697643\n",
      "Epoch4865 | train loss 0.5532753332331777\n",
      "Epoch4866 | train loss 0.5532756853476166\n",
      "Epoch4867 | train loss 0.5532758172787726\n",
      "Epoch4868 | train loss 0.5532749858498573\n",
      "Epoch4869 | train loss 0.5532754544913768\n",
      "Epoch4870 | train loss 0.553273928258568\n",
      "Epoch4871 | train loss 0.553275741674006\n",
      "Epoch4872 | train loss 0.5532740890979767\n",
      "Epoch4873 | train loss 0.5532744042575359\n",
      "Epoch4874 | train loss 0.5532751178555191\n",
      "Epoch4875 | train loss 0.553274710662663\n",
      "Epoch4876 | train loss 0.5532742946222424\n",
      "Epoch4877 | train loss 0.5532745774276555\n",
      "Epoch4878 | train loss 0.5532739380374551\n",
      "Epoch4879 | train loss 0.5532744283229113\n",
      "Epoch4880 | train loss 0.5532737615704536\n",
      "Epoch4881 | train loss 0.5532735219225288\n",
      "Epoch4882 | train loss 0.5532744927331805\n",
      "Epoch4883 | train loss 0.5532738444954157\n",
      "Epoch4884 | train loss 0.5532730943709612\n",
      "Epoch4885 | train loss 0.5532733310386538\n",
      "Epoch4886 | train loss 0.5532740116491914\n",
      "Epoch4887 | train loss 0.5532742517441511\n",
      "Epoch4888 | train loss 0.5532731322571636\n",
      "Epoch4889 | train loss 0.5532736038416624\n",
      "Epoch4890 | train loss 0.5532733385264873\n",
      "Epoch4891 | train loss 0.5532727427221835\n",
      "Epoch4892 | train loss 0.5532735330052674\n",
      "Epoch4893 | train loss 0.5532726054824889\n",
      "Epoch4894 | train loss 0.5532728158868849\n",
      "Epoch4895 | train loss 0.5532722083292901\n",
      "Epoch4896 | train loss 0.5532727869972587\n",
      "Epoch4897 | train loss 0.5532721012458205\n",
      "Epoch4898 | train loss 0.5532727156020701\n",
      "Epoch4899 | train loss 0.5532726891152561\n",
      "Epoch4900 | train loss 0.5532723657600581\n",
      "Epoch4901 | train loss 0.5532708611525595\n",
      "Epoch4902 | train loss 0.553272557631135\n",
      "Epoch4903 | train loss 0.5532723956182599\n",
      "Epoch4904 | train loss 0.5532711992226541\n",
      "Epoch4905 | train loss 0.55327224239707\n",
      "Epoch4906 | train loss 0.553270890135318\n",
      "Epoch4907 | train loss 0.5532713490538299\n",
      "Epoch4908 | train loss 0.5532713625021279\n",
      "Epoch4909 | train loss 0.553270966168493\n",
      "Epoch4910 | train loss 0.5532719151303173\n",
      "Epoch4911 | train loss 0.5532716909609735\n",
      "Epoch4912 | train loss 0.5532712485268712\n",
      "Epoch4913 | train loss 0.5532704945094884\n",
      "Epoch4914 | train loss 0.5532712566293776\n",
      "Epoch4915 | train loss 0.5532712188363075\n",
      "Epoch4916 | train loss 0.5532700453326106\n",
      "Epoch4917 | train loss 0.553271237295121\n",
      "Epoch4918 | train loss 0.5532704131118953\n",
      "Epoch4919 | train loss 0.5532703689485788\n",
      "Epoch4920 | train loss 0.5532710975408555\n",
      "Epoch4921 | train loss 0.5532710628397762\n",
      "Epoch4922 | train loss 0.553269923273474\n",
      "Epoch4923 | train loss 0.5532708851993084\n",
      "Epoch4924 | train loss 0.553270291686058\n",
      "Epoch4925 | train loss 0.5532698706164956\n",
      "Epoch4926 | train loss 0.5532700346037746\n",
      "Epoch4927 | train loss 0.5532702040858567\n",
      "Epoch4928 | train loss 0.5532694654911756\n",
      "Epoch4929 | train loss 0.5532701760716736\n",
      "Epoch4930 | train loss 0.5532703224755824\n",
      "Epoch4931 | train loss 0.5532692929543555\n",
      "Epoch4932 | train loss 0.553270250633359\n",
      "Epoch4933 | train loss 0.5532698869518936\n",
      "Epoch4934 | train loss 0.5532693877071142\n",
      "Epoch4935 | train loss 0.5532699558883906\n",
      "Epoch4936 | train loss 0.553268527686596\n",
      "Epoch4937 | train loss 0.5532698040455579\n",
      "Epoch4938 | train loss 0.5532698096893728\n",
      "Epoch4939 | train loss 0.5532686839066446\n",
      "Epoch4940 | train loss 0.5532693778164685\n",
      "Epoch4941 | train loss 0.5532693705521524\n",
      "Epoch4942 | train loss 0.5532681403309107\n",
      "Epoch4943 | train loss 0.5532693917118013\n",
      "Epoch4944 | train loss 0.5532690833695233\n",
      "Epoch4945 | train loss 0.5532687005028128\n",
      "Epoch4946 | train loss 0.5532689213566482\n",
      "Epoch4947 | train loss 0.5532680311240256\n",
      "Epoch4948 | train loss 0.5532689862512052\n",
      "Epoch4949 | train loss 0.5532681046240032\n",
      "Epoch4950 | train loss 0.5532690748013556\n",
      "Epoch4951 | train loss 0.5532670720107853\n",
      "Epoch4952 | train loss 0.5532684507220984\n",
      "Epoch4953 | train loss 0.5532686484232545\n",
      "Epoch4954 | train loss 0.5532685008645057\n",
      "Epoch4955 | train loss 0.5532675540074706\n",
      "Epoch4956 | train loss 0.5532683912478388\n",
      "Epoch4957 | train loss 0.5532680995017291\n",
      "Epoch4958 | train loss 0.5532681307569146\n",
      "Epoch4959 | train loss 0.5532682986557483\n",
      "Epoch4960 | train loss 0.5532672669552267\n",
      "Epoch4961 | train loss 0.5532675669528544\n",
      "Epoch4962 | train loss 0.5532674605213106\n",
      "Epoch4963 | train loss 0.5532680873014033\n",
      "Epoch4964 | train loss 0.5532680673897267\n",
      "Epoch4965 | train loss 0.5532663418911398\n",
      "Epoch4966 | train loss 0.553267791736871\n",
      "Epoch4967 | train loss 0.5532676876522601\n",
      "Epoch4968 | train loss 0.5532671712897718\n",
      "Epoch4969 | train loss 0.5532665150240064\n",
      "Epoch4970 | train loss 0.5532671447098255\n",
      "Epoch4971 | train loss 0.5532674886472523\n",
      "Epoch4972 | train loss 0.5532665579766035\n",
      "Epoch4973 | train loss 0.553267143573612\n",
      "Epoch4974 | train loss 0.5532661896198988\n",
      "Epoch4975 | train loss 0.5532674829103053\n",
      "Epoch4976 | train loss 0.5532670176774264\n",
      "Epoch4977 | train loss 0.5532655440084636\n",
      "Epoch4978 | train loss 0.5532668668217957\n",
      "Epoch4979 | train loss 0.5532665661722421\n",
      "Epoch4980 | train loss 0.5532656316831708\n",
      "Epoch4981 | train loss 0.5532663275673986\n",
      "Epoch4982 | train loss 0.553266825415194\n",
      "Epoch4983 | train loss 0.5532662581279874\n",
      "Epoch4984 | train loss 0.5532660672999918\n",
      "Epoch4985 | train loss 0.5532661156542599\n",
      "Epoch4986 | train loss 0.5532653971388936\n",
      "Epoch4987 | train loss 0.5532666572369636\n",
      "Epoch4988 | train loss 0.5532658423297108\n",
      "Epoch4989 | train loss 0.5532661199569702\n",
      "Epoch4990 | train loss 0.5532652602903545\n",
      "Epoch4991 | train loss 0.5532661324366928\n",
      "Epoch4992 | train loss 0.5532659283280372\n",
      "Epoch4993 | train loss 0.5532649607025086\n",
      "Epoch4994 | train loss 0.5532660109549761\n",
      "Epoch4995 | train loss 0.5532652695290744\n",
      "Epoch4996 | train loss 0.5532655513286591\n",
      "Epoch4997 | train loss 0.5532657112367452\n",
      "Epoch4998 | train loss 0.5532650044560432\n",
      "Epoch4999 | train loss 0.5532653315551579\n",
      "Epoch5000 | train loss 0.5532652078196406\n",
      "Epoch5001 | train loss 0.5532650456577539\n",
      "Epoch5002 | train loss 0.553265167903155\n",
      "Epoch5003 | train loss 0.5532639285549521\n",
      "Epoch5004 | train loss 0.5532649812288583\n",
      "Epoch5005 | train loss 0.5532649367675185\n",
      "Epoch5006 | train loss 0.5532651379145682\n",
      "Epoch5007 | train loss 0.553264893963933\n",
      "Epoch5008 | train loss 0.5532642636075615\n",
      "Epoch5009 | train loss 0.5532646563649177\n",
      "Epoch5010 | train loss 0.5532644246518612\n",
      "Epoch5011 | train loss 0.553264437392354\n",
      "Epoch5012 | train loss 0.5532641972787679\n",
      "Epoch5013 | train loss 0.5532643751055002\n",
      "Epoch5014 | train loss 0.5532642170973122\n",
      "Epoch5015 | train loss 0.5532636840082705\n",
      "Epoch5016 | train loss 0.5532644152455032\n",
      "Epoch5017 | train loss 0.5532637382671237\n",
      "Epoch5018 | train loss 0.5532637626864017\n",
      "Epoch5019 | train loss 0.5532639085128903\n",
      "Epoch5020 | train loss 0.5532636541500687\n",
      "Epoch5021 | train loss 0.5532641201093793\n",
      "Epoch5022 | train loss 0.5532637904584408\n",
      "Epoch5023 | train loss 0.553263193629682\n",
      "Epoch5024 | train loss 0.5532634949684143\n",
      "Epoch5025 | train loss 0.5532633614167571\n",
      "Epoch5026 | train loss 0.553263518344611\n",
      "Epoch5027 | train loss 0.553263664599508\n",
      "Epoch5028 | train loss 0.5532633097283542\n",
      "Epoch5029 | train loss 0.5532632601633668\n",
      "Epoch5030 | train loss 0.5532632739469409\n",
      "Epoch5031 | train loss 0.5532627690024674\n",
      "Epoch5032 | train loss 0.553262896463275\n",
      "Epoch5033 | train loss 0.5532631550356746\n",
      "Epoch5034 | train loss 0.5532627390138805\n",
      "Epoch5035 | train loss 0.5532628909312188\n",
      "Epoch5036 | train loss 0.5532630897127092\n",
      "Epoch5037 | train loss 0.5532628174126148\n",
      "Epoch5038 | train loss 0.5532624739594758\n",
      "Epoch5039 | train loss 0.5532621874287724\n",
      "Epoch5040 | train loss 0.5532626480795443\n",
      "Epoch5041 | train loss 0.553262353092432\n",
      "Epoch5042 | train loss 0.5532623256742955\n",
      "Epoch5043 | train loss 0.5532622413523495\n",
      "Epoch5044 | train loss 0.5532618805952371\n",
      "Epoch5045 | train loss 0.5532620220072567\n",
      "Epoch5046 | train loss 0.5532623628340662\n",
      "Epoch5047 | train loss 0.5532621652632952\n",
      "Epoch5048 | train loss 0.5532619588077068\n",
      "Epoch5049 | train loss 0.5532619228027761\n",
      "Epoch5050 | train loss 0.5532615293189883\n",
      "Epoch5051 | train loss 0.5532618160359561\n",
      "Epoch5052 | train loss 0.5532614849507809\n",
      "Epoch5053 | train loss 0.553261426948011\n",
      "Epoch5054 | train loss 0.5532615859061479\n",
      "Epoch5055 | train loss 0.5532618688233196\n",
      "Epoch5056 | train loss 0.5532615547440947\n",
      "Epoch5057 | train loss 0.5532609423436224\n",
      "Epoch5058 | train loss 0.5532613277994096\n",
      "Epoch5059 | train loss 0.5532614622265101\n",
      "Epoch5060 | train loss 0.5532612554728985\n",
      "Epoch5061 | train loss 0.5532612225785851\n",
      "Epoch5062 | train loss 0.5532614064961672\n",
      "Epoch5063 | train loss 0.553260565251112\n",
      "Epoch5064 | train loss 0.5532608284801245\n",
      "Epoch5065 | train loss 0.5532611407153308\n",
      "Epoch5066 | train loss 0.5532609766162931\n",
      "Epoch5067 | train loss 0.5532609344087541\n",
      "Epoch5068 | train loss 0.5532608013041318\n",
      "Epoch5069 | train loss 0.5532603220455349\n",
      "Epoch5070 | train loss 0.5532608339749276\n",
      "Epoch5071 | train loss 0.5532610664516687\n",
      "Epoch5072 | train loss 0.5532603288814425\n",
      "Epoch5073 | train loss 0.5532610865682364\n",
      "Epoch5074 | train loss 0.5532611734233797\n",
      "Epoch5075 | train loss 0.553260787371546\n",
      "Epoch5076 | train loss 0.553260340411216\n",
      "Epoch5077 | train loss 0.5532603517360986\n",
      "Epoch5078 | train loss 0.5532604465447366\n",
      "Epoch5079 | train loss 0.5532606381736695\n",
      "Epoch5080 | train loss 0.553260272052139\n",
      "Epoch5081 | train loss 0.5532601928152144\n",
      "Epoch5082 | train loss 0.5532599500566721\n",
      "Epoch5083 | train loss 0.5532601422443986\n",
      "Epoch5084 | train loss 0.5532600614614784\n",
      "Epoch5085 | train loss 0.5532602747529745\n",
      "Epoch5086 | train loss 0.5532600031793118\n",
      "Epoch5087 | train loss 0.5532593187876046\n",
      "Epoch5088 | train loss 0.5532599587365985\n",
      "Epoch5089 | train loss 0.5532598372921348\n",
      "Epoch5090 | train loss 0.5532597007229925\n",
      "Epoch5091 | train loss 0.5532594906724989\n",
      "Epoch5092 | train loss 0.5532596862129867\n",
      "Epoch5093 | train loss 0.5532595263980329\n",
      "Epoch5094 | train loss 0.5532596200145781\n",
      "Epoch5095 | train loss 0.5532591102831066\n",
      "Epoch5096 | train loss 0.5532588729821145\n",
      "Epoch5097 | train loss 0.5532591942697763\n",
      "Epoch5098 | train loss 0.5532591821439564\n",
      "Epoch5099 | train loss 0.5532594082504511\n",
      "Epoch5100 | train loss 0.5532593044638634\n",
      "Epoch5101 | train loss 0.5532595421932638\n",
      "Epoch5102 | train loss 0.5532592489384115\n",
      "Epoch5103 | train loss 0.5532575412653387\n",
      "Epoch5104 | train loss 0.5532575106061995\n",
      "Epoch5105 | train loss 0.5532572949677705\n",
      "Epoch5106 | train loss 0.5532568930462003\n",
      "Epoch5107 | train loss 0.5532580724544823\n",
      "Epoch5108 | train loss 0.553256646785885\n",
      "Epoch5109 | train loss 0.5532575639523566\n",
      "Epoch5110 | train loss 0.5532567412778735\n",
      "Epoch5111 | train loss 0.5532585016638041\n",
      "Epoch5112 | train loss 0.5532566801086068\n",
      "Epoch5113 | train loss 0.5532563376799225\n",
      "Epoch5114 | train loss 0.5532570360600948\n",
      "Epoch5115 | train loss 0.5532570013403892\n",
      "Epoch5116 | train loss 0.5532561691850424\n",
      "Epoch5117 | train loss 0.553256848435849\n",
      "Epoch5118 | train loss 0.5532556704059243\n",
      "Epoch5119 | train loss 0.5532575787417591\n",
      "Epoch5120 | train loss 0.5532561542652548\n",
      "Epoch5121 | train loss 0.5532567531615495\n",
      "Epoch5122 | train loss 0.5532558601163328\n",
      "Epoch5123 | train loss 0.553257318586111\n",
      "Epoch5124 | train loss 0.5532557299174369\n",
      "Epoch5125 | train loss 0.553258354626596\n",
      "Epoch5126 | train loss 0.5532553748972714\n",
      "Epoch5127 | train loss 0.5532570597156883\n",
      "Epoch5128 | train loss 0.5532552763074636\n",
      "Epoch5129 | train loss 0.5532569305598736\n",
      "Epoch5130 | train loss 0.5532552466727794\n",
      "Epoch5131 | train loss 0.5532559190317988\n",
      "Epoch5132 | train loss 0.5532551730051637\n",
      "Epoch5133 | train loss 0.5532567039132118\n",
      "Epoch5134 | train loss 0.5532559158094227\n",
      "Epoch5135 | train loss 0.5532549759559333\n",
      "Epoch5136 | train loss 0.5532564191892743\n",
      "Epoch5137 | train loss 0.5532550475001335\n",
      "Epoch5138 | train loss 0.5532579171657562\n",
      "Epoch5139 | train loss 0.5532545949332416\n",
      "Epoch5140 | train loss 0.553255975600332\n",
      "Epoch5141 | train loss 0.5532558331079781\n",
      "Epoch5142 | train loss 0.5532550134509802\n",
      "Epoch5143 | train loss 0.5532552271150053\n",
      "Epoch5144 | train loss 0.5532545422017574\n",
      "Epoch5145 | train loss 0.5532575704157352\n",
      "Epoch5146 | train loss 0.5532551469095052\n",
      "Epoch5147 | train loss 0.5532543103024363\n",
      "Epoch5148 | train loss 0.5532557789236308\n",
      "Epoch5149 | train loss 0.5532545882835984\n",
      "Epoch5150 | train loss 0.5532557365857065\n",
      "Epoch5151 | train loss 0.5532541230507195\n",
      "Epoch5152 | train loss 0.5532545304857195\n",
      "Epoch5153 | train loss 0.5532556282356381\n",
      "Epoch5154 | train loss 0.5532540884055197\n",
      "Epoch5155 | train loss 0.5532572113722563\n",
      "Epoch5156 | train loss 0.5532537684589625\n",
      "Epoch5157 | train loss 0.5532543923147023\n",
      "Epoch5158 | train loss 0.5532549811340869\n",
      "Epoch5159 | train loss 0.55325399575755\n",
      "Epoch5160 | train loss 0.5532542905397713\n",
      "Epoch5161 | train loss 0.55325418388471\n",
      "Epoch5162 | train loss 0.5532532876729965\n",
      "Epoch5163 | train loss 0.5532545364834368\n",
      "Epoch5164 | train loss 0.5532562606781721\n",
      "Epoch5165 | train loss 0.5532538381032646\n",
      "Epoch5166 | train loss 0.5532540136016906\n",
      "Epoch5167 | train loss 0.5532541826553643\n",
      "Epoch5168 | train loss 0.5532528818957507\n",
      "Epoch5169 | train loss 0.5532545340061188\n",
      "Epoch5170 | train loss 0.5532543533109129\n",
      "Epoch5171 | train loss 0.5532533721067011\n",
      "Epoch5172 | train loss 0.5532551825605333\n",
      "Epoch5173 | train loss 0.5532528917863965\n",
      "Epoch5174 | train loss 0.5532535332068801\n",
      "Epoch5175 | train loss 0.553254099600017\n",
      "Epoch5176 | train loss 0.5532531011663377\n",
      "Epoch5177 | train loss 0.5532533515803516\n",
      "Epoch5178 | train loss 0.5532539986073971\n",
      "Epoch5179 | train loss 0.5532533124834299\n",
      "Epoch5180 | train loss 0.5532551743090153\n",
      "Epoch5181 | train loss 0.5532529929839075\n",
      "Epoch5182 | train loss 0.553252594191581\n",
      "Epoch5183 | train loss 0.5532533708773554\n",
      "Epoch5184 | train loss 0.5532520781084895\n",
      "Epoch5185 | train loss 0.5532552292570472\n",
      "Epoch5186 | train loss 0.5532527478411794\n",
      "Epoch5187 | train loss 0.5532536655105651\n",
      "Epoch5188 | train loss 0.5532528623379767\n",
      "Epoch5189 | train loss 0.5532536370307207\n",
      "Epoch5190 | train loss 0.5532536680437624\n",
      "Epoch5191 | train loss 0.5532521394640207\n",
      "Epoch5192 | train loss 0.5532529324106872\n",
      "Epoch5193 | train loss 0.5532526468671858\n",
      "Epoch5194 | train loss 0.5532543706893921\n",
      "Epoch5195 | train loss 0.5532522932067514\n",
      "Epoch5196 | train loss 0.5532527288608253\n",
      "Epoch5197 | train loss 0.5532528524287045\n",
      "Epoch5198 | train loss 0.5532516663149\n",
      "Epoch5199 | train loss 0.553254170883447\n",
      "Epoch5200 | train loss 0.5532521050795913\n",
      "Epoch5201 | train loss 0.5532534846849739\n",
      "Epoch5202 | train loss 0.5532519658096134\n",
      "Epoch5203 | train loss 0.5532526729814708\n",
      "Epoch5204 | train loss 0.553253206461668\n",
      "Epoch5205 | train loss 0.5532534463517368\n",
      "Epoch5206 | train loss 0.5532525142095983\n",
      "Epoch5207 | train loss 0.5532515065744519\n",
      "Epoch5208 | train loss 0.5532526993751525\n",
      "Epoch5209 | train loss 0.5532511486858129\n",
      "Epoch5210 | train loss 0.5532542955502868\n",
      "Epoch5211 | train loss 0.5532524829171598\n",
      "Epoch5212 | train loss 0.5532517366670072\n",
      "Epoch5213 | train loss 0.5532520715892315\n",
      "Epoch5214 | train loss 0.5532527678459883\n",
      "Epoch5215 | train loss 0.5532529301196337\n",
      "Epoch5216 | train loss 0.5532516536861658\n",
      "Epoch5217 | train loss 0.5532526491396129\n",
      "Epoch5218 | train loss 0.5532514710538089\n",
      "Epoch5219 | train loss 0.5532522360235452\n",
      "Epoch5220 | train loss 0.5532531659305095\n",
      "Epoch5221 | train loss 0.5532509212568403\n",
      "Epoch5222 | train loss 0.5532523322477937\n",
      "Epoch5223 | train loss 0.553251198027283\n",
      "Epoch5224 | train loss 0.5532530679926276\n",
      "Epoch5225 | train loss 0.5532507841847837\n",
      "Epoch5226 | train loss 0.5532522071711719\n",
      "Epoch5227 | train loss 0.553251118902117\n",
      "Epoch5228 | train loss 0.5532529039867222\n",
      "Epoch5229 | train loss 0.5532528446987272\n",
      "Epoch5230 | train loss 0.5532500660978258\n",
      "Epoch5231 | train loss 0.5532514910772443\n",
      "Epoch5232 | train loss 0.5532508008554577\n",
      "Epoch5233 | train loss 0.5532526779174805\n",
      "Epoch5234 | train loss 0.55325134716928\n",
      "Epoch5235 | train loss 0.5532525748945772\n",
      "Epoch5236 | train loss 0.5532501932419837\n",
      "Epoch5237 | train loss 0.5532504677027464\n",
      "Epoch5238 | train loss 0.55325204892084\n",
      "Epoch5239 | train loss 0.5532504184544087\n",
      "Epoch5240 | train loss 0.5532514309138059\n",
      "Epoch5241 | train loss 0.5532509846426547\n",
      "Epoch5242 | train loss 0.5532502796314657\n",
      "Epoch5243 | train loss 0.5532519155927003\n",
      "Epoch5244 | train loss 0.5532515452243387\n",
      "Epoch5245 | train loss 0.5532509307190776\n",
      "Epoch5246 | train loss 0.5532511099427938\n",
      "Epoch5247 | train loss 0.5532513085007668\n",
      "Epoch5248 | train loss 0.5532495339401067\n",
      "Epoch5249 | train loss 0.553251090478152\n",
      "Epoch5250 | train loss 0.5532500094920397\n",
      "Epoch5251 | train loss 0.553251828327775\n",
      "Epoch5252 | train loss 0.5532506371475756\n",
      "Epoch5253 | train loss 0.5532513089478016\n",
      "Epoch5254 | train loss 0.5532502007298171\n",
      "Epoch5255 | train loss 0.5532506592758\n",
      "Epoch5256 | train loss 0.5532509587518871\n",
      "Epoch5257 | train loss 0.553250558655709\n",
      "Epoch5258 | train loss 0.5532522264681756\n",
      "Epoch5259 | train loss 0.5532508310116827\n",
      "Epoch5260 | train loss 0.5532505197450519\n",
      "Epoch5261 | train loss 0.5532495462335646\n",
      "Epoch5262 | train loss 0.5532505348324775\n",
      "Epoch5263 | train loss 0.5532510534860193\n",
      "Epoch5264 | train loss 0.5532498393580317\n",
      "Epoch5265 | train loss 0.5532493027858436\n",
      "Epoch5266 | train loss 0.553251923006028\n",
      "Epoch5267 | train loss 0.5532505942694843\n",
      "Epoch5268 | train loss 0.5532498868927359\n",
      "Epoch5269 | train loss 0.5532506948150694\n",
      "Epoch5270 | train loss 0.5532520952448249\n",
      "Epoch5271 | train loss 0.5532490211352706\n",
      "Epoch5272 | train loss 0.5532505833916366\n",
      "Epoch5273 | train loss 0.5532506888732314\n",
      "Epoch5274 | train loss 0.5532508694753051\n",
      "Epoch5275 | train loss 0.55324662739411\n",
      "Epoch5276 | train loss 0.5532478058524429\n",
      "Epoch5277 | train loss 0.55324603414163\n",
      "Epoch5278 | train loss 0.5532482745870948\n",
      "Epoch5279 | train loss 0.5532485208287835\n",
      "Epoch5280 | train loss 0.5532454732432961\n",
      "Epoch5281 | train loss 0.5532468054629862\n",
      "Epoch5282 | train loss 0.5532456684671342\n",
      "Epoch5283 | train loss 0.5532463448122144\n",
      "Epoch5284 | train loss 0.5532457767799497\n",
      "Epoch5285 | train loss 0.5532484145462513\n",
      "Epoch5286 | train loss 0.5532483699359\n",
      "Epoch5287 | train loss 0.5532484883256257\n",
      "Epoch5288 | train loss 0.5532470184378326\n",
      "Epoch5289 | train loss 0.5532453844510019\n",
      "Epoch5290 | train loss 0.5532480555772782\n",
      "Epoch5291 | train loss 0.5532456766441465\n",
      "Epoch5292 | train loss 0.5532464192435146\n",
      "Epoch5293 | train loss 0.5532453313842416\n",
      "Epoch5294 | train loss 0.5532475439459086\n",
      "Epoch5295 | train loss 0.5532466021925211\n",
      "Epoch5296 | train loss 0.5532444719970226\n",
      "Epoch5297 | train loss 0.5532448704726994\n",
      "Epoch5298 | train loss 0.5532434233464301\n",
      "Epoch5299 | train loss 0.5532418183237314\n",
      "Epoch5300 | train loss 0.5532438882254064\n",
      "Epoch5301 | train loss 0.553241872228682\n",
      "Epoch5302 | train loss 0.5532425434887409\n",
      "Epoch5303 | train loss 0.5532431408390402\n",
      "Epoch5304 | train loss 0.5532425656355917\n",
      "Epoch5305 | train loss 0.553241786584258\n",
      "Epoch5306 | train loss 0.5532427697815001\n",
      "Epoch5307 | train loss 0.5532438859529794\n",
      "Epoch5308 | train loss 0.5532417345046997\n",
      "Epoch5309 | train loss 0.5532411693036556\n",
      "Epoch5310 | train loss 0.5532416188158095\n",
      "Epoch5311 | train loss 0.5532412075996399\n",
      "Epoch5312 | train loss 0.553243827689439\n",
      "Epoch5313 | train loss 0.5532417569495738\n",
      "Epoch5314 | train loss 0.5532425274513662\n",
      "Epoch5315 | train loss 0.5532410775125026\n",
      "Epoch5316 | train loss 0.5532402049750089\n",
      "Epoch5317 | train loss 0.5532425116933882\n",
      "Epoch5318 | train loss 0.5532416918873787\n",
      "Epoch5319 | train loss 0.5532422707974911\n",
      "Epoch5320 | train loss 0.5532407967932522\n",
      "Epoch5321 | train loss 0.5532420371845365\n",
      "Epoch5322 | train loss 0.5532419670186937\n",
      "Epoch5323 | train loss 0.5532414557412266\n",
      "Epoch5324 | train loss 0.5532420984655618\n",
      "Epoch5325 | train loss 0.5532425048761069\n",
      "Epoch5326 | train loss 0.5532411354593932\n",
      "Epoch5327 | train loss 0.5532421823777258\n",
      "Epoch5328 | train loss 0.5532404336333275\n",
      "Epoch5329 | train loss 0.553240867909044\n",
      "Epoch5330 | train loss 0.5532411174848676\n",
      "Epoch5331 | train loss 0.553240808788687\n",
      "Epoch5332 | train loss 0.5532404283620417\n",
      "Epoch5333 | train loss 0.5532419441081583\n",
      "Epoch5334 | train loss 0.553240326307714\n",
      "Epoch5335 | train loss 0.5532410736009479\n",
      "Epoch5336 | train loss 0.5532405294291675\n",
      "Epoch5337 | train loss 0.5532408597134054\n",
      "Epoch5338 | train loss 0.5532398674637079\n",
      "Epoch5339 | train loss 0.5532398293539882\n",
      "Epoch5340 | train loss 0.5532403245940805\n",
      "Epoch5341 | train loss 0.5532409842312336\n",
      "Epoch5342 | train loss 0.5532388844154775\n",
      "Epoch5343 | train loss 0.5532389202900231\n",
      "Epoch5344 | train loss 0.5532395008392632\n",
      "Epoch5345 | train loss 0.5532400952465832\n",
      "Epoch5346 | train loss 0.5532398213259876\n",
      "Epoch5347 | train loss 0.5532394954562188\n",
      "Epoch5348 | train loss 0.5532401843555271\n",
      "Epoch5349 | train loss 0.5532393597625196\n",
      "Epoch5350 | train loss 0.5532376195862889\n",
      "Epoch5351 | train loss 0.5532392163388431\n",
      "Epoch5352 | train loss 0.5532391601242125\n",
      "Epoch5353 | train loss 0.5532374413497746\n",
      "Epoch5354 | train loss 0.5532391138933599\n",
      "Epoch5355 | train loss 0.5532378826476634\n",
      "Epoch5356 | train loss 0.5532382328994572\n",
      "Epoch5357 | train loss 0.5532395808212459\n",
      "Epoch5358 | train loss 0.5532384173944592\n",
      "Epoch5359 | train loss 0.5532375016063452\n",
      "Epoch5360 | train loss 0.5532382027804852\n",
      "Epoch5361 | train loss 0.5532383659109473\n",
      "Epoch5362 | train loss 0.5532385851442814\n",
      "Epoch5363 | train loss 0.5532374438643456\n",
      "Epoch5364 | train loss 0.5532390383258462\n",
      "Epoch5365 | train loss 0.5532383062876761\n",
      "Epoch5366 | train loss 0.5532373857311904\n",
      "Epoch5367 | train loss 0.5532380882091821\n",
      "Epoch5368 | train loss 0.5532371804863214\n",
      "Epoch5369 | train loss 0.5532372195087373\n",
      "Epoch5370 | train loss 0.5532379028387368\n",
      "Epoch5371 | train loss 0.5532378218136728\n",
      "Epoch5372 | train loss 0.5532377734035253\n",
      "Epoch5373 | train loss 0.5532377287000417\n",
      "Epoch5374 | train loss 0.5532365801185369\n",
      "Epoch5375 | train loss 0.5532382162287831\n",
      "Epoch5376 | train loss 0.5532369019463659\n",
      "Epoch5377 | train loss 0.5532369986921549\n",
      "Epoch5378 | train loss 0.5532370549999177\n",
      "Epoch5379 | train loss 0.5532369370944799\n",
      "Epoch5380 | train loss 0.5532375317625702\n",
      "Epoch5381 | train loss 0.5532368795201182\n",
      "Epoch5382 | train loss 0.5532366361282766\n",
      "Epoch5383 | train loss 0.5532374279946088\n",
      "Epoch5384 | train loss 0.5532360443286598\n",
      "Epoch5385 | train loss 0.5532376668974757\n",
      "Epoch5386 | train loss 0.5532369117625058\n",
      "Epoch5387 | train loss 0.5532372933998704\n",
      "Epoch5388 | train loss 0.5532368435896933\n",
      "Epoch5389 | train loss 0.5532362396456301\n",
      "Epoch5390 | train loss 0.553237322513014\n",
      "Epoch5391 | train loss 0.5532370984181761\n",
      "Epoch5392 | train loss 0.5532363925129176\n",
      "Epoch5393 | train loss 0.553236506395042\n",
      "Epoch5394 | train loss 0.5532359861209989\n",
      "Epoch5395 | train loss 0.5532376690208912\n",
      "Epoch5396 | train loss 0.553236591834575\n",
      "Epoch5397 | train loss 0.5532361454889179\n",
      "Epoch5398 | train loss 0.5532353529147804\n",
      "Epoch5399 | train loss 0.5532369077578188\n",
      "Epoch5400 | train loss 0.553236055597663\n",
      "Epoch5401 | train loss 0.553236278053373\n",
      "Epoch5402 | train loss 0.5532378349639475\n",
      "Epoch5403 | train loss 0.5532363211177289\n",
      "Epoch5404 | train loss 0.5532361184246838\n",
      "Epoch5405 | train loss 0.5532350588031113\n",
      "Epoch5406 | train loss 0.5532353405281901\n",
      "Epoch5407 | train loss 0.5532353705167771\n",
      "Epoch5408 | train loss 0.5532362972572445\n",
      "Epoch5409 | train loss 0.5532363218441606\n",
      "Epoch5410 | train loss 0.5532355430163443\n",
      "Epoch5411 | train loss 0.5532348539866507\n",
      "Epoch5412 | train loss 0.553235522788018\n",
      "Epoch5413 | train loss 0.5532367082126438\n",
      "Epoch5414 | train loss 0.5532348120398819\n",
      "Epoch5415 | train loss 0.5532357021607459\n",
      "Epoch5416 | train loss 0.5532363326847554\n",
      "Epoch5417 | train loss 0.5532372219488024\n",
      "Epoch5418 | train loss 0.5532355339080095\n",
      "Epoch5419 | train loss 0.5532355425320565\n",
      "Epoch5420 | train loss 0.5532355884090066\n",
      "Epoch5421 | train loss 0.5532361307367683\n",
      "Epoch5422 | train loss 0.5532346059940756\n",
      "Epoch5423 | train loss 0.5532368140108883\n",
      "Epoch5424 | train loss 0.5532343050837517\n",
      "Epoch5425 | train loss 0.5532363378442824\n",
      "Epoch5426 | train loss 0.5532352313585579\n",
      "Epoch5427 | train loss 0.5532348316535354\n",
      "Epoch5428 | train loss 0.5532359091751278\n",
      "Epoch5429 | train loss 0.5532350178807974\n",
      "Epoch5430 | train loss 0.5532341108657419\n",
      "Epoch5431 | train loss 0.553235979527235\n",
      "Epoch5432 | train loss 0.5532364488765598\n",
      "Epoch5433 | train loss 0.55323656398803\n",
      "Epoch5434 | train loss 0.5532362580671907\n",
      "Epoch5435 | train loss 0.5532360413298011\n",
      "Epoch5436 | train loss 0.5532356140576303\n",
      "Epoch5437 | train loss 0.5532340881042183\n",
      "Epoch5438 | train loss 0.5532353430055081\n",
      "Epoch5439 | train loss 0.553234258312732\n",
      "Epoch5440 | train loss 0.5532352565415204\n",
      "Epoch5441 | train loss 0.5532353195734322\n",
      "Epoch5442 | train loss 0.5532339037209749\n",
      "Epoch5443 | train loss 0.5532363300397992\n",
      "Epoch5444 | train loss 0.5532349883206189\n",
      "Epoch5445 | train loss 0.5532341278158128\n",
      "Epoch5446 | train loss 0.5532349704019726\n",
      "Epoch5447 | train loss 0.5532351345382631\n",
      "Epoch5448 | train loss 0.5532345384918154\n",
      "Epoch5449 | train loss 0.5532349259592593\n",
      "Epoch5450 | train loss 0.5532344249635934\n",
      "Epoch5451 | train loss 0.5532341082394123\n",
      "Epoch5452 | train loss 0.5532343851588667\n",
      "Epoch5453 | train loss 0.5532336199469864\n",
      "Epoch5454 | train loss 0.5532344298809767\n",
      "Epoch5455 | train loss 0.5532350541464984\n",
      "Epoch5456 | train loss 0.5532339584827423\n",
      "Epoch5457 | train loss 0.5532349850051105\n",
      "Epoch5458 | train loss 0.5532351722754538\n",
      "Epoch5459 | train loss 0.5532336117140949\n",
      "Epoch5460 | train loss 0.5532345710135996\n",
      "Epoch5461 | train loss 0.5532340642996132\n",
      "Epoch5462 | train loss 0.5532346190884709\n",
      "Epoch5463 | train loss 0.5532341316342354\n",
      "Epoch5464 | train loss 0.5532341506704688\n",
      "Epoch5465 | train loss 0.5532334904000163\n",
      "Epoch5466 | train loss 0.5532341781631112\n",
      "Epoch5467 | train loss 0.5532337918691337\n",
      "Epoch5468 | train loss 0.5532342462055385\n",
      "Epoch5469 | train loss 0.5532337762601673\n",
      "Epoch5470 | train loss 0.5532336012646556\n",
      "Epoch5471 | train loss 0.5532342306151986\n",
      "Epoch5472 | train loss 0.5532335348613561\n",
      "Epoch5473 | train loss 0.5532341685518622\n",
      "Epoch5474 | train loss 0.5532334771752357\n",
      "Epoch5475 | train loss 0.5532333586923778\n",
      "Epoch5476 | train loss 0.5532338560931385\n",
      "Epoch5477 | train loss 0.5532333920150996\n",
      "Epoch5478 | train loss 0.5532324071601034\n",
      "Epoch5479 | train loss 0.5532340863347054\n",
      "Epoch5480 | train loss 0.5532338288053871\n",
      "Epoch5481 | train loss 0.5532332146167755\n",
      "Epoch5482 | train loss 0.5532333368621767\n",
      "Epoch5483 | train loss 0.553232870772481\n",
      "Epoch5484 | train loss 0.5532334654405713\n",
      "Epoch5485 | train loss 0.5532318899035453\n",
      "Epoch5486 | train loss 0.5532321511395275\n",
      "Epoch5487 | train loss 0.5532335858233273\n",
      "Epoch5488 | train loss 0.5532339481078088\n",
      "Epoch5489 | train loss 0.5532326198741794\n",
      "Epoch5490 | train loss 0.5532335657067597\n",
      "Epoch5491 | train loss 0.5532320954278112\n",
      "Epoch5492 | train loss 0.5532324400544166\n",
      "Epoch5493 | train loss 0.5532330450974405\n",
      "Epoch5494 | train loss 0.5532331268489361\n",
      "Epoch5495 | train loss 0.5532329409196973\n",
      "Epoch5496 | train loss 0.5532329594157637\n",
      "Epoch5497 | train loss 0.5532310308143497\n",
      "Epoch5498 | train loss 0.5532329322211444\n",
      "Epoch5499 | train loss 0.5532328312285244\n",
      "Epoch5500 | train loss 0.5532335031591356\n",
      "Epoch5501 | train loss 0.5532313261367381\n",
      "Epoch5502 | train loss 0.5532330197654665\n",
      "Epoch5503 | train loss 0.5532320707477629\n",
      "Epoch5504 | train loss 0.5532322711497545\n",
      "Epoch5505 | train loss 0.5532318940013647\n",
      "Epoch5506 | train loss 0.5532326253503561\n",
      "Epoch5507 | train loss 0.5532326411642134\n",
      "Epoch5508 | train loss 0.5532325702905655\n",
      "Epoch5509 | train loss 0.5532328364998103\n",
      "Epoch5510 | train loss 0.5532314312644303\n",
      "Epoch5511 | train loss 0.5532314387150109\n",
      "Epoch5512 | train loss 0.5532321033068002\n",
      "Epoch5513 | train loss 0.5532314180769027\n",
      "Epoch5514 | train loss 0.5532312062382698\n",
      "Epoch5515 | train loss 0.5532317818515002\n",
      "Epoch5516 | train loss 0.5532327879965305\n",
      "Epoch5517 | train loss 0.5532328077405692\n",
      "Epoch5518 | train loss 0.5532318344898521\n",
      "Epoch5519 | train loss 0.5532326458021999\n",
      "Epoch5520 | train loss 0.5532311214320361\n",
      "Epoch5521 | train loss 0.5532318892143667\n",
      "Epoch5522 | train loss 0.5532319419272244\n",
      "Epoch5523 | train loss 0.5532315444946289\n",
      "Epoch5524 | train loss 0.5532315759174525\n",
      "Epoch5525 | train loss 0.5532318529486656\n",
      "Epoch5526 | train loss 0.5532313609682024\n",
      "Epoch5527 | train loss 0.5532300400547683\n",
      "Epoch5528 | train loss 0.5532314682379365\n",
      "Epoch5529 | train loss 0.553231572303921\n",
      "Epoch5530 | train loss 0.5532312064990401\n",
      "Epoch5531 | train loss 0.5532310717552901\n",
      "Epoch5532 | train loss 0.553231168538332\n",
      "Epoch5533 | train loss 0.5532311784289777\n",
      "Epoch5534 | train loss 0.5532317924872041\n",
      "Epoch5535 | train loss 0.5532313289493322\n",
      "Epoch5536 | train loss 0.5532317867130041\n",
      "Epoch5537 | train loss 0.5532304485701025\n",
      "Epoch5538 | train loss 0.5532305791787803\n",
      "Epoch5539 | train loss 0.5532317577116191\n",
      "Epoch5540 | train loss 0.5532300005666911\n",
      "Epoch5541 | train loss 0.5532309056259692\n",
      "Epoch5542 | train loss 0.5532307781651616\n",
      "Epoch5543 | train loss 0.553230371978134\n",
      "Epoch5544 | train loss 0.5532311109080911\n",
      "Epoch5545 | train loss 0.5532315164618195\n",
      "Epoch5546 | train loss 0.5532301046140492\n",
      "Epoch5547 | train loss 0.553230170737952\n",
      "Epoch5548 | train loss 0.5532308478280902\n",
      "Epoch5549 | train loss 0.5532314899936318\n",
      "Epoch5550 | train loss 0.5532308036834002\n",
      "Epoch5551 | train loss 0.5532297009788454\n",
      "Epoch5552 | train loss 0.5532311962358654\n",
      "Epoch5553 | train loss 0.5532299155555666\n",
      "Epoch5554 | train loss 0.5532306630164385\n",
      "Epoch5555 | train loss 0.5532312159612774\n",
      "Epoch5556 | train loss 0.5532305243611336\n",
      "Epoch5557 | train loss 0.5532288975827396\n",
      "Epoch5558 | train loss 0.5532312815450132\n",
      "Epoch5559 | train loss 0.5532312192209065\n",
      "Epoch5560 | train loss 0.5532310714013875\n",
      "Epoch5561 | train loss 0.5532302904874087\n",
      "Epoch5562 | train loss 0.5532294777035713\n",
      "Epoch5563 | train loss 0.5532291289418936\n",
      "Epoch5564 | train loss 0.5532303695380688\n",
      "Epoch5565 | train loss 0.5532293104939163\n",
      "Epoch5566 | train loss 0.5532307889685035\n",
      "Epoch5567 | train loss 0.5532301638647914\n",
      "Epoch5568 | train loss 0.5532305482961237\n",
      "Epoch5569 | train loss 0.5532294761762023\n",
      "Epoch5570 | train loss 0.5532295222021639\n",
      "Epoch5571 | train loss 0.5532302202284336\n",
      "Epoch5572 | train loss 0.5532298537530005\n",
      "Epoch5573 | train loss 0.5532295639626682\n",
      "Epoch5574 | train loss 0.5532289818301797\n",
      "Epoch5575 | train loss 0.5532299190200866\n",
      "Epoch5576 | train loss 0.5532297724112868\n",
      "Epoch5577 | train loss 0.553229193110019\n",
      "Epoch5578 | train loss 0.5532295698858798\n",
      "Epoch5579 | train loss 0.5532295472361147\n",
      "Epoch5580 | train loss 0.5532290218397975\n",
      "Epoch5581 | train loss 0.5532292304374278\n",
      "Epoch5582 | train loss 0.5532292703539133\n",
      "Epoch5583 | train loss 0.5532286133989692\n",
      "Epoch5584 | train loss 0.5532301287166774\n",
      "Epoch5585 | train loss 0.5532297119125724\n",
      "Epoch5586 | train loss 0.5532299127429724\n",
      "Epoch5587 | train loss 0.5532293377444149\n",
      "Epoch5588 | train loss 0.5532277361862361\n",
      "Epoch5589 | train loss 0.5532291748188436\n",
      "Epoch5590 | train loss 0.5532289920002222\n",
      "Epoch5591 | train loss 0.5532284703850746\n",
      "Epoch5592 | train loss 0.5532295771501958\n",
      "Epoch5593 | train loss 0.5532297681644559\n",
      "Epoch5594 | train loss 0.5532295654527843\n",
      "Epoch5595 | train loss 0.5532289525307715\n",
      "Epoch5596 | train loss 0.5532283964008093\n",
      "Epoch5597 | train loss 0.5532296048849821\n",
      "Epoch5598 | train loss 0.5532282150536776\n",
      "Epoch5599 | train loss 0.5532292619720102\n",
      "Epoch5600 | train loss 0.5532287743687629\n",
      "Epoch5601 | train loss 0.55322724474594\n",
      "Epoch5602 | train loss 0.5532294436730445\n",
      "Epoch5603 | train loss 0.5532291365601122\n",
      "Epoch5604 | train loss 0.5532288755103946\n",
      "Epoch5605 | train loss 0.5532283166982234\n",
      "Epoch5606 | train loss 0.553228500019759\n",
      "Epoch5607 | train loss 0.5532281804643572\n",
      "Epoch5608 | train loss 0.5532292257808149\n",
      "Epoch5609 | train loss 0.5532290733233094\n",
      "Epoch5610 | train loss 0.5532283215038478\n",
      "Epoch5611 | train loss 0.5532290596142411\n",
      "Epoch5612 | train loss 0.5532285978645086\n",
      "Epoch5613 | train loss 0.5532280024141073\n",
      "Epoch5614 | train loss 0.5532284799218178\n",
      "Epoch5615 | train loss 0.5532276519201695\n",
      "Epoch5616 | train loss 0.5532280475273729\n",
      "Epoch5617 | train loss 0.5532280438020826\n",
      "Epoch5618 | train loss 0.5532276768237352\n",
      "Epoch5619 | train loss 0.5532286598160863\n",
      "Epoch5620 | train loss 0.553229343444109\n",
      "Epoch5621 | train loss 0.5532279092632234\n",
      "Epoch5622 | train loss 0.5532272355258465\n",
      "Epoch5623 | train loss 0.5532282742485404\n",
      "Epoch5624 | train loss 0.5532276677712799\n",
      "Epoch5625 | train loss 0.5532286524772644\n",
      "Epoch5626 | train loss 0.553229156266898\n",
      "Epoch5627 | train loss 0.553227263931185\n",
      "Epoch5628 | train loss 0.5532283871620893\n",
      "Epoch5629 | train loss 0.5532275849953294\n",
      "Epoch5630 | train loss 0.5532272436097264\n",
      "Epoch5631 | train loss 0.5532274433225394\n",
      "Epoch5632 | train loss 0.5532266694307327\n",
      "Epoch5633 | train loss 0.5532284408248961\n",
      "Epoch5634 | train loss 0.5532278580404818\n",
      "Epoch5635 | train loss 0.5532281603105367\n",
      "Epoch5636 | train loss 0.5532282521948219\n",
      "Epoch5637 | train loss 0.5532279559224844\n",
      "Epoch5638 | train loss 0.5532278594374657\n",
      "Epoch5639 | train loss 0.5532267446443438\n",
      "Epoch5640 | train loss 0.5532276652380824\n",
      "Epoch5641 | train loss 0.5532273693196476\n",
      "Epoch5642 | train loss 0.5532277401909232\n",
      "Epoch5643 | train loss 0.5532274625077843\n",
      "Epoch5644 | train loss 0.5532271719165146\n",
      "Epoch5645 | train loss 0.5532270012795926\n",
      "Epoch5646 | train loss 0.5532272084802389\n",
      "Epoch5647 | train loss 0.5532269204780459\n",
      "Epoch5648 | train loss 0.5532279422320425\n",
      "Epoch5649 | train loss 0.5532280066609383\n",
      "Epoch5650 | train loss 0.5532271292060613\n",
      "Epoch5651 | train loss 0.5532278391346336\n",
      "Epoch5652 | train loss 0.5532274625450373\n",
      "Epoch5653 | train loss 0.5532263814471662\n",
      "Epoch5654 | train loss 0.5532277277484536\n",
      "Epoch5655 | train loss 0.5532265978679061\n",
      "Epoch5656 | train loss 0.553227636218071\n",
      "Epoch5657 | train loss 0.5532265914045275\n",
      "Epoch5658 | train loss 0.5532275080122053\n",
      "Epoch5659 | train loss 0.5532262667827308\n",
      "Epoch5660 | train loss 0.5532272417098284\n",
      "Epoch5661 | train loss 0.5532273624092341\n",
      "Epoch5662 | train loss 0.5532252616807818\n",
      "Epoch5663 | train loss 0.5532283470779658\n",
      "Epoch5664 | train loss 0.5532263256795704\n",
      "Epoch5665 | train loss 0.5532267683185637\n",
      "Epoch5666 | train loss 0.5532265247218311\n",
      "Epoch5667 | train loss 0.5532259525358677\n",
      "Epoch5668 | train loss 0.5532270100340247\n",
      "Epoch5669 | train loss 0.5532261881232262\n",
      "Epoch5670 | train loss 0.5532260903902352\n",
      "Epoch5671 | train loss 0.5532279633358121\n",
      "Epoch5672 | train loss 0.5532258060015738\n",
      "Epoch5673 | train loss 0.5532270094938576\n",
      "Epoch5674 | train loss 0.5532257029414177\n",
      "Epoch5675 | train loss 0.5532267848029733\n",
      "Epoch5676 | train loss 0.553225688226521\n",
      "Epoch5677 | train loss 0.5532279717177153\n",
      "Epoch5678 | train loss 0.5532267492078244\n",
      "Epoch5679 | train loss 0.55322429837659\n",
      "Epoch5680 | train loss 0.5532260100357235\n",
      "Epoch5681 | train loss 0.5532265113852918\n",
      "Epoch5682 | train loss 0.5532266259752214\n",
      "Epoch5683 | train loss 0.5532257224805653\n",
      "Epoch5684 | train loss 0.553226706944406\n",
      "Epoch5685 | train loss 0.5532245009951293\n",
      "Epoch5686 | train loss 0.5532274885103107\n",
      "Epoch5687 | train loss 0.5532252228260041\n",
      "Epoch5688 | train loss 0.5532262725941837\n",
      "Epoch5689 | train loss 0.5532256787270308\n",
      "Epoch5690 | train loss 0.5532248925790191\n",
      "Epoch5691 | train loss 0.5532274652644992\n",
      "Epoch5692 | train loss 0.5532254339382052\n",
      "Epoch5693 | train loss 0.5532275147922338\n",
      "Epoch5694 | train loss 0.5532245040312409\n",
      "Epoch5695 | train loss 0.5532262490317226\n",
      "Epoch5696 | train loss 0.553224510923028\n",
      "Epoch5697 | train loss 0.5532275460474193\n",
      "Epoch5698 | train loss 0.5532253432832658\n",
      "Epoch5699 | train loss 0.5532257740013301\n",
      "Epoch5700 | train loss 0.5532260496355593\n",
      "Epoch5701 | train loss 0.553224359471351\n",
      "Epoch5702 | train loss 0.5532264142110944\n",
      "Epoch5703 | train loss 0.5532250311411917\n",
      "Epoch5704 | train loss 0.5532261429168284\n",
      "Epoch5705 | train loss 0.553225367590785\n",
      "Epoch5706 | train loss 0.553227302879095\n",
      "Epoch5707 | train loss 0.5532255070656538\n",
      "Epoch5708 | train loss 0.5532259698025882\n",
      "Epoch5709 | train loss 0.553225610293448\n",
      "Epoch5710 | train loss 0.5532252550125122\n",
      "Epoch5711 | train loss 0.5532251814566552\n",
      "Epoch5712 | train loss 0.5532269741222262\n",
      "Epoch5713 | train loss 0.5532258868217468\n",
      "Epoch5714 | train loss 0.553223731443286\n",
      "Epoch5715 | train loss 0.5532248631119728\n",
      "Epoch5716 | train loss 0.5532263743132353\n",
      "Epoch5717 | train loss 0.5532245554588735\n",
      "Epoch5718 | train loss 0.5532267655059695\n",
      "Epoch5719 | train loss 0.5532245863974095\n",
      "Epoch5720 | train loss 0.5532250594906509\n",
      "Epoch5721 | train loss 0.5532258661650121\n",
      "Epoch5722 | train loss 0.5532247078977526\n",
      "Epoch5723 | train loss 0.5532257805578411\n",
      "Epoch5724 | train loss 0.5532250736095011\n",
      "Epoch5725 | train loss 0.553224427010864\n",
      "Epoch5726 | train loss 0.5532232611626386\n",
      "Epoch5727 | train loss 0.553225118201226\n",
      "Epoch5728 | train loss 0.5532257768139243\n",
      "Epoch5729 | train loss 0.553225281033665\n",
      "Epoch5730 | train loss 0.5532237007468939\n",
      "Epoch5731 | train loss 0.5532248366251588\n",
      "Epoch5732 | train loss 0.5532258279807866\n",
      "Epoch5733 | train loss 0.5532252083159983\n",
      "Epoch5734 | train loss 0.5532239995338023\n",
      "Epoch5735 | train loss 0.5532248708978296\n",
      "Epoch5736 | train loss 0.5532245576940477\n",
      "Epoch5737 | train loss 0.5532241982407868\n",
      "Epoch5738 | train loss 0.5532246449030935\n",
      "Epoch5739 | train loss 0.5532251452282071\n",
      "Epoch5740 | train loss 0.5532238693535327\n",
      "Epoch5741 | train loss 0.5532251891493797\n",
      "Epoch5742 | train loss 0.553224773593247\n",
      "Epoch5743 | train loss 0.5532249530032277\n",
      "Epoch5744 | train loss 0.5532229928672314\n",
      "Epoch5745 | train loss 0.553225288130343\n",
      "Epoch5746 | train loss 0.5532243411429226\n",
      "Epoch5747 | train loss 0.5532247230410576\n",
      "Epoch5748 | train loss 0.553223117440939\n",
      "Epoch5749 | train loss 0.5532254309020936\n",
      "Epoch5750 | train loss 0.5532234571501613\n",
      "Epoch5751 | train loss 0.5532246734015643\n",
      "Epoch5752 | train loss 0.5532241923548281\n",
      "Epoch5753 | train loss 0.5532247800566256\n",
      "Epoch5754 | train loss 0.553223130274564\n",
      "Epoch5755 | train loss 0.5532250513136386\n",
      "Epoch5756 | train loss 0.5532238373346626\n",
      "Epoch5757 | train loss 0.5532242451235652\n",
      "Epoch5758 | train loss 0.5532241271622479\n",
      "Epoch5759 | train loss 0.5532255322858691\n",
      "Epoch5760 | train loss 0.5532245194353164\n",
      "Epoch5761 | train loss 0.5532246594317257\n",
      "Epoch5762 | train loss 0.5532225002720952\n",
      "Epoch5763 | train loss 0.5532245752587914\n",
      "Epoch5764 | train loss 0.5532253419421613\n",
      "Epoch5765 | train loss 0.5532234420254827\n",
      "Epoch5766 | train loss 0.5532229284383356\n",
      "Epoch5767 | train loss 0.5532241720333695\n",
      "Epoch5768 | train loss 0.5532252381555736\n",
      "Epoch5769 | train loss 0.5532230839692056\n",
      "Epoch5770 | train loss 0.5532245387509466\n",
      "Epoch5771 | train loss 0.5532240169122815\n",
      "Epoch5772 | train loss 0.5532245566509664\n",
      "Epoch5773 | train loss 0.553223465681076\n",
      "Epoch5774 | train loss 0.5532242245040834\n",
      "Epoch5775 | train loss 0.5532227181270719\n",
      "Epoch5776 | train loss 0.5532229975238443\n",
      "Epoch5777 | train loss 0.5532248823530972\n",
      "Epoch5778 | train loss 0.5532232760451734\n",
      "Epoch5779 | train loss 0.5532238493673504\n",
      "Epoch5780 | train loss 0.5532239029556513\n",
      "Epoch5781 | train loss 0.5532235956005752\n",
      "Epoch5782 | train loss 0.5532238305360079\n",
      "Epoch5783 | train loss 0.5532235157117248\n",
      "Epoch5784 | train loss 0.553222868796438\n",
      "Epoch5785 | train loss 0.5532233067974448\n",
      "Epoch5786 | train loss 0.5532233946211637\n",
      "Epoch5787 | train loss 0.5532232787832618\n",
      "Epoch5788 | train loss 0.5532234973087907\n",
      "Epoch5789 | train loss 0.5532227469608187\n",
      "Epoch5790 | train loss 0.5532245129533112\n",
      "Epoch5791 | train loss 0.5532219505310059\n",
      "Epoch5792 | train loss 0.5532245101034641\n",
      "Epoch5793 | train loss 0.5532228474132717\n",
      "Epoch5794 | train loss 0.5532230756804347\n",
      "Epoch5795 | train loss 0.5532234959304333\n",
      "Epoch5796 | train loss 0.5532225308008492\n",
      "Epoch5797 | train loss 0.5532228700257837\n",
      "Epoch5798 | train loss 0.5532240931689739\n",
      "Epoch5799 | train loss 0.5532229775935411\n",
      "Epoch5800 | train loss 0.5532235138304532\n",
      "Epoch5801 | train loss 0.5532231170125306\n",
      "Epoch5802 | train loss 0.5532230559177697\n",
      "Epoch5803 | train loss 0.553222601916641\n",
      "Epoch5804 | train loss 0.5532221803255379\n",
      "Epoch5805 | train loss 0.5532213798724115\n",
      "Epoch5806 | train loss 0.5532237324491143\n",
      "Epoch5807 | train loss 0.5532228036783635\n",
      "Epoch5808 | train loss 0.5532218533009291\n",
      "Epoch5809 | train loss 0.5532238743267953\n",
      "Epoch5810 | train loss 0.5532221562601626\n",
      "Epoch5811 | train loss 0.5532238494046032\n",
      "Epoch5812 | train loss 0.5532232072204352\n",
      "Epoch5813 | train loss 0.5532223385199905\n",
      "Epoch5814 | train loss 0.5532213245332241\n",
      "Epoch5815 | train loss 0.5532217795960606\n",
      "Epoch5816 | train loss 0.5532217598892748\n",
      "Epoch5817 | train loss 0.5532237264141441\n",
      "Epoch5818 | train loss 0.5532222575880588\n",
      "Epoch5819 | train loss 0.5532223473675549\n",
      "Epoch5820 | train loss 0.5532226693257689\n",
      "Epoch5821 | train loss 0.5532224376127124\n",
      "Epoch5822 | train loss 0.5532216284051538\n",
      "Epoch5823 | train loss 0.5532236065715551\n",
      "Epoch5824 | train loss 0.5532234466820956\n",
      "Epoch5825 | train loss 0.5532213753275573\n",
      "Epoch5826 | train loss 0.5532225096225738\n",
      "Epoch5827 | train loss 0.5532224768958985\n",
      "Epoch5828 | train loss 0.5532223637960851\n",
      "Epoch5829 | train loss 0.553221353199333\n",
      "Epoch5830 | train loss 0.5532231715135276\n",
      "Epoch5831 | train loss 0.5532209458574653\n",
      "Epoch5832 | train loss 0.5532227805070579\n",
      "Epoch5833 | train loss 0.5532218410260975\n",
      "Epoch5834 | train loss 0.5532233144901693\n",
      "Epoch5835 | train loss 0.5532204356975854\n",
      "Epoch5836 | train loss 0.5532225531153381\n",
      "Epoch5837 | train loss 0.553221620209515\n",
      "Epoch5838 | train loss 0.5532219142653048\n",
      "Epoch5839 | train loss 0.5532219354249537\n",
      "Epoch5840 | train loss 0.5532216813974082\n",
      "Epoch5841 | train loss 0.5532209715247154\n",
      "Epoch5842 | train loss 0.5532231330126524\n",
      "Epoch5843 | train loss 0.5532215786725283\n",
      "Epoch5844 | train loss 0.5532216797955334\n",
      "Epoch5845 | train loss 0.5532210364751518\n",
      "Epoch5846 | train loss 0.553222312759608\n",
      "Epoch5847 | train loss 0.5532211564481259\n",
      "Epoch5848 | train loss 0.5532217527553439\n",
      "Epoch5849 | train loss 0.5532219559140503\n",
      "Epoch5850 | train loss 0.5532218019664288\n",
      "Epoch5851 | train loss 0.553220613785088\n",
      "Epoch5852 | train loss 0.5532228221558034\n",
      "Epoch5853 | train loss 0.5532208920642734\n",
      "Epoch5854 | train loss 0.5532214387878776\n",
      "Epoch5855 | train loss 0.5532210501283408\n",
      "Epoch5856 | train loss 0.5532207241840661\n",
      "Epoch5857 | train loss 0.5532212832570076\n",
      "Epoch5858 | train loss 0.5532210403494537\n",
      "Epoch5859 | train loss 0.5532203581742943\n",
      "Epoch5860 | train loss 0.5532218014448881\n",
      "Epoch5861 | train loss 0.5532211012765765\n",
      "Epoch5862 | train loss 0.5532209682278335\n",
      "Epoch5863 | train loss 0.5532202496007085\n",
      "Epoch5864 | train loss 0.5532225571572781\n",
      "Epoch5865 | train loss 0.553220404330641\n",
      "Epoch5866 | train loss 0.5532207219302654\n",
      "Epoch5867 | train loss 0.5532207532599568\n",
      "Epoch5868 | train loss 0.5532200367562473\n",
      "Epoch5869 | train loss 0.5532206290401518\n",
      "Epoch5870 | train loss 0.5532206375151872\n",
      "Epoch5871 | train loss 0.5532219851016998\n",
      "Epoch5872 | train loss 0.5532192783243954\n",
      "Epoch5873 | train loss 0.5532220295257866\n",
      "Epoch5874 | train loss 0.5532211386598647\n",
      "Epoch5875 | train loss 0.5532204608432949\n",
      "Epoch5876 | train loss 0.553220459446311\n",
      "Epoch5877 | train loss 0.553219771515578\n",
      "Epoch5878 | train loss 0.5532210444100201\n",
      "Epoch5879 | train loss 0.5532199263572692\n",
      "Epoch5880 | train loss 0.5532197880744935\n",
      "Epoch5881 | train loss 0.5532201857678593\n",
      "Epoch5882 | train loss 0.5532202883996069\n",
      "Epoch5883 | train loss 0.5532207616977394\n",
      "Epoch5884 | train loss 0.5532200505957008\n",
      "Epoch5885 | train loss 0.5532200722768903\n",
      "Epoch5886 | train loss 0.5532199584320188\n",
      "Epoch5887 | train loss 0.5532202343456447\n",
      "Epoch5888 | train loss 0.5532199177518486\n",
      "Epoch5889 | train loss 0.5532202532701195\n",
      "Epoch5890 | train loss 0.5532201337069274\n",
      "Epoch5891 | train loss 0.5532194534316659\n",
      "Epoch5892 | train loss 0.5532203902117908\n",
      "Epoch5893 | train loss 0.5532199912518263\n",
      "Epoch5894 | train loss 0.5532192165404558\n",
      "Epoch5895 | train loss 0.5532200205139816\n",
      "Epoch5896 | train loss 0.5532200111262501\n",
      "Epoch5897 | train loss 0.5532196726649999\n",
      "Epoch5898 | train loss 0.5532192975282669\n",
      "Epoch5899 | train loss 0.5532201174646616\n",
      "Epoch5900 | train loss 0.553219436313957\n",
      "Epoch5901 | train loss 0.5532198277302086\n",
      "Epoch5902 | train loss 0.5532202465832233\n",
      "Epoch5903 | train loss 0.5532193115912378\n",
      "Epoch5904 | train loss 0.553219587020576\n",
      "Epoch5905 | train loss 0.5532196637615562\n",
      "Epoch5906 | train loss 0.5532185916602611\n",
      "Epoch5907 | train loss 0.5532192488200962\n",
      "Epoch5908 | train loss 0.5532183872908354\n",
      "Epoch5909 | train loss 0.5532197776064277\n",
      "Epoch5910 | train loss 0.5532199070602656\n",
      "Epoch5911 | train loss 0.5532188463956118\n",
      "Epoch5912 | train loss 0.5532194247655571\n",
      "Epoch5913 | train loss 0.5532193854264915\n",
      "Epoch5914 | train loss 0.5532190837711096\n",
      "Epoch5915 | train loss 0.5532191693782806\n",
      "Epoch5916 | train loss 0.5532194384932518\n",
      "Epoch5917 | train loss 0.553218849748373\n",
      "Epoch5918 | train loss 0.5532190938293934\n",
      "Epoch5919 | train loss 0.5532187421992422\n",
      "Epoch5920 | train loss 0.5532191631756723\n",
      "Epoch5921 | train loss 0.5532192986272275\n",
      "Epoch5922 | train loss 0.5532182912714779\n",
      "Epoch5923 | train loss 0.5532190809585154\n",
      "Epoch5924 | train loss 0.5532187177054584\n",
      "Epoch5925 | train loss 0.5532189352996647\n",
      "Epoch5926 | train loss 0.5532186042331159\n",
      "Epoch5927 | train loss 0.5532189800590277\n",
      "Epoch5928 | train loss 0.5532190203852951\n",
      "Epoch5929 | train loss 0.5532186209969222\n",
      "Epoch5930 | train loss 0.5532192710973323\n",
      "Epoch5931 | train loss 0.5532182314991951\n",
      "Epoch5932 | train loss 0.5532185281440616\n",
      "Epoch5933 | train loss 0.5532169267348945\n",
      "Epoch5934 | train loss 0.5532186548225582\n",
      "Epoch5935 | train loss 0.5532186198979616\n",
      "Epoch5936 | train loss 0.5532195650972426\n",
      "Epoch5937 | train loss 0.5532185778021812\n",
      "Epoch5938 | train loss 0.5532175273261964\n",
      "Epoch5939 | train loss 0.5532191609218716\n",
      "Epoch5940 | train loss 0.5532185818441212\n",
      "Epoch5941 | train loss 0.5532185534574091\n",
      "Epoch5942 | train loss 0.5532185077294707\n",
      "Epoch5943 | train loss 0.5532186079025269\n",
      "Epoch5944 | train loss 0.5532182725332677\n",
      "Epoch5945 | train loss 0.5532189315743744\n",
      "Epoch5946 | train loss 0.5532184266857803\n",
      "Epoch5947 | train loss 0.5532181228511035\n",
      "Epoch5948 | train loss 0.5532182031683623\n",
      "Epoch5949 | train loss 0.5532183558680117\n",
      "Epoch5950 | train loss 0.5532171468622983\n",
      "Epoch5951 | train loss 0.5532182634808123\n",
      "Epoch5952 | train loss 0.5532181619480252\n",
      "Epoch5953 | train loss 0.5532176514156163\n",
      "Epoch5954 | train loss 0.5532180233299733\n",
      "Epoch5955 | train loss 0.5532170893996954\n",
      "Epoch5956 | train loss 0.5532186375185847\n",
      "Epoch5957 | train loss 0.5532177780941129\n",
      "Epoch5958 | train loss 0.5532175449095666\n",
      "Epoch5959 | train loss 0.5532190494798124\n",
      "Epoch5960 | train loss 0.5532170594483614\n",
      "Epoch5961 | train loss 0.5532176879420877\n",
      "Epoch5962 | train loss 0.5532180260121823\n",
      "Epoch5963 | train loss 0.5532167839631438\n",
      "Epoch5964 | train loss 0.5532179565168918\n",
      "Epoch5965 | train loss 0.5532178862579167\n",
      "Epoch5966 | train loss 0.5532173891738057\n",
      "Epoch5967 | train loss 0.5532183982618153\n",
      "Epoch5968 | train loss 0.5532178381830454\n",
      "Epoch5969 | train loss 0.5532172192819417\n",
      "Epoch5970 | train loss 0.5532173828594387\n",
      "Epoch5971 | train loss 0.5532169317081571\n",
      "Epoch5972 | train loss 0.5532177725993097\n",
      "Epoch5973 | train loss 0.5532178235054016\n",
      "Epoch5974 | train loss 0.5532164595462382\n",
      "Epoch5975 | train loss 0.553218317553401\n",
      "Epoch5976 | train loss 0.5532176460698247\n",
      "Epoch5977 | train loss 0.5532170120067894\n",
      "Epoch5978 | train loss 0.5532178369350731\n",
      "Epoch5979 | train loss 0.5532174651883542\n",
      "Epoch5980 | train loss 0.5532172051817179\n",
      "Epoch5981 | train loss 0.5532174590043724\n",
      "Epoch5982 | train loss 0.5532172666117549\n",
      "Epoch5983 | train loss 0.5532170727103949\n",
      "Epoch5984 | train loss 0.5532177219726145\n",
      "Epoch5985 | train loss 0.5532171434350311\n",
      "Epoch5986 | train loss 0.5532174722105264\n",
      "Epoch5987 | train loss 0.5532173297181725\n",
      "Epoch5988 | train loss 0.5532170909456908\n",
      "Epoch5989 | train loss 0.55321722548455\n",
      "Epoch5990 | train loss 0.5532169130071998\n",
      "Epoch5991 | train loss 0.553217438030988\n",
      "Epoch5992 | train loss 0.5532169670425355\n",
      "Epoch5993 | train loss 0.5532155307941139\n",
      "Epoch5994 | train loss 0.5532171976566315\n",
      "Epoch5995 | train loss 0.5532161474972963\n",
      "Epoch5996 | train loss 0.5532170565053821\n",
      "Epoch5997 | train loss 0.5532173726893962\n",
      "Epoch5998 | train loss 0.553216829970479\n",
      "Epoch5999 | train loss 0.5532170500792563\n",
      "Epoch6000 | train loss 0.5532159088738262\n",
      "Epoch6001 | train loss 0.5532178604975343\n",
      "Epoch6002 | train loss 0.553217336460948\n",
      "Epoch6003 | train loss 0.5532165694236756\n",
      "Epoch6004 | train loss 0.553217014465481\n",
      "Epoch6005 | train loss 0.5532168428972364\n",
      "Epoch6006 | train loss 0.5532165937125683\n",
      "Epoch6007 | train loss 0.5532157100550831\n",
      "Epoch6008 | train loss 0.5532165174745023\n",
      "Epoch6009 | train loss 0.5532179006189107\n",
      "Epoch6010 | train loss 0.5532169349491596\n",
      "Epoch6011 | train loss 0.5532162822782993\n",
      "Epoch6012 | train loss 0.5532161506451666\n",
      "Epoch6013 | train loss 0.5532168259099126\n",
      "Epoch6014 | train loss 0.5532163251750171\n",
      "Epoch6015 | train loss 0.5532149641215801\n",
      "Epoch6016 | train loss 0.5532165035791695\n",
      "Epoch6017 | train loss 0.5532164636440575\n",
      "Epoch6018 | train loss 0.5532166751474142\n",
      "Epoch6019 | train loss 0.5532162697799504\n",
      "Epoch6020 | train loss 0.5532154880836606\n",
      "Epoch6021 | train loss 0.5532165893353522\n",
      "Epoch6022 | train loss 0.5532161423377693\n",
      "Epoch6023 | train loss 0.553217245452106\n",
      "Epoch6024 | train loss 0.5532158253341913\n",
      "Epoch6025 | train loss 0.5532152301259339\n",
      "Epoch6026 | train loss 0.5532161316089332\n",
      "Epoch6027 | train loss 0.5532151391357183\n",
      "Epoch6028 | train loss 0.553216183744371\n",
      "Epoch6029 | train loss 0.5532165334187448\n",
      "Epoch6030 | train loss 0.5532155239023269\n",
      "Epoch6031 | train loss 0.5532164338231087\n",
      "Epoch6032 | train loss 0.5532158909924328\n",
      "Epoch6033 | train loss 0.5532152385264635\n",
      "Epoch6034 | train loss 0.5532157755456865\n",
      "Epoch6035 | train loss 0.5532152735441923\n",
      "Epoch6036 | train loss 0.5532160618156194\n",
      "Epoch6037 | train loss 0.5532154248468578\n",
      "Epoch6038 | train loss 0.5532153903879226\n",
      "Epoch6039 | train loss 0.5532156141661108\n",
      "Epoch6040 | train loss 0.5532151135057211\n",
      "Epoch6041 | train loss 0.5532155681960285\n",
      "Epoch6042 | train loss 0.5532163394987584\n",
      "Epoch6043 | train loss 0.5532150174677372\n",
      "Epoch6044 | train loss 0.5532163262553513\n",
      "Epoch6045 | train loss 0.5532157260552049\n",
      "Epoch6046 | train loss 0.5532149548642338\n",
      "Epoch6047 | train loss 0.5532164147868752\n",
      "Epoch6048 | train loss 0.5532160774432122\n",
      "Epoch6049 | train loss 0.5532142478786409\n",
      "Epoch6050 | train loss 0.5532155852392315\n",
      "Epoch6051 | train loss 0.5532151333242655\n",
      "Epoch6052 | train loss 0.5532152171805501\n",
      "Epoch6053 | train loss 0.5532163848169148\n",
      "Epoch6054 | train loss 0.5532139558717608\n",
      "Epoch6055 | train loss 0.5532159419171512\n",
      "Epoch6056 | train loss 0.5532151949964463\n",
      "Epoch6057 | train loss 0.5532151063904166\n",
      "Epoch6058 | train loss 0.5532161806151271\n",
      "Epoch6059 | train loss 0.5532140601612627\n",
      "Epoch6060 | train loss 0.5532162515632808\n",
      "Epoch6061 | train loss 0.5532144778035581\n",
      "Epoch6062 | train loss 0.5532144365645945\n",
      "Epoch6063 | train loss 0.553216048963368\n",
      "Epoch6064 | train loss 0.5532150229997933\n",
      "Epoch6065 | train loss 0.5532147102989257\n",
      "Epoch6066 | train loss 0.5532147021964192\n",
      "Epoch6067 | train loss 0.5532141407392919\n",
      "Epoch6068 | train loss 0.5532156205549836\n",
      "Epoch6069 | train loss 0.5532143405079841\n",
      "Epoch6070 | train loss 0.5532134763151407\n",
      "Epoch6071 | train loss 0.5532158521749079\n",
      "Epoch6072 | train loss 0.5532132339663803\n",
      "Epoch6073 | train loss 0.5532145273126662\n",
      "Epoch6074 | train loss 0.5532144351303577\n",
      "Epoch6075 | train loss 0.5532156393304467\n",
      "Epoch6076 | train loss 0.5532145446538925\n",
      "Epoch6077 | train loss 0.5532139954902232\n",
      "Epoch6078 | train loss 0.5532144199870527\n",
      "Epoch6079 | train loss 0.553213850185275\n",
      "Epoch6080 | train loss 0.5532135370559991\n",
      "Epoch6081 | train loss 0.5532128408737481\n",
      "Epoch6082 | train loss 0.5532153996266425\n",
      "Epoch6083 | train loss 0.5532145109772683\n",
      "Epoch6084 | train loss 0.5532132472097874\n",
      "Epoch6085 | train loss 0.5532143565453589\n",
      "Epoch6086 | train loss 0.553212521187961\n",
      "Epoch6087 | train loss 0.5532138215564192\n",
      "Epoch6088 | train loss 0.5532142703607679\n",
      "Epoch6089 | train loss 0.5532137840427458\n",
      "Epoch6090 | train loss 0.5532140162214637\n",
      "Epoch6091 | train loss 0.5532144696079194\n",
      "Epoch6092 | train loss 0.5532134296372533\n",
      "Epoch6093 | train loss 0.5532145264558495\n",
      "Epoch6094 | train loss 0.5532134055159986\n",
      "Epoch6095 | train loss 0.5532132995501161\n",
      "Epoch6096 | train loss 0.5532133696787059\n",
      "Epoch6097 | train loss 0.5532139660418034\n",
      "Epoch6098 | train loss 0.5532145806960762\n",
      "Epoch6099 | train loss 0.5532124397531152\n",
      "Epoch6100 | train loss 0.5532133037783206\n",
      "Epoch6101 | train loss 0.553213846962899\n",
      "Epoch6102 | train loss 0.5532129244692624\n",
      "Epoch6103 | train loss 0.5532144061289728\n",
      "Epoch6104 | train loss 0.5532120326906442\n",
      "Epoch6105 | train loss 0.553213603310287\n",
      "Epoch6106 | train loss 0.5532143009640277\n",
      "Epoch6107 | train loss 0.5532126770168543\n",
      "Epoch6108 | train loss 0.5532130198739469\n",
      "Epoch6109 | train loss 0.5532130155153573\n",
      "Epoch6110 | train loss 0.5532134348712862\n",
      "Epoch6111 | train loss 0.5532143232598901\n",
      "Epoch6112 | train loss 0.5532130670174956\n",
      "Epoch6113 | train loss 0.5532140501216054\n",
      "Epoch6114 | train loss 0.5532131704688072\n",
      "Epoch6115 | train loss 0.5532130943425\n",
      "Epoch6116 | train loss 0.5532119629904628\n",
      "Epoch6117 | train loss 0.553213154617697\n",
      "Epoch6118 | train loss 0.5532139496132732\n",
      "Epoch6119 | train loss 0.5532129965908825\n",
      "Epoch6120 | train loss 0.5532125319354236\n",
      "Epoch6121 | train loss 0.5532128588669002\n",
      "Epoch6122 | train loss 0.5532116113230586\n",
      "Epoch6123 | train loss 0.553212865665555\n",
      "Epoch6124 | train loss 0.5532126399129629\n",
      "Epoch6125 | train loss 0.5532128795050084\n",
      "Epoch6126 | train loss 0.5532138217240572\n",
      "Epoch6127 | train loss 0.553212511036545\n",
      "Epoch6128 | train loss 0.5532125630229712\n",
      "Epoch6129 | train loss 0.5532125731930136\n",
      "Epoch6130 | train loss 0.5532125995494426\n",
      "Epoch6131 | train loss 0.5532127615064383\n",
      "Epoch6132 | train loss 0.5532123159058392\n",
      "Epoch6133 | train loss 0.5532118229009211\n",
      "Epoch6134 | train loss 0.5532122671976686\n",
      "Epoch6135 | train loss 0.5532122035324574\n",
      "Epoch6136 | train loss 0.5532136143557728\n",
      "Epoch6137 | train loss 0.5532121581025422\n",
      "Epoch6138 | train loss 0.5532116561010479\n",
      "Epoch6139 | train loss 0.5532121559791267\n",
      "Epoch6140 | train loss 0.5532121205888688\n",
      "Epoch6141 | train loss 0.553213551864028\n",
      "Epoch6142 | train loss 0.5532113256119192\n",
      "Epoch6143 | train loss 0.5532124867849052\n",
      "Epoch6144 | train loss 0.5532122326269746\n",
      "Epoch6145 | train loss 0.5532115200720727\n",
      "Epoch6146 | train loss 0.5532123824208974\n",
      "Epoch6147 | train loss 0.553211787417531\n",
      "Epoch6148 | train loss 0.5532117343880236\n",
      "Epoch6149 | train loss 0.5532121034525335\n",
      "Epoch6150 | train loss 0.5532113901153207\n",
      "Epoch6151 | train loss 0.5532120444625616\n",
      "Epoch6152 | train loss 0.5532116032019258\n",
      "Epoch6153 | train loss 0.5532119074463844\n",
      "Epoch6154 | train loss 0.5532122658006847\n",
      "Epoch6155 | train loss 0.5532105129398406\n",
      "Epoch6156 | train loss 0.553213269803673\n",
      "Epoch6157 | train loss 0.5532118967920542\n",
      "Epoch6158 | train loss 0.5532101673819124\n",
      "Epoch6159 | train loss 0.5532114937528968\n",
      "Epoch6160 | train loss 0.5532116665504873\n",
      "Epoch6161 | train loss 0.5532117707841099\n",
      "Epoch6162 | train loss 0.5532115917094051\n",
      "Epoch6163 | train loss 0.5532108253054321\n",
      "Epoch6164 | train loss 0.5532116634771228\n",
      "Epoch6165 | train loss 0.5532114246115089\n",
      "Epoch6166 | train loss 0.5532118252292275\n",
      "Epoch6167 | train loss 0.5532110577449203\n",
      "Epoch6168 | train loss 0.5532107463665307\n",
      "Epoch6169 | train loss 0.5532113429531456\n",
      "Epoch6170 | train loss 0.5532118243165314\n",
      "Epoch6171 | train loss 0.5532116348668933\n",
      "Epoch6172 | train loss 0.5532106441818178\n",
      "Epoch6173 | train loss 0.553211427256465\n",
      "Epoch6174 | train loss 0.5532113415934146\n",
      "Epoch6175 | train loss 0.5532110731117428\n",
      "Epoch6176 | train loss 0.5532111347094179\n",
      "Epoch6177 | train loss 0.5532113667391241\n",
      "Epoch6178 | train loss 0.5532106499373913\n",
      "Epoch6179 | train loss 0.5532114993222058\n",
      "Epoch6180 | train loss 0.5532108768634498\n",
      "Epoch6181 | train loss 0.5532094651088119\n",
      "Epoch6182 | train loss 0.553209962323308\n",
      "Epoch6183 | train loss 0.5532122464291751\n",
      "Epoch6184 | train loss 0.5532112851552665\n",
      "Epoch6185 | train loss 0.5532100386917591\n",
      "Epoch6186 | train loss 0.5532107154838741\n",
      "Epoch6187 | train loss 0.5532113788090647\n",
      "Epoch6188 | train loss 0.5532097409665585\n",
      "Epoch6189 | train loss 0.5532111759483814\n",
      "Epoch6190 | train loss 0.553210912514478\n",
      "Epoch6191 | train loss 0.5532107256539166\n",
      "Epoch6192 | train loss 0.5532107805833221\n",
      "Epoch6193 | train loss 0.5532094789296389\n",
      "Epoch6194 | train loss 0.5532104777172208\n",
      "Epoch6195 | train loss 0.5532108234241605\n",
      "Epoch6196 | train loss 0.5532104156911373\n",
      "Epoch6197 | train loss 0.5532105057686567\n",
      "Epoch6198 | train loss 0.5532103461958467\n",
      "Epoch6199 | train loss 0.5532108390145004\n",
      "Epoch6200 | train loss 0.5532093973457813\n",
      "Epoch6201 | train loss 0.553209098689258\n",
      "Epoch6202 | train loss 0.5532097821310162\n",
      "Epoch6203 | train loss 0.5532103957235813\n",
      "Epoch6204 | train loss 0.5532098317146301\n",
      "Epoch6205 | train loss 0.5532105268537998\n",
      "Epoch6206 | train loss 0.553210287205875\n",
      "Epoch6207 | train loss 0.553209379222244\n",
      "Epoch6208 | train loss 0.5532110767997801\n",
      "Epoch6209 | train loss 0.5532099830172956\n",
      "Epoch6210 | train loss 0.5532097706198692\n",
      "Epoch6211 | train loss 0.5532097972556949\n",
      "Epoch6212 | train loss 0.5532089989259839\n",
      "Epoch6213 | train loss 0.5532103033736349\n",
      "Epoch6214 | train loss 0.5532083345763386\n",
      "Epoch6215 | train loss 0.5532102486677468\n",
      "Epoch6216 | train loss 0.5532099299505353\n",
      "Epoch6217 | train loss 0.553210660237819\n",
      "Epoch6218 | train loss 0.5532089407555759\n",
      "Epoch6219 | train loss 0.5532094731740653\n",
      "Epoch6220 | train loss 0.5532088277861476\n",
      "Epoch6221 | train loss 0.5532097591459751\n",
      "Epoch6222 | train loss 0.5532095802202821\n",
      "Epoch6223 | train loss 0.5532095315121114\n",
      "Epoch6224 | train loss 0.553208218012005\n",
      "Epoch6225 | train loss 0.553209891282022\n",
      "Epoch6226 | train loss 0.5532093380950391\n",
      "Epoch6227 | train loss 0.553207077421248\n",
      "Epoch6228 | train loss 0.5532087932899594\n",
      "Epoch6229 | train loss 0.5532094740495086\n",
      "Epoch6230 | train loss 0.5532082145288587\n",
      "Epoch6231 | train loss 0.5532087166979909\n",
      "Epoch6232 | train loss 0.5532091974839568\n",
      "Epoch6233 | train loss 0.5532083562202752\n",
      "Epoch6234 | train loss 0.553208795171231\n",
      "Epoch6235 | train loss 0.5532088161073625\n",
      "Epoch6236 | train loss 0.553208467438817\n",
      "Epoch6237 | train loss 0.5532098762132227\n",
      "Epoch6238 | train loss 0.5532073432207107\n",
      "Epoch6239 | train loss 0.5532093156315386\n",
      "Epoch6240 | train loss 0.5532097285799682\n",
      "Epoch6241 | train loss 0.5532073179446161\n",
      "Epoch6242 | train loss 0.5532091273926198\n",
      "Epoch6243 | train loss 0.5532075463421643\n",
      "Epoch6244 | train loss 0.5532079274393618\n",
      "Epoch6245 | train loss 0.553207465223968\n",
      "Epoch6246 | train loss 0.5532071788795292\n",
      "Epoch6247 | train loss 0.553209345266223\n",
      "Epoch6248 | train loss 0.5532073419168592\n",
      "Epoch6249 | train loss 0.5532080817595124\n",
      "Epoch6250 | train loss 0.5532072468474507\n",
      "Epoch6251 | train loss 0.5532081499882042\n",
      "Epoch6252 | train loss 0.5532077870890498\n",
      "Epoch6253 | train loss 0.5532073947601021\n",
      "Epoch6254 | train loss 0.5532076595164835\n",
      "Epoch6255 | train loss 0.5532076299004257\n",
      "Epoch6256 | train loss 0.5532073351368308\n",
      "Epoch6257 | train loss 0.5532070036232472\n",
      "Epoch6258 | train loss 0.5532089298218489\n",
      "Epoch6259 | train loss 0.5532066593132913\n",
      "Epoch6260 | train loss 0.5532074418850244\n",
      "Epoch6261 | train loss 0.5532070668786764\n",
      "Epoch6262 | train loss 0.5532076885551214\n",
      "Epoch6263 | train loss 0.5532070092856884\n",
      "Epoch6264 | train loss 0.553206760045141\n",
      "Epoch6265 | train loss 0.5532085911929607\n",
      "Epoch6266 | train loss 0.5532061411254108\n",
      "Epoch6267 | train loss 0.5532064158283174\n",
      "Epoch6268 | train loss 0.5532065765373408\n",
      "Epoch6269 | train loss 0.5532083387859166\n",
      "Epoch6270 | train loss 0.5532071740925312\n",
      "Epoch6271 | train loss 0.5532061152718961\n",
      "Epoch6272 | train loss 0.5532064675725996\n",
      "Epoch6273 | train loss 0.5532066370733082\n",
      "Epoch6274 | train loss 0.5532071613520384\n",
      "Epoch6275 | train loss 0.5532057000137865\n",
      "Epoch6276 | train loss 0.5532068695686757\n",
      "Epoch6277 | train loss 0.5532064637169242\n",
      "Epoch6278 | train loss 0.5532063864916563\n",
      "Epoch6279 | train loss 0.553207754548639\n",
      "Epoch6280 | train loss 0.5532055662572384\n",
      "Epoch6281 | train loss 0.5532077876850963\n",
      "Epoch6282 | train loss 0.5532056232355536\n",
      "Epoch6283 | train loss 0.5532053511589765\n",
      "Epoch6284 | train loss 0.5532067622803152\n",
      "Epoch6285 | train loss 0.5532056534476578\n",
      "Epoch6286 | train loss 0.5532075180485845\n",
      "Epoch6287 | train loss 0.5532062947750092\n",
      "Epoch6288 | train loss 0.5532063775323331\n",
      "Epoch6289 | train loss 0.5532075424864888\n",
      "Epoch6290 | train loss 0.5532056061550975\n",
      "Epoch6291 | train loss 0.5532038834318519\n",
      "Epoch6292 | train loss 0.5532067172601819\n",
      "Epoch6293 | train loss 0.5532061359658837\n",
      "Epoch6294 | train loss 0.5532072096690536\n",
      "Epoch6295 | train loss 0.5532059222459793\n",
      "Epoch6296 | train loss 0.5532060012407601\n",
      "Epoch6297 | train loss 0.553205959238112\n",
      "Epoch6298 | train loss 0.553205916006118\n",
      "Epoch6299 | train loss 0.5532068666443228\n",
      "Epoch6300 | train loss 0.5532053877599538\n",
      "Epoch6301 | train loss 0.5532056808099151\n",
      "Epoch6302 | train loss 0.5532067000120878\n",
      "Epoch6303 | train loss 0.5532048152014614\n",
      "Epoch6304 | train loss 0.553205821029842\n",
      "Epoch6305 | train loss 0.5532040530070662\n",
      "Epoch6306 | train loss 0.5532056397385895\n",
      "Epoch6307 | train loss 0.5532064628787339\n",
      "Epoch6308 | train loss 0.5532044785283506\n",
      "Epoch6309 | train loss 0.5532052842900157\n",
      "Epoch6310 | train loss 0.5532046077214181\n",
      "Epoch6311 | train loss 0.5532051713578403\n",
      "Epoch6312 | train loss 0.5532049404084682\n",
      "Epoch6313 | train loss 0.5532038941606879\n",
      "Epoch6314 | train loss 0.553206199221313\n",
      "Epoch6315 | train loss 0.553205214869231\n",
      "Epoch6316 | train loss 0.5532052598334849\n",
      "Epoch6317 | train loss 0.5532051461189985\n",
      "Epoch6318 | train loss 0.5532059198245406\n",
      "Epoch6319 | train loss 0.5532051494345069\n",
      "Epoch6320 | train loss 0.553204627931118\n",
      "Epoch6321 | train loss 0.553204915560782\n",
      "Epoch6322 | train loss 0.5532050866633653\n",
      "Epoch6323 | train loss 0.5532051716558635\n",
      "Epoch6324 | train loss 0.5532061288692057\n",
      "Epoch6325 | train loss 0.5532037280313671\n",
      "Epoch6326 | train loss 0.5532052613422275\n",
      "Epoch6327 | train loss 0.5532049241662026\n",
      "Epoch6328 | train loss 0.5532055361010134\n",
      "Epoch6329 | train loss 0.5532033141329884\n",
      "Epoch6330 | train loss 0.5532057049870491\n",
      "Epoch6331 | train loss 0.5532047762908041\n",
      "Epoch6332 | train loss 0.5532053980231285\n",
      "Epoch6333 | train loss 0.5532038390636445\n",
      "Epoch6334 | train loss 0.5532048785500229\n",
      "Epoch6335 | train loss 0.5532053915038705\n",
      "Epoch6336 | train loss 0.5532051006890834\n",
      "Epoch6337 | train loss 0.5532039112970233\n",
      "Epoch6338 | train loss 0.5532046159729361\n",
      "Epoch6339 | train loss 0.5532046419195831\n",
      "Epoch6340 | train loss 0.5532044087536633\n",
      "Epoch6341 | train loss 0.5532050530798733\n",
      "Epoch6342 | train loss 0.5532049579173326\n",
      "Epoch6343 | train loss 0.553203757815063\n",
      "Epoch6344 | train loss 0.5532040171325207\n",
      "Epoch6345 | train loss 0.5532034506835043\n",
      "Epoch6346 | train loss 0.553202786706388\n",
      "Epoch6347 | train loss 0.5532059719599783\n",
      "Epoch6348 | train loss 0.5532038084976375\n",
      "Epoch6349 | train loss 0.5532037369720638\n",
      "Epoch6350 | train loss 0.5532042928598822\n",
      "Epoch6351 | train loss 0.5532049716822803\n",
      "Epoch6352 | train loss 0.5532037578895688\n",
      "Epoch6353 | train loss 0.5532031951844693\n",
      "Epoch6354 | train loss 0.5532039297558368\n",
      "Epoch6355 | train loss 0.553202839512378\n",
      "Epoch6356 | train loss 0.553203992061317\n",
      "Epoch6357 | train loss 0.5532037617638708\n",
      "Epoch6358 | train loss 0.5532047976180912\n",
      "Epoch6359 | train loss 0.5532035150192678\n",
      "Epoch6360 | train loss 0.5532049405388534\n",
      "Epoch6361 | train loss 0.5532032544352115\n",
      "Epoch6362 | train loss 0.5532048151269555\n",
      "Epoch6363 | train loss 0.553202613927424\n",
      "Epoch6364 | train loss 0.5532050371915102\n",
      "Epoch6365 | train loss 0.5532021497189998\n",
      "Epoch6366 | train loss 0.5532030351646244\n",
      "Epoch6367 | train loss 0.5532040045782923\n",
      "Epoch6368 | train loss 0.5532036936469376\n",
      "Epoch6369 | train loss 0.5532026178948581\n",
      "Epoch6370 | train loss 0.5532035205513239\n",
      "Epoch6371 | train loss 0.5532039589621127\n",
      "Epoch6372 | train loss 0.5532022079080343\n",
      "Epoch6373 | train loss 0.5532028557546437\n",
      "Epoch6374 | train loss 0.5532045846246183\n",
      "Epoch6375 | train loss 0.5532011922635138\n",
      "Epoch6376 | train loss 0.5532048463262618\n",
      "Epoch6377 | train loss 0.5532033370062709\n",
      "Epoch6378 | train loss 0.5532042826339603\n",
      "Epoch6379 | train loss 0.5532017514854669\n",
      "Epoch6380 | train loss 0.5532047281600535\n",
      "Epoch6381 | train loss 0.5532009378820658\n",
      "Epoch6382 | train loss 0.5532046759873629\n",
      "Epoch6383 | train loss 0.5532018173113465\n",
      "Epoch6384 | train loss 0.5532028659805656\n",
      "Epoch6385 | train loss 0.5532024217955768\n",
      "Epoch6386 | train loss 0.5532022194191814\n",
      "Epoch6387 | train loss 0.5532045083865523\n",
      "Epoch6388 | train loss 0.5532015706412494\n",
      "Epoch6389 | train loss 0.5532030655257404\n",
      "Epoch6390 | train loss 0.5532032095640897\n",
      "Epoch6391 | train loss 0.5532025674171746\n",
      "Epoch6392 | train loss 0.553202738314867\n",
      "Epoch6393 | train loss 0.553202816452831\n",
      "Epoch6394 | train loss 0.5532020784914493\n",
      "Epoch6395 | train loss 0.5532028483785689\n",
      "Epoch6396 | train loss 0.5532023027539253\n",
      "Epoch6397 | train loss 0.5532023340649903\n",
      "Epoch6398 | train loss 0.5532029215618968\n",
      "Epoch6399 | train loss 0.5532037221826613\n",
      "Epoch6400 | train loss 0.5532027466036379\n",
      "Epoch6401 | train loss 0.5532035706564784\n",
      "Epoch6402 | train loss 0.5532024335488677\n",
      "Epoch6403 | train loss 0.5532035894505679\n",
      "Epoch6404 | train loss 0.5532033713534474\n",
      "Epoch6405 | train loss 0.5532032660767436\n",
      "Epoch6406 | train loss 0.5532019395008683\n",
      "Epoch6407 | train loss 0.5532014491222799\n",
      "Epoch6408 | train loss 0.5532038527727127\n",
      "Epoch6409 | train loss 0.553201661054045\n",
      "Epoch6410 | train loss 0.5532025981508195\n",
      "Epoch6411 | train loss 0.5532025560364127\n",
      "Epoch6412 | train loss 0.5532018102146685\n",
      "Epoch6413 | train loss 0.5532008844986558\n",
      "Epoch6414 | train loss 0.5532027773372828\n",
      "Epoch6415 | train loss 0.553202099557966\n",
      "Epoch6416 | train loss 0.5532034598104656\n",
      "Epoch6417 | train loss 0.5532023909315467\n",
      "Epoch6418 | train loss 0.5532031963393093\n",
      "Epoch6419 | train loss 0.5532009637728333\n",
      "Epoch6420 | train loss 0.553201601523906\n",
      "Epoch6421 | train loss 0.5532027434743941\n",
      "Epoch6422 | train loss 0.5532022294029594\n",
      "Epoch6423 | train loss 0.5532017798349261\n",
      "Epoch6424 | train loss 0.5532024114951491\n",
      "Epoch6425 | train loss 0.5532019342109561\n",
      "Epoch6426 | train loss 0.5532019556686282\n",
      "Epoch6427 | train loss 0.5532021192461252\n",
      "Epoch6428 | train loss 0.5532008392363786\n",
      "Epoch6429 | train loss 0.5532034988328814\n",
      "Epoch6430 | train loss 0.5531999631598592\n",
      "Epoch6431 | train loss 0.5532016264274716\n",
      "Epoch6432 | train loss 0.5532020149379968\n",
      "Epoch6433 | train loss 0.5532021877914667\n",
      "Epoch6434 | train loss 0.553202400058508\n",
      "Epoch6435 | train loss 0.5532027646154165\n",
      "Epoch6436 | train loss 0.5532017393782734\n",
      "Epoch6437 | train loss 0.553201876617968\n",
      "Epoch6438 | train loss 0.5532027656398714\n",
      "Epoch6439 | train loss 0.5532027631253004\n",
      "Epoch6440 | train loss 0.553201785236597\n",
      "Epoch6441 | train loss 0.5532003936730325\n",
      "Epoch6442 | train loss 0.5532018163427711\n",
      "Epoch6443 | train loss 0.5532021443732082\n",
      "Epoch6444 | train loss 0.5532015018723905\n",
      "Epoch6445 | train loss 0.5532025618851185\n",
      "Epoch6446 | train loss 0.553201237525791\n",
      "Epoch6447 | train loss 0.553200672455132\n",
      "Epoch6448 | train loss 0.5532025660946965\n",
      "Epoch6449 | train loss 0.5532013460993767\n",
      "Epoch6450 | train loss 0.5532018979266285\n",
      "Epoch6451 | train loss 0.5532008620910347\n",
      "Epoch6452 | train loss 0.5532016951777041\n",
      "Epoch6453 | train loss 0.5532008965313434\n",
      "Epoch6454 | train loss 0.5532028186507523\n",
      "Epoch6455 | train loss 0.5532013509236277\n",
      "Epoch6456 | train loss 0.5532023328356445\n",
      "Epoch6457 | train loss 0.5531999709270895\n",
      "Epoch6458 | train loss 0.5532012446969747\n",
      "Epoch6459 | train loss 0.5532010584324598\n",
      "Epoch6460 | train loss 0.5532019732147455\n",
      "Epoch6461 | train loss 0.553201069701463\n",
      "Epoch6462 | train loss 0.553202166929841\n",
      "Epoch6463 | train loss 0.5532008245959879\n",
      "Epoch6464 | train loss 0.5532001299224794\n",
      "Epoch6465 | train loss 0.5532023490220308\n",
      "Epoch6466 | train loss 0.5532008092105388\n",
      "Epoch6467 | train loss 0.5532006551139057\n",
      "Epoch6468 | train loss 0.5532018146850168\n",
      "Epoch6469 | train loss 0.5532018900662661\n",
      "Epoch6470 | train loss 0.5532006072998047\n",
      "Epoch6471 | train loss 0.5532020414993167\n",
      "Epoch6472 | train loss 0.553199592102319\n",
      "Epoch6473 | train loss 0.5532011171244084\n",
      "Epoch6474 | train loss 0.5532020012661815\n",
      "Epoch6475 | train loss 0.5531998308375478\n",
      "Epoch6476 | train loss 0.553201535642147\n",
      "Epoch6477 | train loss 0.5532016521319747\n",
      "Epoch6478 | train loss 0.5532016443088651\n",
      "Epoch6479 | train loss 0.5532004039362073\n",
      "Epoch6480 | train loss 0.5532015334255993\n",
      "Epoch6481 | train loss 0.5532011554203927\n",
      "Epoch6482 | train loss 0.5532015754468739\n",
      "Epoch6483 | train loss 0.5532005153223872\n",
      "Epoch6484 | train loss 0.553201064337045\n",
      "Epoch6485 | train loss 0.5532002897933126\n",
      "Epoch6486 | train loss 0.5532009492814541\n",
      "Epoch6487 | train loss 0.5532021094858647\n",
      "Epoch6488 | train loss 0.5531992453895509\n",
      "Epoch6489 | train loss 0.5532005350477993\n",
      "Epoch6490 | train loss 0.5531996460072697\n",
      "Epoch6491 | train loss 0.553200506567955\n",
      "Epoch6492 | train loss 0.5531997459568083\n",
      "Epoch6493 | train loss 0.5532009099982679\n",
      "Epoch6494 | train loss 0.5532017899863422\n",
      "Epoch6495 | train loss 0.5532011484354734\n",
      "Epoch6496 | train loss 0.553200369849801\n",
      "Epoch6497 | train loss 0.5532014897465706\n",
      "Epoch6498 | train loss 0.5532005164772272\n",
      "Epoch6499 | train loss 0.5531992562487722\n",
      "Epoch6500 | train loss 0.5532001133449376\n",
      "Epoch6501 | train loss 0.5531996802985668\n",
      "Epoch6502 | train loss 0.5532003497891128\n",
      "Epoch6503 | train loss 0.5532006079889834\n",
      "Epoch6504 | train loss 0.553201349452138\n",
      "Epoch6505 | train loss 0.5532009193114936\n",
      "Epoch6506 | train loss 0.5531999534368515\n",
      "Epoch6507 | train loss 0.5532010997086764\n",
      "Epoch6508 | train loss 0.5531999331712723\n",
      "Epoch6509 | train loss 0.5532012400962413\n",
      "Epoch6510 | train loss 0.5532000268995761\n",
      "Epoch6511 | train loss 0.5532004849612713\n",
      "Epoch6512 | train loss 0.553201263807714\n",
      "Epoch6513 | train loss 0.5532006604969502\n",
      "Epoch6514 | train loss 0.5531993598677218\n",
      "Epoch6515 | train loss 0.5532001417130232\n",
      "Epoch6516 | train loss 0.5531993920728564\n",
      "Epoch6517 | train loss 0.5531997062452138\n",
      "Epoch6518 | train loss 0.5532003936171531\n",
      "Epoch6519 | train loss 0.5532011763006449\n",
      "Epoch6520 | train loss 0.5532001436874271\n",
      "Epoch6521 | train loss 0.5532004394754767\n",
      "Epoch6522 | train loss 0.5532010015845299\n",
      "Epoch6523 | train loss 0.5531995647028088\n",
      "Epoch6524 | train loss 0.5532011876441538\n",
      "Epoch6525 | train loss 0.5532006699778139\n",
      "Epoch6526 | train loss 0.5532005095854402\n",
      "Epoch6527 | train loss 0.5532000531256199\n",
      "Epoch6528 | train loss 0.5532008047215641\n",
      "Epoch6529 | train loss 0.5531992060318589\n",
      "Epoch6530 | train loss 0.5531998535618186\n",
      "Epoch6531 | train loss 0.5531991640292108\n",
      "Epoch6532 | train loss 0.5531995271332562\n",
      "Epoch6533 | train loss 0.5532004558108747\n",
      "Epoch6534 | train loss 0.5532007726095617\n",
      "Epoch6535 | train loss 0.5532005222700537\n",
      "Epoch6536 | train loss 0.5532006288133562\n",
      "Epoch6537 | train loss 0.5532003340497613\n",
      "Epoch6538 | train loss 0.5531996855884791\n",
      "Epoch6539 | train loss 0.5532008869759738\n",
      "Epoch6540 | train loss 0.5531994016841054\n",
      "Epoch6541 | train loss 0.553200237005949\n",
      "Epoch6542 | train loss 0.5531999931298196\n",
      "Epoch6543 | train loss 0.5532012256607414\n",
      "Epoch6544 | train loss 0.5531991304829716\n",
      "Epoch6545 | train loss 0.553199597876519\n",
      "Epoch6546 | train loss 0.5532001023553312\n",
      "Epoch6547 | train loss 0.5532002480700612\n",
      "Epoch6548 | train loss 0.5532006043754518\n",
      "Epoch6549 | train loss 0.5532005542702972\n",
      "Epoch6550 | train loss 0.5531991501152516\n",
      "Epoch6551 | train loss 0.5531998402066529\n",
      "Epoch6552 | train loss 0.5532000085711479\n",
      "Epoch6553 | train loss 0.5532007759809494\n",
      "Epoch6554 | train loss 0.5532003295980394\n",
      "Epoch6555 | train loss 0.5532003229111433\n",
      "Epoch6556 | train loss 0.5531990026682615\n",
      "Epoch6557 | train loss 0.5531999141909182\n",
      "Epoch6558 | train loss 0.5532003866322338\n",
      "Epoch6559 | train loss 0.5532001317106188\n",
      "Epoch6560 | train loss 0.5531998540647328\n",
      "Epoch6561 | train loss 0.5531995498575271\n",
      "Epoch6562 | train loss 0.5531998942792415\n",
      "Epoch6563 | train loss 0.5532010469771922\n",
      "Epoch6564 | train loss 0.5531995348073542\n",
      "Epoch6565 | train loss 0.5531994476914406\n",
      "Epoch6566 | train loss 0.5531999463960529\n",
      "Epoch6567 | train loss 0.5532004765793681\n",
      "Epoch6568 | train loss 0.553199739549309\n",
      "Epoch6569 | train loss 0.5531989530101419\n",
      "Epoch6570 | train loss 0.5532002228312194\n",
      "Epoch6571 | train loss 0.5531999267637729\n",
      "Epoch6572 | train loss 0.5532001527957618\n",
      "Epoch6573 | train loss 0.553199362680316\n",
      "Epoch6574 | train loss 0.5531995179504157\n",
      "Epoch6575 | train loss 0.5531994725763798\n",
      "Epoch6576 | train loss 0.553199619743973\n",
      "Epoch6577 | train loss 0.5532008117623627\n",
      "Epoch6578 | train loss 0.5531997297145427\n",
      "Epoch6579 | train loss 0.5531991473026574\n",
      "Epoch6580 | train loss 0.5531996845081448\n",
      "Epoch6581 | train loss 0.5531992293335497\n",
      "Epoch6582 | train loss 0.553199773747474\n",
      "Epoch6583 | train loss 0.5532003167830407\n",
      "Epoch6584 | train loss 0.5531996678933502\n",
      "Epoch6585 | train loss 0.5531991926766932\n",
      "Epoch6586 | train loss 0.5531995027512312\n",
      "Epoch6587 | train loss 0.5531988419219851\n",
      "Epoch6588 | train loss 0.5531995614804327\n",
      "Epoch6589 | train loss 0.5532006391882897\n",
      "Epoch6590 | train loss 0.5531994699500501\n",
      "Epoch6591 | train loss 0.5531996934302151\n",
      "Epoch6592 | train loss 0.5531987965852022\n",
      "Epoch6593 | train loss 0.5531997958011925\n",
      "Epoch6594 | train loss 0.5532000493817031\n",
      "Epoch6595 | train loss 0.5531988360546529\n",
      "Epoch6596 | train loss 0.5531994871795177\n",
      "Epoch6597 | train loss 0.5531995189189911\n",
      "Epoch6598 | train loss 0.553199140559882\n",
      "Epoch6599 | train loss 0.553198707755655\n",
      "Epoch6600 | train loss 0.5531996974349022\n",
      "Epoch6601 | train loss 0.5531998883746564\n",
      "Epoch6602 | train loss 0.5532000536471605\n",
      "Epoch6603 | train loss 0.5531985696591437\n",
      "Epoch6604 | train loss 0.5531993165239691\n",
      "Epoch6605 | train loss 0.5531985303387046\n",
      "Epoch6606 | train loss 0.5532005598396063\n",
      "Epoch6607 | train loss 0.5531994235143065\n",
      "Epoch6608 | train loss 0.5531992219947278\n",
      "Epoch6609 | train loss 0.5531988123804331\n",
      "Epoch6610 | train loss 0.5531990225426853\n",
      "Epoch6611 | train loss 0.5531996886990964\n",
      "Epoch6612 | train loss 0.5531997217610478\n",
      "Epoch6613 | train loss 0.5531995491124689\n",
      "Epoch6614 | train loss 0.5531983805634081\n",
      "Epoch6615 | train loss 0.5531989394128323\n",
      "Epoch6616 | train loss 0.5531998280063272\n",
      "Epoch6617 | train loss 0.5531998912617564\n",
      "Epoch6618 | train loss 0.553199297003448\n",
      "Epoch6619 | train loss 0.5531984497234226\n",
      "Epoch6620 | train loss 0.5531997462920845\n",
      "Epoch6621 | train loss 0.5531988877616822\n",
      "Epoch6622 | train loss 0.5531989899463952\n",
      "Epoch6623 | train loss 0.5531990383565426\n",
      "Epoch6624 | train loss 0.5532004437968134\n",
      "Epoch6625 | train loss 0.5531986958160996\n",
      "Epoch6626 | train loss 0.5531998050957918\n",
      "Epoch6627 | train loss 0.5531984603963792\n",
      "Epoch6628 | train loss 0.553199208471924\n",
      "Epoch6629 | train loss 0.5531989075988532\n",
      "Epoch6630 | train loss 0.5531997202523052\n",
      "Epoch6631 | train loss 0.5531995152868331\n",
      "Epoch6632 | train loss 0.5531989945098758\n",
      "Epoch6633 | train loss 0.5531984462402761\n",
      "Epoch6634 | train loss 0.5531991139240563\n",
      "Epoch6635 | train loss 0.5531973946467041\n",
      "Epoch6636 | train loss 0.5531984585523605\n",
      "Epoch6637 | train loss 0.5531982587836682\n",
      "Epoch6638 | train loss 0.5531983342207968\n",
      "Epoch6639 | train loss 0.5531996570155024\n",
      "Epoch6640 | train loss 0.5531992868892849\n",
      "Epoch6641 | train loss 0.553199721723795\n",
      "Epoch6642 | train loss 0.553199368044734\n",
      "Epoch6643 | train loss 0.5531993949040771\n",
      "Epoch6644 | train loss 0.5531987375207246\n",
      "Epoch6645 | train loss 0.5531990409269929\n",
      "Epoch6646 | train loss 0.5532000395096839\n",
      "Epoch6647 | train loss 0.5531995757110417\n",
      "Epoch6648 | train loss 0.553198060747236\n",
      "Epoch6649 | train loss 0.5531981587037444\n",
      "Epoch6650 | train loss 0.5531993679143489\n",
      "Epoch6651 | train loss 0.5531990467943251\n",
      "Epoch6652 | train loss 0.5531993729062379\n",
      "Epoch6653 | train loss 0.5531996306404472\n",
      "Epoch6654 | train loss 0.5531990692950786\n",
      "Epoch6655 | train loss 0.5531988791190088\n",
      "Epoch6656 | train loss 0.5531991200149059\n",
      "Epoch6657 | train loss 0.5531970691494643\n",
      "Epoch6658 | train loss 0.553197768162936\n",
      "Epoch6659 | train loss 0.5531984028965234\n",
      "Epoch6660 | train loss 0.5531995777413249\n",
      "Epoch6661 | train loss 0.5531999317370355\n",
      "Epoch6662 | train loss 0.5531992894597352\n",
      "Epoch6663 | train loss 0.5531985976919532\n",
      "Epoch6664 | train loss 0.5531985420547426\n",
      "Epoch6665 | train loss 0.5531985001638532\n",
      "Epoch6666 | train loss 0.5531987096555531\n",
      "Epoch6667 | train loss 0.5531994753144681\n",
      "Epoch6668 | train loss 0.553199357483536\n",
      "Epoch6669 | train loss 0.5531991865113377\n",
      "Epoch6670 | train loss 0.5531979370862246\n",
      "Epoch6671 | train loss 0.5531971460580826\n",
      "Epoch6672 | train loss 0.5531982493586838\n",
      "Epoch6673 | train loss 0.5531990699283779\n",
      "Epoch6674 | train loss 0.553199193496257\n",
      "Epoch6675 | train loss 0.5531991223245859\n",
      "Epoch6676 | train loss 0.5531980340369046\n",
      "Epoch6677 | train loss 0.5531991565972567\n",
      "Epoch6678 | train loss 0.553199273403734\n",
      "Epoch6679 | train loss 0.5531982049904763\n",
      "Epoch6680 | train loss 0.5531993004865945\n",
      "Epoch6681 | train loss 0.5531986919976771\n",
      "Epoch6682 | train loss 0.5531981304846704\n",
      "Epoch6683 | train loss 0.5531987554952502\n",
      "Epoch6684 | train loss 0.5531987982057035\n",
      "Epoch6685 | train loss 0.5531974719464778\n",
      "Epoch6686 | train loss 0.5531992167420685\n",
      "Epoch6687 | train loss 0.553198934365064\n",
      "Epoch6688 | train loss 0.5531988514959812\n",
      "Epoch6689 | train loss 0.5531984979845583\n",
      "Epoch6690 | train loss 0.5531997627392411\n",
      "Epoch6691 | train loss 0.5531986916437746\n",
      "Epoch6692 | train loss 0.5531979202851653\n",
      "Epoch6693 | train loss 0.5531975313648582\n",
      "Epoch6694 | train loss 0.5531976412981748\n",
      "Epoch6695 | train loss 0.5531985773146153\n",
      "Epoch6696 | train loss 0.5531992382183671\n",
      "Epoch6697 | train loss 0.5531987430527806\n",
      "Epoch6698 | train loss 0.5531982436962426\n",
      "Epoch6699 | train loss 0.553198802638799\n",
      "Epoch6700 | train loss 0.5531995612755418\n",
      "Epoch6701 | train loss 0.5531992438808083\n",
      "Epoch6702 | train loss 0.5531986832432448\n",
      "Epoch6703 | train loss 0.5531976937130093\n",
      "Epoch6704 | train loss 0.5531973386555911\n",
      "Epoch6705 | train loss 0.5531975786015392\n",
      "Epoch6706 | train loss 0.5531984158046543\n",
      "Epoch6707 | train loss 0.5531988681294024\n",
      "Epoch6708 | train loss 0.5531988465413451\n",
      "Epoch6709 | train loss 0.5531988518871367\n",
      "Epoch6710 | train loss 0.553199015390128\n",
      "Epoch6711 | train loss 0.5531980338692665\n",
      "Epoch6712 | train loss 0.5531992461159825\n",
      "Epoch6713 | train loss 0.5531982291862368\n",
      "Epoch6714 | train loss 0.553198361005634\n",
      "Epoch6715 | train loss 0.5531973239965737\n",
      "Epoch6716 | train loss 0.5531991478987038\n",
      "Epoch6717 | train loss 0.5531989451311529\n",
      "Epoch6718 | train loss 0.5531984992139042\n",
      "Epoch6719 | train loss 0.5531975050829351\n",
      "Epoch6720 | train loss 0.5531988923251628\n",
      "Epoch6721 | train loss 0.5531987204216421\n",
      "Epoch6722 | train loss 0.5531974391080439\n",
      "Epoch6723 | train loss 0.5531978074461221\n",
      "Epoch6724 | train loss 0.5531989143788815\n",
      "Epoch6725 | train loss 0.5531980604305864\n",
      "Epoch6726 | train loss 0.5531982303783297\n",
      "Epoch6727 | train loss 0.5531987179815769\n",
      "Epoch6728 | train loss 0.5531986548751593\n",
      "Epoch6729 | train loss 0.5531987405195832\n",
      "Epoch6730 | train loss 0.5531966012716293\n",
      "Epoch6731 | train loss 0.5531969628296792\n",
      "Epoch6732 | train loss 0.5531975874491036\n",
      "Epoch6733 | train loss 0.553198602758348\n",
      "Epoch6734 | train loss 0.5531978248618543\n",
      "Epoch6735 | train loss 0.5531981555558741\n",
      "Epoch6736 | train loss 0.5531985285319387\n",
      "Epoch6737 | train loss 0.5531989951990545\n",
      "Epoch6738 | train loss 0.5531986437365413\n",
      "Epoch6739 | train loss 0.5531979415006936\n",
      "Epoch6740 | train loss 0.5531989898532629\n",
      "Epoch6741 | train loss 0.5531984154693782\n",
      "Epoch6742 | train loss 0.553196715246886\n",
      "Epoch6743 | train loss 0.5531975270994007\n",
      "Epoch6744 | train loss 0.5531985472328961\n",
      "Epoch6745 | train loss 0.5531984642334282\n",
      "Epoch6746 | train loss 0.5531985450349748\n",
      "Epoch6747 | train loss 0.553197263199836\n",
      "Epoch6748 | train loss 0.553198682423681\n",
      "Epoch6749 | train loss 0.5531984572298825\n",
      "Epoch6750 | train loss 0.5531966139934957\n",
      "Epoch6751 | train loss 0.5531973733194172\n",
      "Epoch6752 | train loss 0.5531970868073404\n",
      "Epoch6753 | train loss 0.553198454733938\n",
      "Epoch6754 | train loss 0.5531987879052758\n",
      "Epoch6755 | train loss 0.553197679631412\n",
      "Epoch6756 | train loss 0.5531983029842377\n",
      "Epoch6757 | train loss 0.5531985410675406\n",
      "Epoch6758 | train loss 0.5531976372934878\n",
      "Epoch6759 | train loss 0.5531986132636666\n",
      "Epoch6760 | train loss 0.55319818707183\n",
      "Epoch6761 | train loss 0.5531980383023619\n",
      "Epoch6762 | train loss 0.5531967618502677\n",
      "Epoch6763 | train loss 0.5531969364359974\n",
      "Epoch6764 | train loss 0.5531973732449115\n",
      "Epoch6765 | train loss 0.553198609109968\n",
      "Epoch6766 | train loss 0.5531985684111714\n",
      "Epoch6767 | train loss 0.553198315910995\n",
      "Epoch6768 | train loss 0.5531975354999303\n",
      "Epoch6769 | train loss 0.5531982392817736\n",
      "Epoch6770 | train loss 0.5531981589458883\n",
      "Epoch6771 | train loss 0.5531966673210263\n",
      "Epoch6772 | train loss 0.5531973184272647\n",
      "Epoch6773 | train loss 0.5531972943432629\n",
      "Epoch6774 | train loss 0.5531984764710068\n",
      "Epoch6775 | train loss 0.5531981208734215\n",
      "Epoch6776 | train loss 0.553198271971196\n",
      "Epoch6777 | train loss 0.5531975637748837\n",
      "Epoch6778 | train loss 0.5531984956003726\n",
      "Epoch6779 | train loss 0.5531983678415417\n",
      "Epoch6780 | train loss 0.5531965718790889\n",
      "Epoch6781 | train loss 0.553197264354676\n",
      "Epoch6782 | train loss 0.5531982976943255\n",
      "Epoch6783 | train loss 0.553197472281754\n",
      "Epoch6784 | train loss 0.5531982441991568\n",
      "Epoch6785 | train loss 0.553198101837188\n",
      "Epoch6786 | train loss 0.5531981324404478\n",
      "Epoch6787 | train loss 0.5531963014788925\n",
      "Epoch6788 | train loss 0.5531974363699556\n",
      "Epoch6789 | train loss 0.5531984206661582\n",
      "Epoch6790 | train loss 0.5531980240903794\n",
      "Epoch6791 | train loss 0.5531983212940395\n",
      "Epoch6792 | train loss 0.553197953775525\n",
      "Epoch6793 | train loss 0.5531982113048435\n",
      "Epoch6794 | train loss 0.5531981126777827\n",
      "Epoch6795 | train loss 0.5531981046311557\n",
      "Epoch6796 | train loss 0.5531965582072735\n",
      "Epoch6797 | train loss 0.5531978785060346\n",
      "Epoch6798 | train loss 0.5531980493664741\n",
      "Epoch6799 | train loss 0.5531971620395779\n",
      "Epoch6800 | train loss 0.5531979859061539\n",
      "Epoch6801 | train loss 0.553197152800858\n",
      "Epoch6802 | train loss 0.5531982005387545\n",
      "Epoch6803 | train loss 0.5531966491043567\n",
      "Epoch6804 | train loss 0.5531977377459407\n",
      "Epoch6805 | train loss 0.5531970689073205\n",
      "Epoch6806 | train loss 0.5531980939209461\n",
      "Epoch6807 | train loss 0.5531979799084366\n",
      "Epoch6808 | train loss 0.553198067676276\n",
      "Epoch6809 | train loss 0.5531961467862129\n",
      "Epoch6810 | train loss 0.5531971096619963\n",
      "Epoch6811 | train loss 0.5531983346492052\n",
      "Epoch6812 | train loss 0.5531971517205239\n",
      "Epoch6813 | train loss 0.5531979752331972\n",
      "Epoch6814 | train loss 0.5531979508139193\n",
      "Epoch6815 | train loss 0.5531959698721767\n",
      "Epoch6816 | train loss 0.553197049535811\n",
      "Epoch6817 | train loss 0.55319829037413\n",
      "Epoch6818 | train loss 0.5531985007040202\n",
      "Epoch6819 | train loss 0.5531981620006263\n",
      "Epoch6820 | train loss 0.5531968319788575\n",
      "Epoch6821 | train loss 0.5531961664557457\n",
      "Epoch6822 | train loss 0.553197451364249\n",
      "Epoch6823 | train loss 0.5531978359259665\n",
      "Epoch6824 | train loss 0.5531972907483578\n",
      "Epoch6825 | train loss 0.5531976206228137\n",
      "Epoch6826 | train loss 0.5531971835531294\n",
      "Epoch6827 | train loss 0.5531979456543923\n",
      "Epoch6828 | train loss 0.5531960423849523\n",
      "Epoch6829 | train loss 0.5531968063488603\n",
      "Epoch6830 | train loss 0.5531969874724746\n",
      "Epoch6831 | train loss 0.553198023494333\n",
      "Epoch6832 | train loss 0.5531976689025759\n",
      "Epoch6833 | train loss 0.5531978273205459\n",
      "Epoch6834 | train loss 0.553197520300746\n",
      "Epoch6835 | train loss 0.5531979083269835\n",
      "Epoch6836 | train loss 0.5531978978402913\n",
      "Epoch6837 | train loss 0.5531983035057784\n",
      "Epoch6838 | train loss 0.5531975097581744\n",
      "Epoch6839 | train loss 0.553196568004787\n",
      "Epoch6840 | train loss 0.5531968612223863\n",
      "Epoch6841 | train loss 0.5531981096975506\n",
      "Epoch6842 | train loss 0.5531976013071835\n",
      "Epoch6843 | train loss 0.5531968975067139\n",
      "Epoch6844 | train loss 0.5531976127065719\n",
      "Epoch6845 | train loss 0.5531976108625531\n",
      "Epoch6846 | train loss 0.5531960202381014\n",
      "Epoch6847 | train loss 0.5531967920809984\n",
      "Epoch6848 | train loss 0.5531966220214963\n",
      "Epoch6849 | train loss 0.5531979563459754\n",
      "Epoch6850 | train loss 0.5531976369582117\n",
      "Epoch6851 | train loss 0.5531971250288188\n",
      "Epoch6852 | train loss 0.5531977983750402\n",
      "Epoch6853 | train loss 0.5531959051825106\n",
      "Epoch6854 | train loss 0.5531970602460206\n",
      "Epoch6855 | train loss 0.5531965772993863\n",
      "Epoch6856 | train loss 0.5531981377862394\n",
      "Epoch6857 | train loss 0.5531978357210755\n",
      "Epoch6858 | train loss 0.5531977098621428\n",
      "Epoch6859 | train loss 0.5531980959512294\n",
      "Epoch6860 | train loss 0.5531982355751097\n",
      "Epoch6861 | train loss 0.5531975826621056\n",
      "Epoch6862 | train loss 0.5531958022154868\n",
      "Epoch6863 | train loss 0.553196799941361\n",
      "Epoch6864 | train loss 0.5531961529515683\n",
      "Epoch6865 | train loss 0.5531965252384543\n",
      "Epoch6866 | train loss 0.553198109343648\n",
      "Epoch6867 | train loss 0.5531975666806102\n",
      "Epoch6868 | train loss 0.5531977200880647\n",
      "Epoch6869 | train loss 0.5531978236325085\n",
      "Epoch6870 | train loss 0.5531957710906863\n",
      "Epoch6871 | train loss 0.5531978001073002\n",
      "Epoch6872 | train loss 0.5531968533061444\n",
      "Epoch6873 | train loss 0.5531975433044135\n",
      "Epoch6874 | train loss 0.5531980913877487\n",
      "Epoch6875 | train loss 0.5531975523382425\n",
      "Epoch6876 | train loss 0.5531958204321563\n",
      "Epoch6877 | train loss 0.5531971832923591\n",
      "Epoch6878 | train loss 0.5531967073120176\n",
      "Epoch6879 | train loss 0.5531962276622653\n",
      "Epoch6880 | train loss 0.5531976427696645\n",
      "Epoch6881 | train loss 0.5531977582536638\n",
      "Epoch6882 | train loss 0.553197811562568\n",
      "Epoch6883 | train loss 0.5531963624060154\n",
      "Epoch6884 | train loss 0.5531969286315143\n",
      "Epoch6885 | train loss 0.5531961568631232\n",
      "Epoch6886 | train loss 0.5531964548118412\n",
      "Epoch6887 | train loss 0.5531977618858218\n",
      "Epoch6888 | train loss 0.5531977036967873\n",
      "Epoch6889 | train loss 0.5531975399143993\n",
      "Epoch6890 | train loss 0.5531956142373383\n",
      "Epoch6891 | train loss 0.553196988813579\n",
      "Epoch6892 | train loss 0.5531977767311037\n",
      "Epoch6893 | train loss 0.553196382150054\n",
      "Epoch6894 | train loss 0.5531965672783553\n",
      "Epoch6895 | train loss 0.5531963410787284\n",
      "Epoch6896 | train loss 0.5531978505849838\n",
      "Epoch6897 | train loss 0.5531976428627968\n",
      "Epoch6898 | train loss 0.5531977131590247\n",
      "Epoch6899 | train loss 0.5531956866011023\n",
      "Epoch6900 | train loss 0.5531968829035759\n",
      "Epoch6901 | train loss 0.5531965404748916\n",
      "Epoch6902 | train loss 0.5531966385990381\n",
      "Epoch6903 | train loss 0.5531977397762239\n",
      "Epoch6904 | train loss 0.5531978722847998\n",
      "Epoch6905 | train loss 0.5531976267881692\n",
      "Epoch6906 | train loss 0.5531959903612733\n",
      "Epoch6907 | train loss 0.5531964373774827\n",
      "Epoch6908 | train loss 0.5531961621902883\n",
      "Epoch6909 | train loss 0.5531962075456976\n",
      "Epoch6910 | train loss 0.5531975724361837\n",
      "Epoch6911 | train loss 0.553197867218405\n",
      "Epoch6912 | train loss 0.5531974287889898\n",
      "Epoch6913 | train loss 0.553196053635329\n",
      "Epoch6914 | train loss 0.5531976201198995\n",
      "Epoch6915 | train loss 0.553197719398886\n",
      "Epoch6916 | train loss 0.5531954044476152\n",
      "Epoch6917 | train loss 0.5531968146935106\n",
      "Epoch6918 | train loss 0.5531975432485342\n",
      "Epoch6919 | train loss 0.5531976521760226\n",
      "Epoch6920 | train loss 0.5531970714591443\n",
      "Epoch6921 | train loss 0.5531959020160139\n",
      "Epoch6922 | train loss 0.5531961587071419\n",
      "Epoch6923 | train loss 0.5531964555382729\n",
      "Epoch6924 | train loss 0.5531975221633911\n",
      "Epoch6925 | train loss 0.5531975753232836\n",
      "Epoch6926 | train loss 0.5531973305903375\n",
      "Epoch6927 | train loss 0.5531968518346548\n",
      "Epoch6928 | train loss 0.5531958109140396\n",
      "Epoch6929 | train loss 0.5531963354535401\n",
      "Epoch6930 | train loss 0.5531973950378597\n",
      "Epoch6931 | train loss 0.553197491299361\n",
      "Epoch6932 | train loss 0.5531970353238285\n",
      "Epoch6933 | train loss 0.5531956522539258\n",
      "Epoch6934 | train loss 0.5531959600187838\n",
      "Epoch6935 | train loss 0.5531972766853869\n",
      "Epoch6936 | train loss 0.5531974781677127\n",
      "Epoch6937 | train loss 0.5531967804767192\n",
      "Epoch6938 | train loss 0.5531971440464258\n",
      "Epoch6939 | train loss 0.5531957050785422\n",
      "Epoch6940 | train loss 0.553195734731853\n",
      "Epoch6941 | train loss 0.5531970391608775\n",
      "Epoch6942 | train loss 0.5531973095797003\n",
      "Epoch6943 | train loss 0.553196766115725\n",
      "Epoch6944 | train loss 0.5531957302801311\n",
      "Epoch6945 | train loss 0.5531970367766916\n",
      "Epoch6946 | train loss 0.553197079282254\n",
      "Epoch6947 | train loss 0.5531972295418381\n",
      "Epoch6948 | train loss 0.5531973977573216\n",
      "Epoch6949 | train loss 0.553197010755539\n",
      "Epoch6950 | train loss 0.553195013012737\n",
      "Epoch6951 | train loss 0.5531971970759332\n",
      "Epoch6952 | train loss 0.5531970227509737\n",
      "Epoch6953 | train loss 0.5531966662406922\n",
      "Epoch6954 | train loss 0.5531971166096628\n",
      "Epoch6955 | train loss 0.5531966194137931\n",
      "Epoch6956 | train loss 0.553195507414639\n",
      "Epoch6957 | train loss 0.5531969718821347\n",
      "Epoch6958 | train loss 0.5531970399059355\n",
      "Epoch6959 | train loss 0.5531967773847282\n",
      "Epoch6960 | train loss 0.553194834291935\n",
      "Epoch6961 | train loss 0.5531955699436366\n",
      "Epoch6962 | train loss 0.5531956678442657\n",
      "Epoch6963 | train loss 0.5531968762725592\n",
      "Epoch6964 | train loss 0.5531967378780246\n",
      "Epoch6965 | train loss 0.5531968719139695\n",
      "Epoch6966 | train loss 0.5531955522298813\n",
      "Epoch6967 | train loss 0.5531961959414184\n",
      "Epoch6968 | train loss 0.5531957537308335\n",
      "Epoch6969 | train loss 0.5531969496235252\n",
      "Epoch6970 | train loss 0.553197007291019\n",
      "Epoch6971 | train loss 0.5531966665014625\n",
      "Epoch6972 | train loss 0.553195257242769\n",
      "Epoch6973 | train loss 0.5531955038383604\n",
      "Epoch6974 | train loss 0.5531957764364779\n",
      "Epoch6975 | train loss 0.553195886015892\n",
      "Epoch6976 | train loss 0.5531957156024874\n",
      "Epoch6977 | train loss 0.5531966288387775\n",
      "Epoch6978 | train loss 0.5531970012560486\n",
      "Epoch6979 | train loss 0.5531967245601117\n",
      "Epoch6980 | train loss 0.5531954805925489\n",
      "Epoch6981 | train loss 0.5531958620622754\n",
      "Epoch6982 | train loss 0.5531960558891297\n",
      "Epoch6983 | train loss 0.5531966997496783\n",
      "Epoch6984 | train loss 0.553195418138057\n",
      "Epoch6985 | train loss 0.5531951227597892\n",
      "Epoch6986 | train loss 0.5531956757046282\n",
      "Epoch6987 | train loss 0.5531958045437932\n",
      "Epoch6988 | train loss 0.5531956415995956\n",
      "Epoch6989 | train loss 0.553195759896189\n",
      "Epoch6990 | train loss 0.5531956138834357\n",
      "Epoch6991 | train loss 0.553195487819612\n",
      "Epoch6992 | train loss 0.5531959715858101\n",
      "Epoch6993 | train loss 0.5531966129504144\n",
      "Epoch6994 | train loss 0.5531950957514346\n",
      "Epoch6995 | train loss 0.5531957743130624\n",
      "Epoch6996 | train loss 0.5531953921355307\n",
      "Epoch6997 | train loss 0.5531964685954154\n",
      "Epoch6998 | train loss 0.553195545822382\n",
      "Epoch6999 | train loss 0.5531950523890555\n",
      "Epoch7000 | train loss 0.5531961041875184\n",
      "Epoch7001 | train loss 0.5531964858807623\n",
      "Epoch7002 | train loss 0.5531948895193637\n",
      "Epoch7003 | train loss 0.5531954246014357\n",
      "Epoch7004 | train loss 0.5531956932879984\n",
      "Epoch7005 | train loss 0.5531953434459865\n",
      "Epoch7006 | train loss 0.5531962835788726\n",
      "Epoch7007 | train loss 0.5531949369050563\n",
      "Epoch7008 | train loss 0.5531957637704908\n",
      "Epoch7009 | train loss 0.5531963724642992\n",
      "Epoch7010 | train loss 0.5531948644295335\n",
      "Epoch7011 | train loss 0.5531958803907037\n",
      "Epoch7012 | train loss 0.5531952843256295\n",
      "Epoch7013 | train loss 0.553196176327765\n",
      "Epoch7014 | train loss 0.5531949018873275\n",
      "Epoch7015 | train loss 0.5531954977847636\n",
      "Epoch7016 | train loss 0.5531954493187368\n",
      "Epoch7017 | train loss 0.5531962138041854\n",
      "Epoch7018 | train loss 0.5531946268677711\n",
      "Epoch7019 | train loss 0.553195225354284\n",
      "Epoch7020 | train loss 0.5531955061294138\n",
      "Epoch7021 | train loss 0.553195140324533\n",
      "Epoch7022 | train loss 0.5531962290406227\n",
      "Epoch7023 | train loss 0.5531946733407677\n",
      "Epoch7024 | train loss 0.5531951609626412\n",
      "Epoch7025 | train loss 0.5531949880346656\n",
      "Epoch7026 | train loss 0.553195355758071\n",
      "Epoch7027 | train loss 0.5531949421949685\n",
      "Epoch7028 | train loss 0.5531949875317514\n",
      "Epoch7029 | train loss 0.5531957874074578\n",
      "Epoch7030 | train loss 0.5531946089863777\n",
      "Epoch7031 | train loss 0.5531955622881651\n",
      "Epoch7032 | train loss 0.5531949135474861\n",
      "Epoch7033 | train loss 0.5531951899640262\n",
      "Epoch7034 | train loss 0.5531953546591103\n",
      "Epoch7035 | train loss 0.5531950025632978\n",
      "Epoch7036 | train loss 0.5531959016993642\n",
      "Epoch7037 | train loss 0.553194738086313\n",
      "Epoch7038 | train loss 0.5531953696906566\n",
      "Epoch7039 | train loss 0.5531948629021645\n",
      "Epoch7040 | train loss 0.5531946989148855\n",
      "Epoch7041 | train loss 0.5531947426684201\n",
      "Epoch7042 | train loss 0.5531952073611319\n",
      "Epoch7043 | train loss 0.5531942368298769\n",
      "Epoch7044 | train loss 0.5531947009824216\n",
      "Epoch7045 | train loss 0.5531946952827275\n",
      "Epoch7046 | train loss 0.5531948282197118\n",
      "Epoch7047 | train loss 0.5531945144943893\n",
      "Epoch7048 | train loss 0.553194888830185\n",
      "Epoch7049 | train loss 0.5531947892904282\n",
      "Epoch7050 | train loss 0.5531956694461405\n",
      "Epoch7051 | train loss 0.5531942011229694\n",
      "Epoch7052 | train loss 0.5531950612924993\n",
      "Epoch7053 | train loss 0.5531946129351855\n",
      "Epoch7054 | train loss 0.5531947292201221\n",
      "Epoch7055 | train loss 0.5531945331394672\n",
      "Epoch7056 | train loss 0.5531945594958961\n",
      "Epoch7057 | train loss 0.553194897454232\n",
      "Epoch7058 | train loss 0.5531946903839707\n",
      "Epoch7059 | train loss 0.553194680865854\n",
      "Epoch7060 | train loss 0.5531947241164744\n",
      "Epoch7061 | train loss 0.5531943775154651\n",
      "Epoch7062 | train loss 0.5531946203298866\n",
      "Epoch7063 | train loss 0.5531947313994169\n",
      "Epoch7064 | train loss 0.5531943813338875\n",
      "Epoch7065 | train loss 0.5531938090547919\n",
      "Epoch7066 | train loss 0.5531946429982781\n",
      "Epoch7067 | train loss 0.5531948118656874\n",
      "Epoch7068 | train loss 0.5531943060271441\n",
      "Epoch7069 | train loss 0.5531942228786647\n",
      "Epoch7070 | train loss 0.5531945475749671\n",
      "Epoch7071 | train loss 0.5531944094598293\n",
      "Epoch7072 | train loss 0.553194033447653\n",
      "Epoch7073 | train loss 0.5531941328756511\n",
      "Epoch7074 | train loss 0.5531941671483218\n",
      "Epoch7075 | train loss 0.5531935403682291\n",
      "Epoch7076 | train loss 0.553194196075201\n",
      "Epoch7077 | train loss 0.5531938290968538\n",
      "Epoch7078 | train loss 0.5531939349882304\n",
      "Epoch7079 | train loss 0.5531941582076252\n",
      "Epoch7080 | train loss 0.553194011989981\n",
      "Epoch7081 | train loss 0.553193817846477\n",
      "Epoch7082 | train loss 0.553194678556174\n",
      "Epoch7083 | train loss 0.5531943387538195\n",
      "Epoch7084 | train loss 0.5531930671073496\n",
      "Epoch7085 | train loss 0.5531938541308046\n",
      "Epoch7086 | train loss 0.5531939782388509\n",
      "Epoch7087 | train loss 0.5531936075352132\n",
      "Epoch7088 | train loss 0.5531936654262245\n",
      "Epoch7089 | train loss 0.5531936383061111\n",
      "Epoch7090 | train loss 0.5531937089934945\n",
      "Epoch7091 | train loss 0.5531939613074064\n",
      "Epoch7092 | train loss 0.5531939673237503\n",
      "Epoch7093 | train loss 0.5531938258372248\n",
      "Epoch7094 | train loss 0.5531936173513532\n",
      "Epoch7095 | train loss 0.5531936480663717\n",
      "Epoch7096 | train loss 0.5531939979642629\n",
      "Epoch7097 | train loss 0.5531934946030378\n",
      "Epoch7098 | train loss 0.5531937972828745\n",
      "Epoch7099 | train loss 0.5531939502060413\n",
      "Epoch7100 | train loss 0.5531935897096991\n",
      "Epoch7101 | train loss 0.5531930257752538\n",
      "Epoch7102 | train loss 0.5531940284743905\n",
      "Epoch7103 | train loss 0.5531945643946529\n",
      "Epoch7104 | train loss 0.553192387688905\n",
      "Epoch7105 | train loss 0.553193436767906\n",
      "Epoch7106 | train loss 0.5531935413181782\n",
      "Epoch7107 | train loss 0.553193253967911\n",
      "Epoch7108 | train loss 0.5531933763809502\n",
      "Epoch7109 | train loss 0.5531933118961752\n",
      "Epoch7110 | train loss 0.5531934435479343\n",
      "Epoch7111 | train loss 0.5531933174096048\n",
      "Epoch7112 | train loss 0.5531936988420785\n",
      "Epoch7113 | train loss 0.5531935451366007\n",
      "Epoch7114 | train loss 0.5531931616365909\n",
      "Epoch7115 | train loss 0.5531932573579251\n",
      "Epoch7116 | train loss 0.5531934697553516\n",
      "Epoch7117 | train loss 0.5531930824182928\n",
      "Epoch7118 | train loss 0.5531932215951383\n",
      "Epoch7119 | train loss 0.5531941910646856\n",
      "Epoch7120 | train loss 0.5531923284009099\n",
      "Epoch7121 | train loss 0.5531933177821338\n",
      "Epoch7122 | train loss 0.5531937910616398\n",
      "Epoch7123 | train loss 0.5531927541084588\n",
      "Epoch7124 | train loss 0.5531932289712131\n",
      "Epoch7125 | train loss 0.5531933124549687\n",
      "Epoch7126 | train loss 0.5531928906403482\n",
      "Epoch7127 | train loss 0.5531925877183675\n",
      "Epoch7128 | train loss 0.5531929329782724\n",
      "Epoch7129 | train loss 0.5531927679851651\n",
      "Epoch7130 | train loss 0.5531928931735456\n",
      "Epoch7131 | train loss 0.5531932189501823\n",
      "Epoch7132 | train loss 0.5531933560036123\n",
      "Epoch7133 | train loss 0.5531935673393309\n",
      "Epoch7134 | train loss 0.5531929322518409\n",
      "Epoch7135 | train loss 0.5531922337040305\n",
      "Epoch7136 | train loss 0.5531927207112313\n",
      "Epoch7137 | train loss 0.5531924680620431\n",
      "Epoch7138 | train loss 0.5531928967125714\n",
      "Epoch7139 | train loss 0.5531929008290172\n",
      "Epoch7140 | train loss 0.553193926755339\n",
      "Epoch7141 | train loss 0.5531926105543971\n",
      "Epoch7142 | train loss 0.5531929488107562\n",
      "Epoch7143 | train loss 0.5531920065172017\n",
      "Epoch7144 | train loss 0.553193092904985\n",
      "Epoch7145 | train loss 0.5531928359717131\n",
      "Epoch7146 | train loss 0.5531923799775541\n",
      "Epoch7147 | train loss 0.553192875739187\n",
      "Epoch7148 | train loss 0.5531925143674016\n",
      "Epoch7149 | train loss 0.55319260597229\n",
      "Epoch7150 | train loss 0.5531928370520472\n",
      "Epoch7151 | train loss 0.5531930473819375\n",
      "Epoch7152 | train loss 0.5531919004581869\n",
      "Epoch7153 | train loss 0.5531926775351167\n",
      "Epoch7154 | train loss 0.5531928034499287\n",
      "Epoch7155 | train loss 0.553192434553057\n",
      "Epoch7156 | train loss 0.55319240283221\n",
      "Epoch7157 | train loss 0.5531926612928509\n",
      "Epoch7158 | train loss 0.5531926702335477\n",
      "Epoch7159 | train loss 0.5531919010356069\n",
      "Epoch7160 | train loss 0.5531921685859561\n",
      "Epoch7161 | train loss 0.5531922697648406\n",
      "Epoch7162 | train loss 0.5531924101896584\n",
      "Epoch7163 | train loss 0.5531934176199138\n",
      "Epoch7164 | train loss 0.5531924325786531\n",
      "Epoch7165 | train loss 0.5531927563808858\n",
      "Epoch7166 | train loss 0.5531925193406642\n",
      "Epoch7167 | train loss 0.5531916242092848\n",
      "Epoch7168 | train loss 0.5531925802864134\n",
      "Epoch7169 | train loss 0.5531918365880847\n",
      "Epoch7170 | train loss 0.553192245811224\n",
      "Epoch7171 | train loss 0.5531922334060073\n",
      "Epoch7172 | train loss 0.5531926261819899\n",
      "Epoch7173 | train loss 0.5531925717741251\n",
      "Epoch7174 | train loss 0.5531923221237958\n",
      "Epoch7175 | train loss 0.5531914144195617\n",
      "Epoch7176 | train loss 0.5531922553852201\n",
      "Epoch7177 | train loss 0.553192260991782\n",
      "Epoch7178 | train loss 0.5531916743330657\n",
      "Epoch7179 | train loss 0.5531920109502971\n",
      "Epoch7180 | train loss 0.5531921549886465\n",
      "Epoch7181 | train loss 0.5531923821382224\n",
      "Epoch7182 | train loss 0.5531922684796154\n",
      "Epoch7183 | train loss 0.5531923243962228\n",
      "Epoch7184 | train loss 0.5531920720078051\n",
      "Epoch7185 | train loss 0.5531915167160332\n",
      "Epoch7186 | train loss 0.5531919011287392\n",
      "Epoch7187 | train loss 0.5531920314021409\n",
      "Epoch7188 | train loss 0.5531918439641594\n",
      "Epoch7189 | train loss 0.553191957809031\n",
      "Epoch7190 | train loss 0.5531916765496134\n",
      "Epoch7191 | train loss 0.5531918994709849\n",
      "Epoch7192 | train loss 0.5531920197606087\n",
      "Epoch7193 | train loss 0.5531920311227441\n",
      "Epoch7194 | train loss 0.5531918575242162\n",
      "Epoch7195 | train loss 0.5531919278763234\n",
      "Epoch7196 | train loss 0.5531916406191886\n",
      "Epoch7197 | train loss 0.5531918680667878\n",
      "Epoch7198 | train loss 0.5531920884735883\n",
      "Epoch7199 | train loss 0.5531918855942786\n",
      "Epoch7200 | train loss 0.5531917231157422\n",
      "Epoch7201 | train loss 0.5531921186484396\n",
      "Epoch7202 | train loss 0.5531919099763036\n",
      "Epoch7203 | train loss 0.5531916437670589\n",
      "Epoch7204 | train loss 0.5531917009502649\n",
      "Epoch7205 | train loss 0.5531920370273292\n",
      "Epoch7206 | train loss 0.5531918450444937\n",
      "Epoch7207 | train loss 0.5531916812807322\n",
      "Epoch7208 | train loss 0.553191597070545\n",
      "Epoch7209 | train loss 0.553191168513149\n",
      "Epoch7210 | train loss 0.5531918659806252\n",
      "Epoch7211 | train loss 0.5531917290389538\n",
      "Epoch7212 | train loss 0.5531915059313178\n",
      "Epoch7213 | train loss 0.5531917632371187\n",
      "Epoch7214 | train loss 0.5531915165111423\n",
      "Epoch7215 | train loss 0.553191637955606\n",
      "Epoch7216 | train loss 0.5531916013360023\n",
      "Epoch7217 | train loss 0.5531916468031705\n",
      "Epoch7218 | train loss 0.5531917053833604\n",
      "Epoch7219 | train loss 0.553191546201706\n",
      "Epoch7220 | train loss 0.553191473800689\n",
      "Epoch7221 | train loss 0.5531909537874162\n",
      "Epoch7222 | train loss 0.5531917572207748\n",
      "Epoch7223 | train loss 0.5531916372105479\n",
      "Epoch7224 | train loss 0.5531914796866476\n",
      "Epoch7225 | train loss 0.5531914072483778\n",
      "Epoch7226 | train loss 0.553191275820136\n",
      "Epoch7227 | train loss 0.5531915618106723\n",
      "Epoch7228 | train loss 0.5531914553791285\n",
      "Epoch7229 | train loss 0.5531915513798594\n",
      "Epoch7230 | train loss 0.5531916747055948\n",
      "Epoch7231 | train loss 0.5531908881664276\n",
      "Epoch7232 | train loss 0.5531915277615189\n",
      "Epoch7233 | train loss 0.5531914097815752\n",
      "Epoch7234 | train loss 0.5531915263459086\n",
      "Epoch7235 | train loss 0.5531914730742574\n",
      "Epoch7236 | train loss 0.553191336914897\n",
      "Epoch7237 | train loss 0.5531912282854319\n",
      "Epoch7238 | train loss 0.5531911036744713\n",
      "Epoch7239 | train loss 0.5531917115487158\n",
      "Epoch7240 | train loss 0.5531914475187659\n",
      "Epoch7241 | train loss 0.5531912993639707\n",
      "Epoch7242 | train loss 0.553191337659955\n",
      "Epoch7243 | train loss 0.5531914418376982\n",
      "Epoch7244 | train loss 0.553191398140043\n",
      "Epoch7245 | train loss 0.5531911794282496\n",
      "Epoch7246 | train loss 0.5531913184560835\n",
      "Epoch7247 | train loss 0.5531907838582992\n",
      "Epoch7248 | train loss 0.5531914467550814\n",
      "Epoch7249 | train loss 0.5531913639046252\n",
      "Epoch7250 | train loss 0.5531913254596293\n",
      "Epoch7251 | train loss 0.5531912900879979\n",
      "Epoch7252 | train loss 0.5531912375614048\n",
      "Epoch7253 | train loss 0.5531912326812745\n",
      "Epoch7254 | train loss 0.5531913532875479\n",
      "Epoch7255 | train loss 0.5531910870783031\n",
      "Epoch7256 | train loss 0.5531912549585104\n",
      "Epoch7257 | train loss 0.5531907327659428\n",
      "Epoch7258 | train loss 0.5531913571245969\n",
      "Epoch7259 | train loss 0.5531912528537214\n",
      "Epoch7260 | train loss 0.5531912490911782\n",
      "Epoch7261 | train loss 0.5531911040283739\n",
      "Epoch7262 | train loss 0.5531911893375218\n",
      "Epoch7263 | train loss 0.5531911752745509\n",
      "Epoch7264 | train loss 0.5531913760490715\n",
      "Epoch7265 | train loss 0.5531910057738423\n",
      "Epoch7266 | train loss 0.5531910538487136\n",
      "Epoch7267 | train loss 0.5531911478377879\n",
      "Epoch7268 | train loss 0.5531905851513147\n",
      "Epoch7269 | train loss 0.5531914117746055\n",
      "Epoch7270 | train loss 0.5531911940127611\n",
      "Epoch7271 | train loss 0.5531910252571106\n",
      "Epoch7272 | train loss 0.5531911055743695\n",
      "Epoch7273 | train loss 0.5531909260712564\n",
      "Epoch7274 | train loss 0.5531911755353213\n",
      "Epoch7275 | train loss 0.5531911585107445\n",
      "Epoch7276 | train loss 0.5531909191608428\n",
      "Epoch7277 | train loss 0.5531909601204097\n",
      "Epoch7278 | train loss 0.5531912449561059\n",
      "Epoch7279 | train loss 0.5531911599822342\n",
      "Epoch7280 | train loss 0.5531909241713584\n",
      "Epoch7281 | train loss 0.5531908677518368\n",
      "Epoch7282 | train loss 0.5531909369677305\n",
      "Epoch7283 | train loss 0.5531905398517847\n",
      "Epoch7284 | train loss 0.5531910069659353\n",
      "Epoch7285 | train loss 0.5531909677758813\n",
      "Epoch7286 | train loss 0.5531910950876773\n",
      "Epoch7287 | train loss 0.5531908021867276\n",
      "Epoch7288 | train loss 0.5531908828765154\n",
      "Epoch7289 | train loss 0.5531911496073008\n",
      "Epoch7290 | train loss 0.5531910604052246\n",
      "Epoch7291 | train loss 0.5531908328458667\n",
      "Epoch7292 | train loss 0.5531907751597465\n",
      "Epoch7293 | train loss 0.5531909041106701\n",
      "Epoch7294 | train loss 0.553190926425159\n",
      "Epoch7295 | train loss 0.5531908149830997\n",
      "Epoch7296 | train loss 0.5531908607855439\n",
      "Epoch7297 | train loss 0.5531909158267081\n",
      "Epoch7298 | train loss 0.553190619237721\n",
      "Epoch7299 | train loss 0.5531903692334891\n",
      "Epoch7300 | train loss 0.5531908466853201\n",
      "Epoch7301 | train loss 0.5531908060610294\n",
      "Epoch7302 | train loss 0.5531910202093422\n",
      "Epoch7303 | train loss 0.5531909628771245\n",
      "Epoch7304 | train loss 0.5531907147355377\n",
      "Epoch7305 | train loss 0.5531906629912555\n",
      "Epoch7306 | train loss 0.553190811406821\n",
      "Epoch7307 | train loss 0.553190831206739\n",
      "Epoch7308 | train loss 0.5531907014548778\n",
      "Epoch7309 | train loss 0.5531906524673105\n",
      "Epoch7310 | train loss 0.5531907482631504\n",
      "Epoch7311 | train loss 0.5531909690052271\n",
      "Epoch7312 | train loss 0.5531909269280731\n",
      "Epoch7313 | train loss 0.5531906636804342\n",
      "Epoch7314 | train loss 0.5531906184740365\n",
      "Epoch7315 | train loss 0.5531905869580805\n",
      "Epoch7316 | train loss 0.553190731741488\n",
      "Epoch7317 | train loss 0.5531910046935081\n",
      "Epoch7318 | train loss 0.5531902351602912\n",
      "Epoch7319 | train loss 0.5531906473264098\n",
      "Epoch7320 | train loss 0.5531905692815781\n",
      "Epoch7321 | train loss 0.5531906475871802\n",
      "Epoch7322 | train loss 0.5531907126680017\n",
      "Epoch7323 | train loss 0.5531905381195247\n",
      "Epoch7324 | train loss 0.5531906826607883\n",
      "Epoch7325 | train loss 0.5531909164600074\n",
      "Epoch7326 | train loss 0.5531901844777167\n",
      "Epoch7327 | train loss 0.5531905929930508\n",
      "Epoch7328 | train loss 0.5531905301846564\n",
      "Epoch7329 | train loss 0.5531904887408018\n",
      "Epoch7330 | train loss 0.5531906328722834\n",
      "Epoch7331 | train loss 0.5531908947788179\n",
      "Epoch7332 | train loss 0.5531900965049863\n",
      "Epoch7333 | train loss 0.5531905543804169\n",
      "Epoch7334 | train loss 0.5531904775835573\n",
      "Epoch7335 | train loss 0.5531905327923596\n",
      "Epoch7336 | train loss 0.5531905203871429\n",
      "Epoch7337 | train loss 0.5531904545798898\n",
      "Epoch7338 | train loss 0.5531905956752599\n",
      "Epoch7339 | train loss 0.5531909495405852\n",
      "Epoch7340 | train loss 0.5531899872235954\n",
      "Epoch7341 | train loss 0.553190509211272\n",
      "Epoch7342 | train loss 0.5531904290802777\n",
      "Epoch7343 | train loss 0.5531903862021863\n",
      "Epoch7344 | train loss 0.5531903696991504\n",
      "Epoch7345 | train loss 0.5531905306503176\n",
      "Epoch7346 | train loss 0.5531908122263849\n",
      "Epoch7347 | train loss 0.5531903496570885\n",
      "Epoch7348 | train loss 0.5531904016621411\n",
      "Epoch7349 | train loss 0.5531903837621212\n",
      "Epoch7350 | train loss 0.5531903618201613\n",
      "Epoch7351 | train loss 0.553190524354577\n",
      "Epoch7352 | train loss 0.5531907816417515\n",
      "Epoch7353 | train loss 0.5531899457797408\n",
      "Epoch7354 | train loss 0.5531904634088278\n",
      "Epoch7355 | train loss 0.5531903812475503\n",
      "Epoch7356 | train loss 0.5531902742199599\n",
      "Epoch7357 | train loss 0.553190549928695\n",
      "Epoch7358 | train loss 0.5531899841874838\n",
      "Epoch7359 | train loss 0.5531903221830725\n",
      "Epoch7360 | train loss 0.5531905227154493\n",
      "Epoch7361 | train loss 0.5531907440721988\n",
      "Epoch7362 | train loss 0.5531899027898908\n",
      "Epoch7363 | train loss 0.5531904192641377\n",
      "Epoch7364 | train loss 0.5531902742944658\n",
      "Epoch7365 | train loss 0.5531903015263379\n",
      "Epoch7366 | train loss 0.5531904304027557\n",
      "Epoch7367 | train loss 0.5531906975992024\n",
      "Epoch7368 | train loss 0.5531902788951993\n",
      "Epoch7369 | train loss 0.5531902534514666\n",
      "Epoch7370 | train loss 0.5531902453489601\n",
      "Epoch7371 | train loss 0.5531902239285409\n",
      "Epoch7372 | train loss 0.5531902754493058\n",
      "Epoch7373 | train loss 0.5531903588585556\n",
      "Epoch7374 | train loss 0.5531906495988369\n",
      "Epoch7375 | train loss 0.553190058991313\n",
      "Epoch7376 | train loss 0.553190292250365\n",
      "Epoch7377 | train loss 0.553190187793225\n",
      "Epoch7378 | train loss 0.5531901582702994\n",
      "Epoch7379 | train loss 0.5531901372410357\n",
      "Epoch7380 | train loss 0.5531901808828116\n",
      "Epoch7381 | train loss 0.5531902800127864\n",
      "Epoch7382 | train loss 0.5531905931606889\n",
      "Epoch7383 | train loss 0.5531897811405361\n",
      "Epoch7384 | train loss 0.5531902631372213\n",
      "Epoch7385 | train loss 0.5531901321932673\n",
      "Epoch7386 | train loss 0.5531900948472321\n",
      "Epoch7387 | train loss 0.5531897551752627\n",
      "Epoch7388 | train loss 0.5531900988519192\n",
      "Epoch7389 | train loss 0.5531902541406453\n",
      "Epoch7390 | train loss 0.5531906058639288\n",
      "Epoch7391 | train loss 0.5531900703348219\n",
      "Epoch7392 | train loss 0.5531900459714234\n",
      "Epoch7393 | train loss 0.5531900849938393\n",
      "Epoch7394 | train loss 0.5531901564262808\n",
      "Epoch7395 | train loss 0.5531900783069432\n",
      "Epoch7396 | train loss 0.5531902635656297\n",
      "Epoch7397 | train loss 0.5531908381544054\n",
      "Epoch7398 | train loss 0.5531898950599135\n",
      "Epoch7399 | train loss 0.5531901542283595\n",
      "Epoch7400 | train loss 0.5531901247426867\n",
      "Epoch7401 | train loss 0.5531901121698319\n",
      "Epoch7402 | train loss 0.5531901062093675\n",
      "Epoch7403 | train loss 0.5531900941953063\n",
      "Epoch7404 | train loss 0.5531900846026838\n",
      "Epoch7405 | train loss 0.5531902497261763\n",
      "Epoch7406 | train loss 0.5531905890442431\n",
      "Epoch7407 | train loss 0.5531896496377885\n",
      "Epoch7408 | train loss 0.5531901811435819\n",
      "Epoch7409 | train loss 0.5531901093944908\n",
      "Epoch7410 | train loss 0.5531900686584413\n",
      "Epoch7411 | train loss 0.5531900416128337\n",
      "Epoch7412 | train loss 0.5531898991018533\n",
      "Epoch7413 | train loss 0.5531900868937373\n",
      "Epoch7414 | train loss 0.5531902397610247\n",
      "Epoch7415 | train loss 0.5531905353069305\n",
      "Epoch7416 | train loss 0.5531899182125926\n",
      "Epoch7417 | train loss 0.5531897218711674\n",
      "Epoch7418 | train loss 0.5531902073696255\n",
      "Epoch7419 | train loss 0.5531901053711772\n",
      "Epoch7420 | train loss 0.5531900707632303\n",
      "Epoch7421 | train loss 0.5531900334730744\n",
      "Epoch7422 | train loss 0.5531902726925909\n",
      "Epoch7423 | train loss 0.553190093562007\n",
      "Epoch7424 | train loss 0.5531898146495223\n",
      "Epoch7425 | train loss 0.5531901126541198\n",
      "Epoch7426 | train loss 0.5531900385953485\n",
      "Epoch7427 | train loss 0.553190008662641\n",
      "Epoch7428 | train loss 0.5531899989582598\n",
      "Epoch7429 | train loss 0.5531897755712271\n",
      "Epoch7430 | train loss 0.5531901645474135\n",
      "Epoch7431 | train loss 0.5531900354288518\n",
      "Epoch7432 | train loss 0.5531899998150765\n",
      "Epoch7433 | train loss 0.5531899823062122\n",
      "Epoch7434 | train loss 0.5531900759972632\n",
      "Epoch7435 | train loss 0.5531898912601173\n",
      "Epoch7436 | train loss 0.5531901593133807\n",
      "Epoch7437 | train loss 0.5531901308707893\n",
      "Epoch7438 | train loss 0.5531901123747229\n",
      "Epoch7439 | train loss 0.5531898981519043\n",
      "Epoch7440 | train loss 0.5531901587545872\n",
      "Epoch7441 | train loss 0.5531900940462947\n",
      "Epoch7442 | train loss 0.5531898841448128\n",
      "Epoch7443 | train loss 0.55319012908265\n",
      "Epoch7444 | train loss 0.5531900991499424\n",
      "Epoch7445 | train loss 0.5531898654438555\n",
      "Epoch7446 | train loss 0.5531901233643294\n",
      "Epoch7447 | train loss 0.5531900883838534\n",
      "Epoch7448 | train loss 0.5531898476555943\n",
      "Epoch7449 | train loss 0.5531901139020919\n",
      "Epoch7450 | train loss 0.5531900798156858\n",
      "Epoch7451 | train loss 0.5531900506466627\n",
      "Epoch7452 | train loss 0.5531898229010404\n",
      "Epoch7453 | train loss 0.5531900823488831\n",
      "Epoch7454 | train loss 0.5531900474056601\n",
      "Epoch7455 | train loss 0.553189771529287\n",
      "Epoch7456 | train loss 0.5531900733709335\n",
      "Epoch7457 | train loss 0.5531900295056402\n",
      "Epoch7458 | train loss 0.5531900004297495\n",
      "Epoch7459 | train loss 0.553189768474549\n",
      "Epoch7460 | train loss 0.5531899596750737\n",
      "Epoch7461 | train loss 0.553189933244139\n",
      "Epoch7462 | train loss 0.5531901533715426\n",
      "Epoch7463 | train loss 0.5531899798475206\n",
      "Epoch7464 | train loss 0.5531899627670646\n",
      "Epoch7465 | train loss 0.5531899768300355\n",
      "Epoch7466 | train loss 0.5531896838732063\n",
      "Epoch7467 | train loss 0.553190001025796\n",
      "Epoch7468 | train loss 0.5531894479133189\n",
      "Epoch7469 | train loss 0.5531900430843234\n",
      "Epoch7470 | train loss 0.5531899719685316\n",
      "Epoch7471 | train loss 0.5531902312859893\n",
      "Epoch7472 | train loss 0.5531901971064508\n",
      "Epoch7473 | train loss 0.5531896480545402\n",
      "Epoch7474 | train loss 0.5531899323686957\n",
      "Epoch7475 | train loss 0.5531899854168296\n",
      "Epoch7476 | train loss 0.5531900399550795\n",
      "Epoch7477 | train loss 0.5531896759569644\n",
      "Epoch7478 | train loss 0.553189872018993\n",
      "Epoch7479 | train loss 0.5531903265416622\n",
      "Epoch7480 | train loss 0.5531896330229938\n",
      "Epoch7481 | train loss 0.5531899976357818\n",
      "Epoch7482 | train loss 0.5531897676736116\n",
      "Epoch7483 | train loss 0.5531899901106954\n",
      "Epoch7484 | train loss 0.5531896343827247\n",
      "Epoch7485 | train loss 0.5531898323446512\n",
      "Epoch7486 | train loss 0.553190004825592\n",
      "Epoch7487 | train loss 0.5531898622028529\n",
      "Epoch7488 | train loss 0.5531898633949459\n",
      "Epoch7489 | train loss 0.5531901497021318\n",
      "Epoch7490 | train loss 0.5531897613033653\n",
      "Epoch7491 | train loss 0.5531898128800095\n",
      "Epoch7492 | train loss 0.5531898578256369\n",
      "Epoch7493 | train loss 0.5531896509230136\n",
      "Epoch7494 | train loss 0.5531899083219468\n",
      "Epoch7495 | train loss 0.5531895505264401\n",
      "Epoch7496 | train loss 0.5531897358782589\n",
      "Epoch7497 | train loss 0.5531901589594781\n",
      "Epoch7498 | train loss 0.553189491648227\n",
      "Epoch7499 | train loss 0.5531898494437337\n",
      "Epoch7500 | train loss 0.5531898376904428\n",
      "Epoch7501 | train loss 0.5531898837164044\n",
      "Epoch7502 | train loss 0.5531897419318557\n",
      "Epoch7503 | train loss 0.5531897631287575\n",
      "Epoch7504 | train loss 0.5531900472939014\n",
      "Epoch7505 | train loss 0.5531890411674977\n",
      "Epoch7506 | train loss 0.553189667351544\n",
      "Epoch7507 | train loss 0.5531898388825357\n",
      "Epoch7508 | train loss 0.5531893666833639\n",
      "Epoch7509 | train loss 0.5531895950809121\n",
      "Epoch7510 | train loss 0.5531900053843856\n",
      "Epoch7511 | train loss 0.5531899669766426\n",
      "Epoch7512 | train loss 0.5531893495097756\n",
      "Epoch7513 | train loss 0.5531893913820386\n",
      "Epoch7514 | train loss 0.5531895418837667\n",
      "Epoch7515 | train loss 0.553189576305449\n",
      "Epoch7516 | train loss 0.5531893241219222\n",
      "Epoch7517 | train loss 0.5531894872710109\n",
      "Epoch7518 | train loss 0.5531896307878196\n",
      "Epoch7519 | train loss 0.5531896099075675\n",
      "Epoch7520 | train loss 0.5531895659677685\n",
      "Epoch7521 | train loss 0.5531894419901073\n",
      "Epoch7522 | train loss 0.5531892823055387\n",
      "Epoch7523 | train loss 0.5531897633709013\n",
      "Epoch7524 | train loss 0.5531897001899779\n",
      "Epoch7525 | train loss 0.5531896293349564\n",
      "Epoch7526 | train loss 0.5531892568059266\n",
      "Epoch7527 | train loss 0.5531892782635986\n",
      "Epoch7528 | train loss 0.5531896088086069\n",
      "Epoch7529 | train loss 0.553189376089722\n",
      "Epoch7530 | train loss 0.5531900261715055\n",
      "Epoch7531 | train loss 0.5531895039603114\n",
      "Epoch7532 | train loss 0.5531892132945359\n",
      "Epoch7533 | train loss 0.5531896834820509\n",
      "Epoch7534 | train loss 0.5531898878142237\n",
      "Epoch7535 | train loss 0.5531893410719931\n",
      "Epoch7536 | train loss 0.5531897556968033\n",
      "Epoch7537 | train loss 0.5531891107000411\n",
      "Epoch7538 | train loss 0.5531893459521234\n",
      "Epoch7539 | train loss 0.5531898837350309\n",
      "Epoch7540 | train loss 0.5531895705685019\n",
      "Epoch7541 | train loss 0.5531892160512507\n",
      "Epoch7542 | train loss 0.55318943079561\n",
      "Epoch7543 | train loss 0.5531896283850074\n",
      "Epoch7544 | train loss 0.5531896314583719\n",
      "Epoch7545 | train loss 0.5531890979968012\n",
      "Epoch7546 | train loss 0.5531895008310675\n",
      "Epoch7547 | train loss 0.5531893782876431\n",
      "Epoch7548 | train loss 0.5531890244968235\n",
      "Epoch7549 | train loss 0.5531898094899952\n",
      "Epoch7550 | train loss 0.5531889619119466\n",
      "Epoch7551 | train loss 0.5531894350796938\n",
      "Epoch7552 | train loss 0.5531891816295683\n",
      "Epoch7553 | train loss 0.5531887285597622\n",
      "Epoch7554 | train loss 0.5531896505504846\n",
      "Epoch7555 | train loss 0.5531895070895553\n",
      "Epoch7556 | train loss 0.5531889353878796\n",
      "Epoch7557 | train loss 0.5531891941465438\n",
      "Epoch7558 | train loss 0.5531895149871707\n",
      "Epoch7559 | train loss 0.5531891364231706\n",
      "Epoch7560 | train loss 0.5531892884336412\n",
      "Epoch7561 | train loss 0.5531890267319978\n",
      "Epoch7562 | train loss 0.5531890842318535\n",
      "Epoch7563 | train loss 0.5531897178292274\n",
      "Epoch7564 | train loss 0.5531887810863555\n",
      "Epoch7565 | train loss 0.5531891274265945\n",
      "Epoch7566 | train loss 0.5531894700974226\n",
      "Epoch7567 | train loss 0.5531888664327562\n",
      "Epoch7568 | train loss 0.5531893467530609\n",
      "Epoch7569 | train loss 0.5531892192363739\n",
      "Epoch7570 | train loss 0.5531889633648097\n",
      "Epoch7571 | train loss 0.5531894544512034\n",
      "Epoch7572 | train loss 0.5531892335787415\n",
      "Epoch7573 | train loss 0.5531892355158925\n",
      "Epoch7574 | train loss 0.5531890339776874\n",
      "Epoch7575 | train loss 0.5531885087490082\n",
      "Epoch7576 | train loss 0.553189091347158\n",
      "Epoch7577 | train loss 0.5531893474049866\n",
      "Epoch7578 | train loss 0.5531888666749001\n",
      "Epoch7579 | train loss 0.5531892520189285\n",
      "Epoch7580 | train loss 0.5531893170811236\n",
      "Epoch7581 | train loss 0.5531884457543492\n",
      "Epoch7582 | train loss 0.5531895376183092\n",
      "Epoch7583 | train loss 0.5531885895878077\n",
      "Epoch7584 | train loss 0.5531888955458999\n",
      "Epoch7585 | train loss 0.5531896810978651\n",
      "Epoch7586 | train loss 0.55318871691823\n",
      "Epoch7587 | train loss 0.5531891891732812\n",
      "Epoch7588 | train loss 0.5531887827627361\n",
      "Epoch7589 | train loss 0.5531894400715828\n",
      "Epoch7590 | train loss 0.5531891113333404\n",
      "Epoch7591 | train loss 0.5531884103082121\n",
      "Epoch7592 | train loss 0.5531893710419535\n",
      "Epoch7593 | train loss 0.5531885498575866\n",
      "Epoch7594 | train loss 0.5531894032098353\n",
      "Epoch7595 | train loss 0.5531884867139161\n",
      "Epoch7596 | train loss 0.5531890100799501\n",
      "Epoch7597 | train loss 0.5531892726011575\n",
      "Epoch7598 | train loss 0.5531887415610254\n",
      "Epoch7599 | train loss 0.5531887185946107\n",
      "Epoch7600 | train loss 0.5531892769597471\n",
      "Epoch7601 | train loss 0.5531887305155396\n",
      "Epoch7602 | train loss 0.5531888177059591\n",
      "Epoch7603 | train loss 0.5531886160373688\n",
      "Epoch7604 | train loss 0.5531887524016201\n",
      "Epoch7605 | train loss 0.55318937683478\n",
      "Epoch7606 | train loss 0.5531884547695518\n",
      "Epoch7607 | train loss 0.5531893184967339\n",
      "Epoch7608 | train loss 0.5531887749768793\n",
      "Epoch7609 | train loss 0.5531886573694647\n",
      "Epoch7610 | train loss 0.5531887482106685\n",
      "Epoch7611 | train loss 0.5531889075413347\n",
      "Epoch7612 | train loss 0.5531888406351209\n",
      "Epoch7613 | train loss 0.5531887482106685\n",
      "Epoch7614 | train loss 0.5531891086511314\n",
      "Epoch7615 | train loss 0.5531885325908661\n",
      "Epoch7616 | train loss 0.5531886610388755\n",
      "Epoch7617 | train loss 0.5531886141747236\n",
      "Epoch7618 | train loss 0.5531892655603587\n",
      "Epoch7619 | train loss 0.5531886484660208\n",
      "Epoch7620 | train loss 0.5531888570636511\n",
      "Epoch7621 | train loss 0.5531888698600232\n",
      "Epoch7622 | train loss 0.5531886163726449\n",
      "Epoch7623 | train loss 0.5531889366917312\n",
      "Epoch7624 | train loss 0.5531887101568281\n",
      "Epoch7625 | train loss 0.5531886129640042\n",
      "Epoch7626 | train loss 0.5531890720315278\n",
      "Epoch7627 | train loss 0.5531887757778168\n",
      "Epoch7628 | train loss 0.5531883427873254\n",
      "Epoch7629 | train loss 0.5531886478699743\n",
      "Epoch7630 | train loss 0.5531889000721276\n",
      "Epoch7631 | train loss 0.5531890169903636\n",
      "Epoch7632 | train loss 0.553188416864723\n",
      "Epoch7633 | train loss 0.5531885455921293\n",
      "Epoch7634 | train loss 0.5531886252202094\n",
      "Epoch7635 | train loss 0.5531887577660382\n",
      "Epoch7636 | train loss 0.5531884054094554\n",
      "Epoch7637 | train loss 0.5531890534237027\n",
      "Epoch7638 | train loss 0.5531885327771306\n",
      "Epoch7639 | train loss 0.5531884563341737\n",
      "Epoch7640 | train loss 0.5531890962272883\n",
      "Epoch7641 | train loss 0.5531881922110915\n",
      "Epoch7642 | train loss 0.5531880737468601\n",
      "Epoch7643 | train loss 0.553189006652683\n",
      "Epoch7644 | train loss 0.553188716955483\n",
      "Epoch7645 | train loss 0.5531881226226687\n",
      "Epoch7646 | train loss 0.5531891341507434\n",
      "Epoch7647 | train loss 0.5531883321143687\n",
      "Epoch7648 | train loss 0.5531887253373862\n",
      "Epoch7649 | train loss 0.5531882942467928\n",
      "Epoch7650 | train loss 0.5531885415315628\n",
      "Epoch7651 | train loss 0.5531886521354318\n",
      "Epoch7652 | train loss 0.5531878125667572\n",
      "Epoch7653 | train loss 0.5531889454461634\n",
      "Epoch7654 | train loss 0.5531886476464569\n",
      "Epoch7655 | train loss 0.553187847584486\n",
      "Epoch7656 | train loss 0.5531884524971247\n",
      "Epoch7657 | train loss 0.5531886898353696\n",
      "Epoch7658 | train loss 0.5531885825283825\n",
      "Epoch7659 | train loss 0.5531885332614184\n",
      "Epoch7660 | train loss 0.5531881470233202\n",
      "Epoch7661 | train loss 0.553188381884247\n",
      "Epoch7662 | train loss 0.5531884680315852\n",
      "Epoch7663 | train loss 0.5531882234662772\n",
      "Epoch7664 | train loss 0.5531884062103927\n",
      "Epoch7665 | train loss 0.553188202995807\n",
      "Epoch7666 | train loss 0.5531885682418942\n",
      "Epoch7667 | train loss 0.5531883647665381\n",
      "Epoch7668 | train loss 0.5531882032565772\n",
      "Epoch7669 | train loss 0.5531880669109523\n",
      "Epoch7670 | train loss 0.5531885728426278\n",
      "Epoch7671 | train loss 0.553188228495419\n",
      "Epoch7672 | train loss 0.5531880282610655\n",
      "Epoch7673 | train loss 0.5531883074529469\n",
      "Epoch7674 | train loss 0.5531884581036866\n",
      "Epoch7675 | train loss 0.553188335634768\n",
      "Epoch7676 | train loss 0.5531881436891853\n",
      "Epoch7677 | train loss 0.5531876587867737\n",
      "Epoch7678 | train loss 0.553188594840467\n",
      "Epoch7679 | train loss 0.5531879560276866\n",
      "Epoch7680 | train loss 0.5531881979107857\n",
      "Epoch7681 | train loss 0.5531883934885263\n",
      "Epoch7682 | train loss 0.5531878441572189\n",
      "Epoch7683 | train loss 0.553188416082412\n",
      "Epoch7684 | train loss 0.5531878367438913\n",
      "Epoch7685 | train loss 0.5531883551739156\n",
      "Epoch7686 | train loss 0.55318778866902\n",
      "Epoch7687 | train loss 0.553188088145107\n",
      "Epoch7688 | train loss 0.5531885266304016\n",
      "Epoch7689 | train loss 0.5531881345063447\n",
      "Epoch7690 | train loss 0.5531881595402957\n",
      "Epoch7691 | train loss 0.5531881970912218\n",
      "Epoch7692 | train loss 0.5531877209991216\n",
      "Epoch7693 | train loss 0.553188242930919\n",
      "Epoch7694 | train loss 0.5531877073459327\n",
      "Epoch7695 | train loss 0.5531882335990668\n",
      "Epoch7696 | train loss 0.5531876993551851\n",
      "Epoch7697 | train loss 0.553187953364104\n",
      "Epoch7698 | train loss 0.5531878587976098\n",
      "Epoch7699 | train loss 0.5531880799494684\n",
      "Epoch7700 | train loss 0.5531875170394778\n",
      "Epoch7701 | train loss 0.5531879958882928\n",
      "Epoch7702 | train loss 0.5531880893185734\n",
      "Epoch7703 | train loss 0.5531875558197499\n",
      "Epoch7704 | train loss 0.5531878558546305\n",
      "Epoch7705 | train loss 0.5531880765780807\n",
      "Epoch7706 | train loss 0.5531878101080656\n",
      "Epoch7707 | train loss 0.5531878669559955\n",
      "Epoch7708 | train loss 0.5531878002174199\n",
      "Epoch7709 | train loss 0.5531876550614834\n",
      "Epoch7710 | train loss 0.553188175689429\n",
      "Epoch7711 | train loss 0.5531875850073993\n",
      "Epoch7712 | train loss 0.5531878723949194\n",
      "Epoch7713 | train loss 0.5531877285987139\n",
      "Epoch7714 | train loss 0.5531879677996039\n",
      "Epoch7715 | train loss 0.5531880418397486\n",
      "Epoch7716 | train loss 0.553187751211226\n",
      "Epoch7717 | train loss 0.5531878128647805\n",
      "Epoch7718 | train loss 0.5531873707659543\n",
      "Epoch7719 | train loss 0.553187424018979\n",
      "Epoch7720 | train loss 0.5531881723925471\n",
      "Epoch7721 | train loss 0.5531879263557493\n",
      "Epoch7722 | train loss 0.553187406398356\n",
      "Epoch7723 | train loss 0.5531877015158534\n",
      "Epoch7724 | train loss 0.553188034966588\n",
      "Epoch7725 | train loss 0.5531880807504058\n",
      "Epoch7726 | train loss 0.5531876168213785\n",
      "Epoch7727 | train loss 0.5531876384653152\n",
      "Epoch7728 | train loss 0.5531873382627964\n",
      "Epoch7729 | train loss 0.5531876911967992\n",
      "Epoch7730 | train loss 0.5531875836290419\n",
      "Epoch7731 | train loss 0.553187581691891\n",
      "Epoch7732 | train loss 0.553188090864569\n",
      "Epoch7733 | train loss 0.5531874982640147\n",
      "Epoch7734 | train loss 0.5531873823702336\n",
      "Epoch7735 | train loss 0.5531878316216171\n",
      "Epoch7736 | train loss 0.5531876146048308\n",
      "Epoch7737 | train loss 0.5531877189874649\n",
      "Epoch7738 | train loss 0.553187589328736\n",
      "Epoch7739 | train loss 0.5531872985512019\n",
      "Epoch7740 | train loss 0.5531878940574825\n",
      "Epoch7741 | train loss 0.5531873040087522\n",
      "Epoch7742 | train loss 0.5531873250193894\n",
      "Epoch7743 | train loss 0.5531878952682018\n",
      "Epoch7744 | train loss 0.553187671713531\n",
      "Epoch7745 | train loss 0.5531873411498964\n",
      "Epoch7746 | train loss 0.5531880464404821\n",
      "Epoch7747 | train loss 0.5531874759495259\n",
      "Epoch7748 | train loss 0.5531872823648155\n",
      "Epoch7749 | train loss 0.5531872471235693\n",
      "Epoch7750 | train loss 0.5531879374757409\n",
      "Epoch7751 | train loss 0.5531876125000417\n",
      "Epoch7752 | train loss 0.5531871093064546\n",
      "Epoch7753 | train loss 0.5531877559795976\n",
      "Epoch7754 | train loss 0.5531872041709721\n",
      "Epoch7755 | train loss 0.5531871718913317\n",
      "Epoch7756 | train loss 0.5531878803297877\n",
      "Epoch7757 | train loss 0.5531875317357481\n",
      "Epoch7758 | train loss 0.5531869745254516\n",
      "Epoch7759 | train loss 0.5531877978518606\n",
      "Epoch7760 | train loss 0.5531871176883578\n",
      "Epoch7761 | train loss 0.5531874482706189\n",
      "Epoch7762 | train loss 0.5531869892776012\n",
      "Epoch7763 | train loss 0.5531876797415316\n",
      "Epoch7764 | train loss 0.5531874956004321\n",
      "Epoch7765 | train loss 0.5531868931464851\n",
      "Epoch7766 | train loss 0.5531874645873904\n",
      "Epoch7767 | train loss 0.5531877400353551\n",
      "Epoch7768 | train loss 0.5531870747543871\n",
      "Epoch7769 | train loss 0.5531873171590269\n",
      "Epoch7770 | train loss 0.5531868432462216\n",
      "Epoch7771 | train loss 0.5531872730515898\n",
      "Epoch7772 | train loss 0.5531880010850727\n",
      "Epoch7773 | train loss 0.5531873543187976\n",
      "Epoch7774 | train loss 0.5531870646215975\n",
      "Epoch7775 | train loss 0.5531872457824647\n",
      "Epoch7776 | train loss 0.5531871545314789\n",
      "Epoch7777 | train loss 0.5531875054165721\n",
      "Epoch7778 | train loss 0.5531872631981969\n",
      "Epoch7779 | train loss 0.553187299799174\n",
      "Epoch7780 | train loss 0.5531868185289204\n",
      "Epoch7781 | train loss 0.5531871223263443\n",
      "Epoch7782 | train loss 0.5531876811385155\n",
      "Epoch7783 | train loss 0.553186916410923\n",
      "Epoch7784 | train loss 0.5531871812045575\n",
      "Epoch7785 | train loss 0.5531873509846628\n",
      "Epoch7786 | train loss 0.5531870391778648\n",
      "Epoch7787 | train loss 0.5531869529932737\n",
      "Epoch7788 | train loss 0.5531869608722627\n",
      "Epoch7789 | train loss 0.5531870694085955\n",
      "Epoch7790 | train loss 0.5531872271746398\n",
      "Epoch7791 | train loss 0.5531870798021555\n",
      "Epoch7792 | train loss 0.5531871296465397\n",
      "Epoch7793 | train loss 0.5531865171529353\n",
      "Epoch7794 | train loss 0.5531863036938012\n",
      "Epoch7795 | train loss 0.5531867929548026\n",
      "Epoch7796 | train loss 0.5531870471686124\n",
      "Epoch7797 | train loss 0.5531874026171864\n",
      "Epoch7798 | train loss 0.5531858365423977\n",
      "Epoch7799 | train loss 0.5531855316646397\n",
      "Epoch7800 | train loss 0.5531864470615983\n",
      "Epoch7801 | train loss 0.5531852531060576\n",
      "Epoch7802 | train loss 0.553187185190618\n",
      "Epoch7803 | train loss 0.5531864399649202\n",
      "Epoch7804 | train loss 0.5531854085624218\n",
      "Epoch7805 | train loss 0.5531862080283463\n",
      "Epoch7806 | train loss 0.5531852180324495\n",
      "Epoch7807 | train loss 0.5531862012110651\n",
      "Epoch7808 | train loss 0.5531846706010402\n",
      "Epoch7809 | train loss 0.5531858319044113\n",
      "Epoch7810 | train loss 0.5531851967982948\n",
      "Epoch7811 | train loss 0.5531852439977228\n",
      "Epoch7812 | train loss 0.5531855061650276\n",
      "Epoch7813 | train loss 0.5531846668757499\n",
      "Epoch7814 | train loss 0.5531853067688643\n",
      "Epoch7815 | train loss 0.5531844891794025\n",
      "Epoch7816 | train loss 0.5531851428933442\n",
      "Epoch7817 | train loss 0.5531836020015181\n",
      "Epoch7818 | train loss 0.5531836516968905\n",
      "Epoch7819 | train loss 0.5531845505721867\n",
      "Epoch7820 | train loss 0.5531837175041437\n",
      "Epoch7821 | train loss 0.5531841722503305\n",
      "Epoch7822 | train loss 0.5531845454499126\n",
      "Epoch7823 | train loss 0.553184566013515\n",
      "Epoch7824 | train loss 0.5531842004135251\n",
      "Epoch7825 | train loss 0.5531842795386911\n",
      "Epoch7826 | train loss 0.5531832982786\n",
      "Epoch7827 | train loss 0.5531836372427642\n",
      "Epoch7828 | train loss 0.5531840895302593\n",
      "Epoch7829 | train loss 0.5531844605319202\n",
      "Epoch7830 | train loss 0.5531825857236982\n",
      "Epoch7831 | train loss 0.5531840188056231\n",
      "Epoch7832 | train loss 0.5531841878592968\n",
      "Epoch7833 | train loss 0.5531829769350588\n",
      "Epoch7834 | train loss 0.5531839882396161\n",
      "Epoch7835 | train loss 0.5531831598840654\n",
      "Epoch7836 | train loss 0.55318462818861\n",
      "Epoch7837 | train loss 0.5531832829490304\n",
      "Epoch7838 | train loss 0.5531828724779189\n",
      "Epoch7839 | train loss 0.5531838837824762\n",
      "Epoch7840 | train loss 0.5531839795224368\n",
      "Epoch7841 | train loss 0.5531830941326916\n",
      "Epoch7842 | train loss 0.5531824517995119\n",
      "Epoch7843 | train loss 0.5531836855225265\n",
      "Epoch7844 | train loss 0.5531834134086967\n",
      "Epoch7845 | train loss 0.5531828191876411\n",
      "Epoch7846 | train loss 0.5531826259195805\n",
      "Epoch7847 | train loss 0.5531838911771775\n",
      "Epoch7848 | train loss 0.5531827350147068\n",
      "Epoch7849 | train loss 0.5531829649023712\n",
      "Epoch7850 | train loss 0.5531839638203383\n",
      "Epoch7851 | train loss 0.5531839366257191\n",
      "Epoch7852 | train loss 0.553182738237083\n",
      "Epoch7853 | train loss 0.5531841069459915\n",
      "Epoch7854 | train loss 0.5531835976801812\n",
      "Epoch7855 | train loss 0.5531821598112583\n",
      "Epoch7856 | train loss 0.5531836049631238\n",
      "Epoch7857 | train loss 0.5531824725866318\n",
      "Epoch7858 | train loss 0.5531837937235832\n",
      "Epoch7859 | train loss 0.5531832547485829\n",
      "Epoch7860 | train loss 0.553182586748153\n",
      "Epoch7861 | train loss 0.5531841104663908\n",
      "Epoch7862 | train loss 0.5531833176501095\n",
      "Epoch7863 | train loss 0.5531825939752162\n",
      "Epoch7864 | train loss 0.5531835440918803\n",
      "Epoch7865 | train loss 0.5531836348585785\n",
      "Epoch7866 | train loss 0.5531826141662896\n",
      "Epoch7867 | train loss 0.5531820517405868\n",
      "Epoch7868 | train loss 0.553183658272028\n",
      "Epoch7869 | train loss 0.5531838826462626\n",
      "Epoch7870 | train loss 0.5531826471537351\n",
      "Epoch7871 | train loss 0.5531832617893815\n",
      "Epoch7872 | train loss 0.5531824781745672\n",
      "Epoch7873 | train loss 0.5531832491606474\n",
      "Epoch7874 | train loss 0.5531829063780606\n",
      "Epoch7875 | train loss 0.5531838726997376\n",
      "Epoch7876 | train loss 0.5531835978105665\n",
      "Epoch7877 | train loss 0.5531816071085632\n",
      "Epoch7878 | train loss 0.553182744923979\n",
      "Epoch7879 | train loss 0.5531837194785476\n",
      "Epoch7880 | train loss 0.553182260133326\n",
      "Epoch7881 | train loss 0.5531834672018886\n",
      "Epoch7882 | train loss 0.553181420173496\n",
      "Epoch7883 | train loss 0.5531830605864525\n",
      "Epoch7884 | train loss 0.553182795792818\n",
      "Epoch7885 | train loss 0.5531835749186576\n",
      "Epoch7886 | train loss 0.5531821164116263\n",
      "Epoch7887 | train loss 0.5531823802553117\n",
      "Epoch7888 | train loss 0.5531813891232014\n",
      "Epoch7889 | train loss 0.5531822177954018\n",
      "Epoch7890 | train loss 0.5531821427494288\n",
      "Epoch7891 | train loss 0.5531824810616672\n",
      "Epoch7892 | train loss 0.5531818706914783\n",
      "Epoch7893 | train loss 0.5531820852681995\n",
      "Epoch7894 | train loss 0.5531816600076854\n",
      "Epoch7895 | train loss 0.5531815395131707\n",
      "Epoch7896 | train loss 0.5531828895770013\n",
      "Epoch7897 | train loss 0.5531814591027796\n",
      "Epoch7898 | train loss 0.5531828791834414\n",
      "Epoch7899 | train loss 0.5531806506961584\n",
      "Epoch7900 | train loss 0.5531825325265527\n",
      "Epoch7901 | train loss 0.5531832201220095\n",
      "Epoch7902 | train loss 0.5531814995594323\n",
      "Epoch7903 | train loss 0.5531809026189148\n",
      "Epoch7904 | train loss 0.5531821372359991\n",
      "Epoch7905 | train loss 0.5531817597150802\n",
      "Epoch7906 | train loss 0.553182192966342\n",
      "Epoch7907 | train loss 0.5531817550584673\n",
      "Epoch7908 | train loss 0.5531812411732971\n",
      "Epoch7909 | train loss 0.5531819369643927\n",
      "Epoch7910 | train loss 0.5531815915927291\n",
      "Epoch7911 | train loss 0.5531825128756463\n",
      "Epoch7912 | train loss 0.5531821457110345\n",
      "Epoch7913 | train loss 0.5531817345507443\n",
      "Epoch7914 | train loss 0.5531811881810427\n",
      "Epoch7915 | train loss 0.553182575404644\n",
      "Epoch7916 | train loss 0.5531815202534198\n",
      "Epoch7917 | train loss 0.553181774020195\n",
      "Epoch7918 | train loss 0.5531829942762851\n",
      "Epoch7919 | train loss 0.5531814306415618\n",
      "Epoch7920 | train loss 0.5531815729662776\n",
      "Epoch7921 | train loss 0.553181484900415\n",
      "Epoch7922 | train loss 0.5531824342161417\n",
      "Epoch7923 | train loss 0.5531818295642733\n",
      "Epoch7924 | train loss 0.5531818520464004\n",
      "Epoch7925 | train loss 0.5531824703328312\n",
      "Epoch7926 | train loss 0.553183069024235\n",
      "Epoch7927 | train loss 0.553181239310652\n",
      "Epoch7928 | train loss 0.5531818008422852\n",
      "Epoch7929 | train loss 0.553181703556329\n",
      "Epoch7930 | train loss 0.5531814948283136\n",
      "Epoch7931 | train loss 0.5531817656569182\n",
      "Epoch7932 | train loss 0.5531815746426583\n",
      "Epoch7933 | train loss 0.5531815814971924\n",
      "Epoch7934 | train loss 0.5531814687699079\n",
      "Epoch7935 | train loss 0.5531816668994725\n",
      "Epoch7936 | train loss 0.553181032706052\n",
      "Epoch7937 | train loss 0.5531823722459376\n",
      "Epoch7938 | train loss 0.5531829463504255\n",
      "Epoch7939 | train loss 0.553181452639401\n",
      "Epoch7940 | train loss 0.5531822498142719\n",
      "Epoch7941 | train loss 0.5531814891472459\n",
      "Epoch7942 | train loss 0.5531811308674515\n",
      "Epoch7943 | train loss 0.5531829844787717\n",
      "Epoch7944 | train loss 0.5531812489964067\n",
      "Epoch7945 | train loss 0.553181578386575\n",
      "Epoch7946 | train loss 0.5531817772053182\n",
      "Epoch7947 | train loss 0.553181578591466\n",
      "Epoch7948 | train loss 0.5531813544221222\n",
      "Epoch7949 | train loss 0.5531816854886711\n",
      "Epoch7950 | train loss 0.5531821505911648\n",
      "Epoch7951 | train loss 0.5531812163256109\n",
      "Epoch7952 | train loss 0.5531821730919182\n",
      "Epoch7953 | train loss 0.5531824264861643\n",
      "Epoch7954 | train loss 0.5531812008470297\n",
      "Epoch7955 | train loss 0.5531816079095006\n",
      "Epoch7956 | train loss 0.5531811040453612\n",
      "Epoch7957 | train loss 0.5531813482008875\n",
      "Epoch7958 | train loss 0.5531819685548544\n",
      "Epoch7959 | train loss 0.5531812451593577\n",
      "Epoch7960 | train loss 0.5531813439726829\n",
      "Epoch7961 | train loss 0.5531818399019539\n",
      "Epoch7962 | train loss 0.5531827536225319\n",
      "Epoch7963 | train loss 0.5531819809786975\n",
      "Epoch7964 | train loss 0.5531815488263965\n",
      "Epoch7965 | train loss 0.553180861454457\n",
      "Epoch7966 | train loss 0.5531815559044481\n",
      "Epoch7967 | train loss 0.5531811687536538\n",
      "Epoch7968 | train loss 0.5531815834902227\n",
      "Epoch7969 | train loss 0.553181134480983\n",
      "Epoch7970 | train loss 0.5531813973933458\n",
      "Epoch7971 | train loss 0.553181411344558\n",
      "Epoch7972 | train loss 0.5531822053529322\n",
      "Epoch7973 | train loss 0.5531811749748886\n",
      "Epoch7974 | train loss 0.5531819740869105\n",
      "Epoch7975 | train loss 0.5531813085451722\n",
      "Epoch7976 | train loss 0.5531807637587189\n",
      "Epoch7977 | train loss 0.5531826477497817\n",
      "Epoch7978 | train loss 0.5531817010976374\n",
      "Epoch7979 | train loss 0.5531822932884097\n",
      "Epoch7980 | train loss 0.5531809001415968\n",
      "Epoch7981 | train loss 0.5531816871836781\n",
      "Epoch7982 | train loss 0.5531807085312903\n",
      "Epoch7983 | train loss 0.553180781621486\n",
      "Epoch7984 | train loss 0.5531824717111885\n",
      "Epoch7985 | train loss 0.5531810190156102\n",
      "Epoch7986 | train loss 0.5531828137859702\n",
      "Epoch7987 | train loss 0.553180898744613\n",
      "Epoch7988 | train loss 0.5531810427829623\n",
      "Epoch7989 | train loss 0.5531814411096275\n",
      "Epoch7990 | train loss 0.5531823599152267\n",
      "Epoch7991 | train loss 0.5531819455698133\n",
      "Epoch7992 | train loss 0.5531809292547405\n",
      "Epoch7993 | train loss 0.553181648850441\n",
      "Epoch7994 | train loss 0.5531821036338807\n",
      "Epoch7995 | train loss 0.553180902209133\n",
      "Epoch7996 | train loss 0.5531813353672623\n",
      "Epoch7997 | train loss 0.5531823547370732\n",
      "Epoch7998 | train loss 0.5531807314790785\n",
      "Epoch7999 | train loss 0.5531814946234226\n",
      "Epoch8000 | train loss 0.5531824418716133\n",
      "Epoch8001 | train loss 0.5531804687529802\n",
      "Epoch8002 | train loss 0.5531811787374318\n",
      "Epoch8003 | train loss 0.5531806567311287\n",
      "Epoch8004 | train loss 0.5531824138946831\n",
      "Epoch8005 | train loss 0.5531813947297632\n",
      "Epoch8006 | train loss 0.553180675227195\n",
      "Epoch8007 | train loss 0.5531809336692095\n",
      "Epoch8008 | train loss 0.5531820097006858\n",
      "Epoch8009 | train loss 0.5531818498112261\n",
      "Epoch8010 | train loss 0.5531816229969263\n",
      "Epoch8011 | train loss 0.5531812882423401\n",
      "Epoch8012 | train loss 0.5531801358051598\n",
      "Epoch8013 | train loss 0.553180915620178\n",
      "Epoch8014 | train loss 0.5531817166134715\n",
      "Epoch8015 | train loss 0.553181751910597\n",
      "Epoch8016 | train loss 0.5531808985956013\n",
      "Epoch8017 | train loss 0.5531809785217047\n",
      "Epoch8018 | train loss 0.5531816181726754\n",
      "Epoch8019 | train loss 0.5531825439818203\n",
      "Epoch8020 | train loss 0.5531811435706914\n",
      "Epoch8021 | train loss 0.5531811715476215\n",
      "Epoch8022 | train loss 0.5531813900731504\n",
      "Epoch8023 | train loss 0.5531810126081109\n",
      "Epoch8024 | train loss 0.5531807085871696\n",
      "Epoch8025 | train loss 0.5531802738457918\n",
      "Epoch8026 | train loss 0.5531820562854409\n",
      "Epoch8027 | train loss 0.5531817279011011\n",
      "Epoch8028 | train loss 0.5531806382164359\n",
      "Epoch8029 | train loss 0.5531809254735708\n",
      "Epoch8030 | train loss 0.5531807005032897\n",
      "Epoch8031 | train loss 0.5531805918551982\n",
      "Epoch8032 | train loss 0.5531823973543942\n",
      "Epoch8033 | train loss 0.5531810449250042\n",
      "Epoch8034 | train loss 0.5531809975393116\n",
      "Epoch8035 | train loss 0.5531814677268266\n",
      "Epoch8036 | train loss 0.5531811009533704\n",
      "Epoch8037 | train loss 0.5531804347969591\n",
      "Epoch8038 | train loss 0.553182479608804\n",
      "Epoch8039 | train loss 0.5531806634366512\n",
      "Epoch8040 | train loss 0.5531807839497924\n",
      "Epoch8041 | train loss 0.5531815370358527\n",
      "Epoch8042 | train loss 0.5531819696165621\n",
      "Epoch8043 | train loss 0.5531799061968923\n",
      "Epoch8044 | train loss 0.5531804214417935\n",
      "Epoch8045 | train loss 0.5531815529242158\n",
      "Epoch8046 | train loss 0.5531824092939496\n",
      "Epoch8047 | train loss 0.5531807008571923\n",
      "Epoch8048 | train loss 0.5531807296350598\n",
      "Epoch8049 | train loss 0.5531807558052242\n",
      "Epoch8050 | train loss 0.5531820858642459\n",
      "Epoch8051 | train loss 0.5531808371655643\n",
      "Epoch8052 | train loss 0.5531806498020887\n",
      "Epoch8053 | train loss 0.5531811930052936\n",
      "Epoch8054 | train loss 0.5531811610236764\n",
      "Epoch8055 | train loss 0.5531803819723428\n",
      "Epoch8056 | train loss 0.5531812944822013\n",
      "Epoch8057 | train loss 0.5531813265755773\n",
      "Epoch8058 | train loss 0.5531806350499392\n",
      "Epoch8059 | train loss 0.5531813078559935\n",
      "Epoch8060 | train loss 0.5531805180571974\n",
      "Epoch8061 | train loss 0.5531808971986174\n",
      "Epoch8062 | train loss 0.5531804593838752\n",
      "Epoch8063 | train loss 0.5531802901253104\n",
      "Epoch8064 | train loss 0.5531798001937568\n",
      "Epoch8065 | train loss 0.5531819624267519\n",
      "Epoch8066 | train loss 0.5531806957349181\n",
      "Epoch8067 | train loss 0.5531814634054899\n",
      "Epoch8068 | train loss 0.5531796986237169\n",
      "Epoch8069 | train loss 0.5531822085008025\n",
      "Epoch8070 | train loss 0.5531795460730791\n",
      "Epoch8071 | train loss 0.5531820479035378\n",
      "Epoch8072 | train loss 0.5531791807897389\n",
      "Epoch8073 | train loss 0.5531799617968499\n",
      "Epoch8074 | train loss 0.5531808065064251\n",
      "Epoch8075 | train loss 0.5531797139532864\n",
      "Epoch8076 | train loss 0.5531800132989884\n",
      "Epoch8077 | train loss 0.553180639911443\n",
      "Epoch8078 | train loss 0.5531805198453367\n",
      "Epoch8079 | train loss 0.5531792510300875\n",
      "Epoch8080 | train loss 0.5531811047531664\n",
      "Epoch8081 | train loss 0.5531792540848255\n",
      "Epoch8082 | train loss 0.5531814227811992\n",
      "Epoch8083 | train loss 0.5531802368164063\n",
      "Epoch8084 | train loss 0.5531804262846708\n",
      "Epoch8085 | train loss 0.5531799920275807\n",
      "Epoch8086 | train loss 0.5531806897558272\n",
      "Epoch8087 | train loss 0.5531799477338791\n",
      "Epoch8088 | train loss 0.5531802449189126\n",
      "Epoch8089 | train loss 0.553179322835058\n",
      "Epoch8090 | train loss 0.5531813061796129\n",
      "Epoch8091 | train loss 0.5531801706366241\n",
      "Epoch8092 | train loss 0.5531800012104213\n",
      "Epoch8093 | train loss 0.553179939351976\n",
      "Epoch8094 | train loss 0.5531807839497924\n",
      "Epoch8095 | train loss 0.5531799396686256\n",
      "Epoch8096 | train loss 0.553179693967104\n",
      "Epoch8097 | train loss 0.5531802482157946\n",
      "Epoch8098 | train loss 0.5531809431314468\n",
      "Epoch8099 | train loss 0.553179946616292\n",
      "Epoch8100 | train loss 0.5531798075698316\n",
      "Epoch8101 | train loss 0.5531798968650401\n",
      "Epoch8102 | train loss 0.553180837277323\n",
      "Epoch8103 | train loss 0.5531800815463066\n",
      "Epoch8104 | train loss 0.5531799196451902\n",
      "Epoch8105 | train loss 0.5531804860197007\n",
      "Epoch8106 | train loss 0.5531802172213793\n",
      "Epoch8107 | train loss 0.5531804888509214\n",
      "Epoch8108 | train loss 0.5531803790107369\n",
      "Epoch8109 | train loss 0.5531800311245024\n",
      "Epoch8110 | train loss 0.5531793253868819\n",
      "Epoch8111 | train loss 0.5531808811798692\n",
      "Epoch8112 | train loss 0.5531803257018327\n",
      "Epoch8113 | train loss 0.5531805676221847\n",
      "Epoch8114 | train loss 0.5531788584962487\n",
      "Epoch8115 | train loss 0.5531807449832559\n",
      "Epoch8116 | train loss 0.553180875107646\n",
      "Epoch8117 | train loss 0.5531809637509286\n",
      "Epoch8118 | train loss 0.5531806666404009\n",
      "Epoch8119 | train loss 0.5531785487756133\n",
      "Epoch8120 | train loss 0.5531810036860406\n",
      "Epoch8121 | train loss 0.5531798172555864\n",
      "Epoch8122 | train loss 0.5531797008775174\n",
      "Epoch8123 | train loss 0.5531804848834873\n",
      "Epoch8124 | train loss 0.5531801049597561\n",
      "Epoch8125 | train loss 0.5531802717596292\n",
      "Epoch8126 | train loss 0.5531808882951736\n",
      "Epoch8127 | train loss 0.5531802117452025\n",
      "Epoch8128 | train loss 0.5531808850727975\n",
      "Epoch8129 | train loss 0.5531781228631735\n",
      "Epoch8130 | train loss 0.5531806276552379\n",
      "Epoch8131 | train loss 0.5531805997900665\n",
      "Epoch8132 | train loss 0.5531790444813669\n",
      "Epoch8133 | train loss 0.5531795542128384\n",
      "Epoch8134 | train loss 0.5531812857836484\n",
      "Epoch8135 | train loss 0.5531799679994583\n",
      "Epoch8136 | train loss 0.5531809458136558\n",
      "Epoch8137 | train loss 0.5531787321530283\n",
      "Epoch8138 | train loss 0.5531796654872596\n",
      "Epoch8139 | train loss 0.5531809260137379\n",
      "Epoch8140 | train loss 0.5531801556237042\n",
      "Epoch8141 | train loss 0.55317951310426\n",
      "Epoch8142 | train loss 0.5531795561872422\n",
      "Epoch8143 | train loss 0.55318050513044\n",
      "Epoch8144 | train loss 0.5531806473433971\n",
      "Epoch8145 | train loss 0.5531795920804143\n",
      "Epoch8146 | train loss 0.5531807803548873\n",
      "Epoch8147 | train loss 0.5531804712489248\n",
      "Epoch8148 | train loss 0.5531779946945607\n",
      "Epoch8149 | train loss 0.5531804917752743\n",
      "Epoch8150 | train loss 0.5531807268224657\n",
      "Epoch8151 | train loss 0.5531799738667905\n",
      "Epoch8152 | train loss 0.5531799077242613\n",
      "Epoch8153 | train loss 0.5531789498403669\n",
      "Epoch8154 | train loss 0.5531800222396851\n",
      "Epoch8155 | train loss 0.5531801581569016\n",
      "Epoch8156 | train loss 0.5531807637959719\n",
      "Epoch8157 | train loss 0.5531796285696328\n",
      "Epoch8158 | train loss 0.5531802830472589\n",
      "Epoch8159 | train loss 0.5531793158501387\n",
      "Epoch8160 | train loss 0.5531798375025392\n",
      "Epoch8161 | train loss 0.5531810861080885\n",
      "Epoch8162 | train loss 0.5531791614927352\n",
      "Epoch8163 | train loss 0.5531806338205933\n",
      "Epoch8164 | train loss 0.5531803763657809\n",
      "Epoch8165 | train loss 0.5531789276935161\n",
      "Epoch8166 | train loss 0.5531799911893904\n",
      "Epoch8167 | train loss 0.5531804946437479\n",
      "Epoch8168 | train loss 0.5531792361661791\n",
      "Epoch8169 | train loss 0.5531807992979885\n",
      "Epoch8170 | train loss 0.5531789941899479\n",
      "Epoch8171 | train loss 0.5531788217835129\n",
      "Epoch8172 | train loss 0.5531810486502945\n",
      "Epoch8173 | train loss 0.5531799926050007\n",
      "Epoch8174 | train loss 0.5531801162660122\n",
      "Epoch8175 | train loss 0.5531782941333949\n",
      "Epoch8176 | train loss 0.5531795085594058\n",
      "Epoch8177 | train loss 0.5531807770207524\n",
      "Epoch8178 | train loss 0.5531802675500512\n",
      "Epoch8179 | train loss 0.5531792147457599\n",
      "Epoch8180 | train loss 0.5531795408576727\n",
      "Epoch8181 | train loss 0.5531805100105703\n",
      "Epoch8182 | train loss 0.5531806082464754\n",
      "Epoch8183 | train loss 0.553180162012577\n",
      "Epoch8184 | train loss 0.5531793323531747\n",
      "Epoch8185 | train loss 0.5531789254397154\n",
      "Epoch8186 | train loss 0.553180117662996\n",
      "Epoch8187 | train loss 0.5531803907267749\n",
      "Epoch8188 | train loss 0.5531796320527792\n",
      "Epoch8189 | train loss 0.5531798673421144\n",
      "Epoch8190 | train loss 0.5531805149465799\n",
      "Epoch8191 | train loss 0.5531801020540297\n",
      "Epoch8192 | train loss 0.5531789256259799\n",
      "Epoch8193 | train loss 0.553180483840406\n",
      "Epoch8194 | train loss 0.5531790984421968\n",
      "Epoch8195 | train loss 0.5531799265928566\n",
      "Epoch8196 | train loss 0.5531788949668407\n",
      "Epoch8197 | train loss 0.5531801564618946\n",
      "Epoch8198 | train loss 0.5531804637238383\n",
      "Epoch8199 | train loss 0.5531796336174011\n",
      "Epoch8200 | train loss 0.5531797314807773\n",
      "Epoch8201 | train loss 0.5531787954270839\n",
      "Epoch8202 | train loss 0.5531792815774679\n",
      "Epoch8203 | train loss 0.5531795356608927\n",
      "Epoch8204 | train loss 0.5531793469376862\n",
      "Epoch8205 | train loss 0.5531799743510782\n",
      "Epoch8206 | train loss 0.5531802739389241\n",
      "Epoch8207 | train loss 0.5531803320907056\n",
      "Epoch8208 | train loss 0.5531786353699863\n",
      "Epoch8209 | train loss 0.5531791059672833\n",
      "Epoch8210 | train loss 0.553179189953953\n",
      "Epoch8211 | train loss 0.5531794192269445\n",
      "Epoch8212 | train loss 0.5531804697960615\n",
      "Epoch8213 | train loss 0.5531801835633814\n",
      "Epoch8214 | train loss 0.5531792560592294\n",
      "Epoch8215 | train loss 0.5531788237951696\n",
      "Epoch8216 | train loss 0.5531790746189654\n",
      "Epoch8217 | train loss 0.5531801167502999\n",
      "Epoch8218 | train loss 0.5531795654073357\n",
      "Epoch8219 | train loss 0.5531792175956071\n",
      "Epoch8220 | train loss 0.5531790996715427\n",
      "Epoch8221 | train loss 0.5531792178563774\n",
      "Epoch8222 | train loss 0.5531807550415396\n",
      "Epoch8223 | train loss 0.5531789056956768\n",
      "Epoch8224 | train loss 0.5531786203570664\n",
      "Epoch8225 | train loss 0.5531799531914294\n",
      "Epoch8226 | train loss 0.5531793406978249\n",
      "Epoch8227 | train loss 0.5531806452199817\n",
      "Epoch8228 | train loss 0.5531786106526851\n",
      "Epoch8229 | train loss 0.5531784528121352\n",
      "Epoch8230 | train loss 0.553179742693901\n",
      "Epoch8231 | train loss 0.5531800921447575\n",
      "Epoch8232 | train loss 0.553177861366421\n",
      "Epoch8233 | train loss 0.5531799931265414\n",
      "Epoch8234 | train loss 0.553179094158113\n",
      "Epoch8235 | train loss 0.553179709110409\n",
      "Epoch8236 | train loss 0.5531797780282796\n",
      "Epoch8237 | train loss 0.5531779936514795\n",
      "Epoch8238 | train loss 0.5531802970729768\n",
      "Epoch8239 | train loss 0.5531793441809714\n",
      "Epoch8240 | train loss 0.5531790087558329\n",
      "Epoch8241 | train loss 0.5531783165410161\n",
      "Epoch8242 | train loss 0.5531799275428056\n",
      "Epoch8243 | train loss 0.5531794942170382\n",
      "Epoch8244 | train loss 0.5531798242405057\n",
      "Epoch8245 | train loss 0.5531784122809768\n",
      "Epoch8246 | train loss 0.5531800223328173\n",
      "Epoch8247 | train loss 0.5531797831691802\n",
      "Epoch8248 | train loss 0.5531791775673628\n",
      "Epoch8249 | train loss 0.5531785154342651\n",
      "Epoch8250 | train loss 0.5531794627010822\n",
      "Epoch8251 | train loss 0.553179745413363\n",
      "Epoch8252 | train loss 0.5531786061823368\n",
      "Epoch8253 | train loss 0.5531788691319526\n",
      "Epoch8254 | train loss 0.5531799332983792\n",
      "Epoch8255 | train loss 0.5531792271137238\n",
      "Epoch8256 | train loss 0.5531782867014408\n",
      "Epoch8257 | train loss 0.5531793097406625\n",
      "Epoch8258 | train loss 0.5531797483377159\n",
      "Epoch8259 | train loss 0.5531780737452209\n",
      "Epoch8260 | train loss 0.5531792996078729\n",
      "Epoch8261 | train loss 0.5531808522716165\n",
      "Epoch8262 | train loss 0.553177261594683\n",
      "Epoch8263 | train loss 0.5531794452853501\n",
      "Epoch8264 | train loss 0.5531796291097999\n",
      "Epoch8265 | train loss 0.5531786383315921\n",
      "Epoch8266 | train loss 0.5531781652383506\n",
      "Epoch8267 | train loss 0.5531793718226254\n",
      "Epoch8268 | train loss 0.5531787761300803\n",
      "Epoch8269 | train loss 0.553178490921855\n",
      "Epoch8270 | train loss 0.5531792556867003\n",
      "Epoch8271 | train loss 0.5531794692017138\n",
      "Epoch8272 | train loss 0.5531785975769162\n",
      "Epoch8273 | train loss 0.5531783362291753\n",
      "Epoch8274 | train loss 0.5531792282313108\n",
      "Epoch8275 | train loss 0.553179408442229\n",
      "Epoch8276 | train loss 0.5531775476038456\n",
      "Epoch8277 | train loss 0.5531795831955969\n",
      "Epoch8278 | train loss 0.5531791825219989\n",
      "Epoch8279 | train loss 0.5531783794984222\n",
      "Epoch8280 | train loss 0.5531790883280336\n",
      "Epoch8281 | train loss 0.5531792626529932\n",
      "Epoch8282 | train loss 0.553177303429693\n",
      "Epoch8283 | train loss 0.5531792070716619\n",
      "Epoch8284 | train loss 0.5531793759204447\n",
      "Epoch8285 | train loss 0.5531786920875311\n",
      "Epoch8286 | train loss 0.5531790888682008\n",
      "Epoch8287 | train loss 0.5531792935542762\n",
      "Epoch8288 | train loss 0.553178534861654\n",
      "Epoch8289 | train loss 0.5531782571785152\n",
      "Epoch8290 | train loss 0.5531792130321265\n",
      "Epoch8291 | train loss 0.5531793776154518\n",
      "Epoch8292 | train loss 0.5531779027916491\n",
      "Epoch8293 | train loss 0.553178736679256\n",
      "Epoch8294 | train loss 0.553179869838059\n",
      "Epoch8295 | train loss 0.553178161457181\n",
      "Epoch8296 | train loss 0.5531791245006025\n",
      "Epoch8297 | train loss 0.5531792303733528\n",
      "Epoch8298 | train loss 0.5531781030446291\n",
      "Epoch8299 | train loss 0.5531783992797137\n",
      "Epoch8300 | train loss 0.5531784982606769\n",
      "Epoch8301 | train loss 0.5531788013502955\n",
      "Epoch8302 | train loss 0.5531781736016274\n",
      "Epoch8303 | train loss 0.5531789643503725\n",
      "Epoch8304 | train loss 0.5531795324757696\n",
      "Epoch8305 | train loss 0.553177107423544\n",
      "Epoch8306 | train loss 0.5531788796745241\n",
      "Epoch8307 | train loss 0.5531797483749687\n",
      "Epoch8308 | train loss 0.5531782821565866\n",
      "Epoch8309 | train loss 0.553178970720619\n",
      "Epoch8310 | train loss 0.5531791738420725\n",
      "Epoch8311 | train loss 0.5531780549511314\n",
      "Epoch8312 | train loss 0.5531771640107036\n",
      "Epoch8313 | train loss 0.5531788975186646\n",
      "Epoch8314 | train loss 0.5531796971522271\n",
      "Epoch8315 | train loss 0.5531790298223496\n",
      "Epoch8316 | train loss 0.5531771255284548\n",
      "Epoch8317 | train loss 0.5531792539916932\n",
      "Epoch8318 | train loss 0.5531782027333975\n",
      "Epoch8319 | train loss 0.553178978599608\n",
      "Epoch8320 | train loss 0.5531770806014538\n",
      "Epoch8321 | train loss 0.5531788387335836\n",
      "Epoch8322 | train loss 0.5531796129792929\n",
      "Epoch8323 | train loss 0.5531779951415956\n",
      "Epoch8324 | train loss 0.5531790628097951\n",
      "Epoch8325 | train loss 0.5531788243539631\n",
      "Epoch8326 | train loss 0.553178522400558\n",
      "Epoch8327 | train loss 0.5531787506863475\n",
      "Epoch8328 | train loss 0.5531781868822873\n",
      "Epoch8329 | train loss 0.5531791129149497\n",
      "Epoch8330 | train loss 0.5531779063120484\n",
      "Epoch8331 | train loss 0.5531791634857655\n",
      "Epoch8332 | train loss 0.5531781291589141\n",
      "Epoch8333 | train loss 0.5531779711134732\n",
      "Epoch8334 | train loss 0.5531792360171676\n",
      "Epoch8335 | train loss 0.5531785664334893\n",
      "Epoch8336 | train loss 0.5531792234070599\n",
      "Epoch8337 | train loss 0.5531769237294794\n",
      "Epoch8338 | train loss 0.5531794072315097\n",
      "Epoch8339 | train loss 0.5531783021241427\n",
      "Epoch8340 | train loss 0.5531789295934141\n",
      "Epoch8341 | train loss 0.5531778700277209\n",
      "Epoch8342 | train loss 0.553178559653461\n",
      "Epoch8343 | train loss 0.5531791902147234\n",
      "Epoch8344 | train loss 0.5531782420165837\n",
      "Epoch8345 | train loss 0.5531767906248569\n",
      "Epoch8346 | train loss 0.553179025053978\n",
      "Epoch8347 | train loss 0.5531790666468441\n",
      "Epoch8348 | train loss 0.5531783596426249\n",
      "Epoch8349 | train loss 0.5531781062483787\n",
      "Epoch8350 | train loss 0.5531789679452777\n",
      "Epoch8351 | train loss 0.5531777277775108\n",
      "Epoch8352 | train loss 0.5531789483316243\n",
      "Epoch8353 | train loss 0.5531779208779335\n",
      "Epoch8354 | train loss 0.5531790786236525\n",
      "Epoch8355 | train loss 0.5531789269298315\n",
      "Epoch8356 | train loss 0.5531770635955036\n",
      "Epoch8357 | train loss 0.5531789433211088\n",
      "Epoch8358 | train loss 0.5531785275787116\n",
      "Epoch8359 | train loss 0.5531782963126898\n",
      "Epoch8360 | train loss 0.5531786176748574\n",
      "Epoch8361 | train loss 0.553177729845047\n",
      "Epoch8362 | train loss 0.5531788145564497\n",
      "Epoch8363 | train loss 0.5531789720989764\n",
      "Epoch8364 | train loss 0.5531781217083335\n",
      "Epoch8365 | train loss 0.5531777505762875\n",
      "Epoch8366 | train loss 0.5531789832934737\n",
      "Epoch8367 | train loss 0.5531783235818147\n",
      "Epoch8368 | train loss 0.5531794202886522\n",
      "Epoch8369 | train loss 0.5531778419204056\n",
      "Epoch8370 | train loss 0.5531777587532997\n",
      "Epoch8371 | train loss 0.5531788326613605\n",
      "Epoch8372 | train loss 0.5531783246435225\n",
      "Epoch8373 | train loss 0.553179457373917\n",
      "Epoch8374 | train loss 0.5531764529086649\n",
      "Epoch8375 | train loss 0.5531790955364704\n",
      "Epoch8376 | train loss 0.5531782181933522\n",
      "Epoch8377 | train loss 0.553179333731532\n",
      "Epoch8378 | train loss 0.5531777747347951\n",
      "Epoch8379 | train loss 0.5531777033954859\n",
      "Epoch8380 | train loss 0.553178775049746\n",
      "Epoch8381 | train loss 0.5531784878857434\n",
      "Epoch8382 | train loss 0.5531791822239757\n",
      "Epoch8383 | train loss 0.5531766012497247\n",
      "Epoch8384 | train loss 0.5531792197562754\n",
      "Epoch8385 | train loss 0.553177577406168\n",
      "Epoch8386 | train loss 0.5531774592958391\n",
      "Epoch8387 | train loss 0.5531791169941426\n",
      "Epoch8388 | train loss 0.5531780179217458\n",
      "Epoch8389 | train loss 0.5531779593043029\n",
      "Epoch8390 | train loss 0.5531787161901593\n",
      "Epoch8391 | train loss 0.5531775095686317\n",
      "Epoch8392 | train loss 0.5531791592016816\n",
      "Epoch8393 | train loss 0.5531776281259954\n",
      "Epoch8394 | train loss 0.5531775636784733\n",
      "Epoch8395 | train loss 0.5531785080023109\n",
      "Epoch8396 | train loss 0.5531791588291526\n",
      "Epoch8397 | train loss 0.5531780461035669\n",
      "Epoch8398 | train loss 0.5531778645142913\n",
      "Epoch8399 | train loss 0.5531787317059934\n",
      "Epoch8400 | train loss 0.5531777583435178\n",
      "Epoch8401 | train loss 0.5531786162965\n",
      "Epoch8402 | train loss 0.5531789647415281\n",
      "Epoch8403 | train loss 0.5531765142269433\n",
      "Epoch8404 | train loss 0.553178892582655\n",
      "Epoch8405 | train loss 0.5531780434399843\n",
      "Epoch8406 | train loss 0.5531779273599386\n",
      "Epoch8407 | train loss 0.5531767413392663\n",
      "Epoch8408 | train loss 0.5531786476820707\n",
      "Epoch8409 | train loss 0.5531785459443926\n",
      "Epoch8410 | train loss 0.5531780965439975\n",
      "Epoch8411 | train loss 0.5531778989359737\n",
      "Epoch8412 | train loss 0.553178667128086\n",
      "Epoch8413 | train loss 0.553177876342088\n",
      "Epoch8414 | train loss 0.5531772939115762\n",
      "Epoch8415 | train loss 0.5531781343929469\n",
      "Epoch8416 | train loss 0.5531779270060361\n",
      "Epoch8417 | train loss 0.5531779454834759\n",
      "Epoch8418 | train loss 0.553178610317409\n",
      "Epoch8419 | train loss 0.5531785109452904\n",
      "Epoch8420 | train loss 0.5531779720820487\n",
      "Epoch8421 | train loss 0.5531791218928993\n",
      "Epoch8422 | train loss 0.553177553229034\n",
      "Epoch8423 | train loss 0.5531774891354143\n",
      "Epoch8424 | train loss 0.553178768530488\n",
      "Epoch8425 | train loss 0.55317777171731\n",
      "Epoch8426 | train loss 0.5531779122911393\n",
      "Epoch8427 | train loss 0.5531792257167399\n",
      "Epoch8428 | train loss 0.5531761288456619\n",
      "Epoch8429 | train loss 0.5531787744909525\n",
      "Epoch8430 | train loss 0.5531784879788756\n",
      "Epoch8431 | train loss 0.5531774283200502\n",
      "Epoch8432 | train loss 0.553178483415395\n",
      "Epoch8433 | train loss 0.5531784121133387\n",
      "Epoch8434 | train loss 0.5531781437806785\n",
      "Epoch8435 | train loss 0.5531779880821704\n",
      "Epoch8436 | train loss 0.5531788638606667\n",
      "Epoch8437 | train loss 0.5531775262579322\n",
      "Epoch8438 | train loss 0.5531784143485129\n",
      "Epoch8439 | train loss 0.5531785672344267\n",
      "Epoch8440 | train loss 0.5531762705557048\n",
      "Epoch8441 | train loss 0.5531786893308163\n",
      "Epoch8442 | train loss 0.5531778590381146\n",
      "Epoch8443 | train loss 0.5531777601316571\n",
      "Epoch8444 | train loss 0.5531778225302696\n",
      "Epoch8445 | train loss 0.5531770315393806\n",
      "Epoch8446 | train loss 0.5531784019805491\n",
      "Epoch8447 | train loss 0.553178127836436\n",
      "Epoch8448 | train loss 0.5531776718422771\n",
      "Epoch8449 | train loss 0.5531789380684495\n",
      "Epoch8450 | train loss 0.5531774627044796\n",
      "Epoch8451 | train loss 0.5531787377409637\n",
      "Epoch8452 | train loss 0.5531782369874417\n",
      "Epoch8453 | train loss 0.553177610039711\n",
      "Epoch8454 | train loss 0.5531770749948919\n",
      "Epoch8455 | train loss 0.5531784952618182\n",
      "Epoch8456 | train loss 0.5531788334064186\n",
      "Epoch8457 | train loss 0.5531786762550474\n",
      "Epoch8458 | train loss 0.5531777186691761\n",
      "Epoch8459 | train loss 0.5531775810569525\n",
      "Epoch8460 | train loss 0.5531784588657319\n",
      "Epoch8461 | train loss 0.5531784998625517\n",
      "Epoch8462 | train loss 0.5531775799579919\n",
      "Epoch8463 | train loss 0.5531765255145729\n",
      "Epoch8464 | train loss 0.5531784220971168\n",
      "Epoch8465 | train loss 0.5531783314980566\n",
      "Epoch8466 | train loss 0.5531784275732935\n",
      "Epoch8467 | train loss 0.5531776846759021\n",
      "Epoch8468 | train loss 0.5531790228746831\n",
      "Epoch8469 | train loss 0.5531773095950484\n",
      "Epoch8470 | train loss 0.5531776602566242\n",
      "Epoch8471 | train loss 0.5531782533414662\n",
      "Epoch8472 | train loss 0.5531782147847116\n",
      "Epoch8473 | train loss 0.553178371861577\n",
      "Epoch8474 | train loss 0.5531762156076729\n",
      "Epoch8475 | train loss 0.5531789297051728\n",
      "Epoch8476 | train loss 0.5531781429983675\n",
      "Epoch8477 | train loss 0.5531776002235711\n",
      "Epoch8478 | train loss 0.5531781820394098\n",
      "Epoch8479 | train loss 0.5531771954149007\n",
      "Epoch8480 | train loss 0.5531783562712371\n",
      "Epoch8481 | train loss 0.5531788420118392\n",
      "Epoch8482 | train loss 0.5531781654246152\n",
      "Epoch8483 | train loss 0.5531776203401386\n",
      "Epoch8484 | train loss 0.5531770540028811\n",
      "Epoch8485 | train loss 0.553177724890411\n",
      "Epoch8486 | train loss 0.5531787744909525\n",
      "Epoch8487 | train loss 0.5531773291155696\n",
      "Epoch8488 | train loss 0.553178236335516\n",
      "Epoch8489 | train loss 0.5531773854978382\n",
      "Epoch8490 | train loss 0.5531787255220115\n",
      "Epoch8491 | train loss 0.5531782566383481\n",
      "Epoch8492 | train loss 0.5531785994395614\n",
      "Epoch8493 | train loss 0.5531774749048054\n",
      "Epoch8494 | train loss 0.5531776702776551\n",
      "Epoch8495 | train loss 0.5531788979284465\n",
      "Epoch8496 | train loss 0.553176381662488\n",
      "Epoch8497 | train loss 0.5531783373653889\n",
      "Epoch8498 | train loss 0.553178276475519\n",
      "Epoch8499 | train loss 0.5531783888861537\n",
      "Epoch8500 | train loss 0.5531774689257145\n",
      "Epoch8501 | train loss 0.5531772918254138\n",
      "Epoch8502 | train loss 0.5531786705553532\n",
      "Epoch8503 | train loss 0.5531781666539609\n",
      "Epoch8504 | train loss 0.5531774976290762\n",
      "Epoch8505 | train loss 0.5531772539950908\n",
      "Epoch8506 | train loss 0.553178271856159\n",
      "Epoch8507 | train loss 0.5531787514872849\n",
      "Epoch8508 | train loss 0.5531782148964703\n",
      "Epoch8509 | train loss 0.5531783356890082\n",
      "Epoch8510 | train loss 0.5531774415634573\n",
      "Epoch8511 | train loss 0.5531764197163284\n",
      "Epoch8512 | train loss 0.5531787046976387\n",
      "Epoch8513 | train loss 0.5531785014085472\n",
      "Epoch8514 | train loss 0.5531787954270839\n",
      "Epoch8515 | train loss 0.5531774200685322\n",
      "Epoch8516 | train loss 0.5531772270053625\n",
      "Epoch8517 | train loss 0.5531782489456236\n",
      "Epoch8518 | train loss 0.553178574591875\n",
      "Epoch8519 | train loss 0.553177438620478\n",
      "Epoch8520 | train loss 0.5531782558746636\n",
      "Epoch8521 | train loss 0.553177693001926\n",
      "Epoch8522 | train loss 0.5531770495511591\n",
      "Epoch8523 | train loss 0.5531783623993397\n",
      "Epoch8524 | train loss 0.553177609629929\n",
      "Epoch8525 | train loss 0.5531777958013118\n",
      "Epoch8526 | train loss 0.5531780332140624\n",
      "Epoch8527 | train loss 0.5531772360950709\n",
      "Epoch8528 | train loss 0.5531778056919575\n",
      "Epoch8529 | train loss 0.5531780683994293\n",
      "Epoch8530 | train loss 0.5531783942133188\n",
      "Epoch8531 | train loss 0.5531787188723684\n",
      "Epoch8532 | train loss 0.5531773562543094\n",
      "Epoch8533 | train loss 0.5531771564111113\n",
      "Epoch8534 | train loss 0.5531785537302494\n",
      "Epoch8535 | train loss 0.5531780610978604\n",
      "Epoch8536 | train loss 0.5531773893721401\n",
      "Epoch8537 | train loss 0.5531785112060607\n",
      "Epoch8538 | train loss 0.5531779391132295\n",
      "Epoch8539 | train loss 0.5531771410629154\n",
      "Epoch8540 | train loss 0.5531777560152114\n",
      "Epoch8541 | train loss 0.5531780445761979\n",
      "Epoch8542 | train loss 0.5531781738623976\n",
      "Epoch8543 | train loss 0.5531774577312172\n",
      "Epoch8544 | train loss 0.5531777039542795\n",
      "Epoch8545 | train loss 0.5531771329790354\n",
      "Epoch8546 | train loss 0.5531785428710282\n",
      "Epoch8547 | train loss 0.5531771148368716\n",
      "Epoch8548 | train loss 0.5531784357130527\n",
      "Epoch8549 | train loss 0.5531781061924994\n",
      "Epoch8550 | train loss 0.5531774209812284\n",
      "Epoch8551 | train loss 0.5531776540540159\n",
      "Epoch8552 | train loss 0.5531767234578728\n",
      "Epoch8553 | train loss 0.5531785775721073\n",
      "Epoch8554 | train loss 0.5531779536791146\n",
      "Epoch8555 | train loss 0.5531780936382711\n",
      "Epoch8556 | train loss 0.5531773971579969\n",
      "Epoch8557 | train loss 0.5531780299916863\n",
      "Epoch8558 | train loss 0.5531773540750146\n",
      "Epoch8559 | train loss 0.5531786111183464\n",
      "Epoch8560 | train loss 0.553176995422691\n",
      "Epoch8561 | train loss 0.5531784626282752\n",
      "Epoch8562 | train loss 0.5531779668293894\n",
      "Epoch8563 | train loss 0.553178116697818\n",
      "Epoch8564 | train loss 0.5531775427237153\n",
      "Epoch8565 | train loss 0.553178280852735\n",
      "Epoch8566 | train loss 0.5531772000528872\n",
      "Epoch8567 | train loss 0.5531770103424788\n",
      "Epoch8568 | train loss 0.5531780362874269\n",
      "Epoch8569 | train loss 0.5531781601719559\n",
      "Epoch8570 | train loss 0.553177245017141\n",
      "Epoch8571 | train loss 0.5531784049980343\n",
      "Epoch8572 | train loss 0.5531782010197639\n",
      "Epoch8573 | train loss 0.5531771327927708\n",
      "Epoch8574 | train loss 0.5531769962795079\n",
      "Epoch8575 | train loss 0.5531783927232027\n",
      "Epoch8576 | train loss 0.5531780308671296\n",
      "Epoch8577 | train loss 0.5531775001436472\n",
      "Epoch8578 | train loss 0.5531778569146991\n",
      "Epoch8579 | train loss 0.5531781827285885\n",
      "Epoch8580 | train loss 0.5531779135204852\n",
      "Epoch8581 | train loss 0.5531771080382168\n",
      "Epoch8582 | train loss 0.5531769512407482\n",
      "Epoch8583 | train loss 0.5531783926673234\n",
      "Epoch8584 | train loss 0.5531781162507832\n",
      "Epoch8585 | train loss 0.5531772068887949\n",
      "Epoch8586 | train loss 0.5531783805415035\n",
      "Epoch8587 | train loss 0.5531781697273255\n",
      "Epoch8588 | train loss 0.5531772653013468\n",
      "Epoch8589 | train loss 0.5531775571219623\n",
      "Epoch8590 | train loss 0.5531770532764494\n",
      "Epoch8591 | train loss 0.5531781551986933\n",
      "Epoch8592 | train loss 0.5531775509566068\n",
      "Epoch8593 | train loss 0.5531782494112849\n",
      "Epoch8594 | train loss 0.5531778165698051\n",
      "Epoch8595 | train loss 0.5531780090555549\n",
      "Epoch8596 | train loss 0.5531774679943919\n",
      "Epoch8597 | train loss 0.5531782058440149\n",
      "Epoch8598 | train loss 0.5531769574061036\n",
      "Epoch8599 | train loss 0.5531783948093653\n",
      "Epoch8600 | train loss 0.5531778075918555\n",
      "Epoch8601 | train loss 0.5531780037283898\n",
      "Epoch8602 | train loss 0.5531771434471011\n",
      "Epoch8603 | train loss 0.55317732302472\n",
      "Epoch8604 | train loss 0.5531778938509524\n",
      "Epoch8605 | train loss 0.553178021274507\n",
      "Epoch8606 | train loss 0.5531774565018713\n",
      "Epoch8607 | train loss 0.5531782127916813\n",
      "Epoch8608 | train loss 0.5531781434640288\n",
      "Epoch8609 | train loss 0.5531778909265995\n",
      "Epoch8610 | train loss 0.5531773633882403\n",
      "Epoch8611 | train loss 0.5531781442277134\n",
      "Epoch8612 | train loss 0.5531764957308769\n",
      "Epoch8613 | train loss 0.5531783931702375\n",
      "Epoch8614 | train loss 0.5531781683862209\n",
      "Epoch8615 | train loss 0.5531777270510793\n",
      "Epoch8616 | train loss 0.5531778974831104\n",
      "Epoch8617 | train loss 0.5531773868016898\n",
      "Epoch8618 | train loss 0.5531781281717122\n",
      "Epoch8619 | train loss 0.5531778569333256\n",
      "Epoch8620 | train loss 0.5531770147010684\n",
      "Epoch8621 | train loss 0.5531772741116583\n",
      "Epoch8622 | train loss 0.5531778261996806\n",
      "Epoch8623 | train loss 0.5531778413429856\n",
      "Epoch8624 | train loss 0.553178126681596\n",
      "Epoch8625 | train loss 0.5531780696846544\n",
      "Epoch8626 | train loss 0.5531769781000913\n",
      "Epoch8627 | train loss 0.5531772205978632\n",
      "Epoch8628 | train loss 0.5531778092868627\n",
      "Epoch8629 | train loss 0.5531778619065881\n",
      "Epoch8630 | train loss 0.5531781166046857\n",
      "Epoch8631 | train loss 0.5531779721938074\n",
      "Epoch8632 | train loss 0.5531768926046788\n",
      "Epoch8633 | train loss 0.5531781202368439\n",
      "Epoch8634 | train loss 0.5531779839098454\n",
      "Epoch8635 | train loss 0.5531776640377939\n",
      "Epoch8636 | train loss 0.5531771209277213\n",
      "Epoch8637 | train loss 0.5531776925176382\n",
      "Epoch8638 | train loss 0.5531778577156365\n",
      "Epoch8639 | train loss 0.5531769660674035\n",
      "Epoch8640 | train loss 0.5531781441904604\n",
      "Epoch8641 | train loss 0.5531779542192816\n",
      "Epoch8642 | train loss 0.553176871985197\n",
      "Epoch8643 | train loss 0.5531781035475433\n",
      "Epoch8644 | train loss 0.5531779471598566\n",
      "Epoch8645 | train loss 0.5531765803135932\n",
      "Epoch8646 | train loss 0.5531777179799974\n",
      "Epoch8647 | train loss 0.5531780801899732\n",
      "Epoch8648 | train loss 0.5531777761504054\n",
      "Epoch8649 | train loss 0.5531771989539266\n",
      "Epoch8650 | train loss 0.5531775830686092\n",
      "Epoch8651 | train loss 0.5531778574176133\n",
      "Epoch8652 | train loss 0.5531770232319831\n",
      "Epoch8653 | train loss 0.5531776385940611\n",
      "Epoch8654 | train loss 0.5531777872703969\n",
      "Epoch8655 | train loss 0.55317721683532\n",
      "Epoch8656 | train loss 0.5531779726780951\n",
      "Epoch8657 | train loss 0.553177531324327\n",
      "Epoch8658 | train loss 0.5531777067482472\n",
      "Epoch8659 | train loss 0.553177182879299\n",
      "Epoch8660 | train loss 0.5531779363565147\n",
      "Epoch8661 | train loss 0.5531776656769216\n",
      "Epoch8662 | train loss 0.5531771409511567\n",
      "Epoch8663 | train loss 0.5531779211014509\n",
      "Epoch8664 | train loss 0.5531765522249042\n",
      "Epoch8665 | train loss 0.5531780549883842\n",
      "Epoch8666 | train loss 0.5531775806099176\n",
      "Epoch8667 | train loss 0.5531777464970946\n",
      "Epoch8668 | train loss 0.5531779881566763\n",
      "Epoch8669 | train loss 0.5531774513795972\n",
      "Epoch8670 | train loss 0.553177645187825\n",
      "Epoch8671 | train loss 0.553177120219916\n",
      "Epoch8672 | train loss 0.5531778863631189\n",
      "Epoch8673 | train loss 0.5531765067763627\n",
      "Epoch8674 | train loss 0.553178033940494\n",
      "Epoch8675 | train loss 0.5531777419522405\n",
      "Epoch8676 | train loss 0.553176851887256\n",
      "Epoch8677 | train loss 0.5531780184060335\n",
      "Epoch8678 | train loss 0.5531774654053152\n",
      "Epoch8679 | train loss 0.5531777322106063\n",
      "Epoch8680 | train loss 0.5531769599020481\n",
      "Epoch8681 | train loss 0.5531775652244687\n",
      "Epoch8682 | train loss 0.5531779884546996\n",
      "Epoch8683 | train loss 0.5531778629496693\n",
      "Epoch8684 | train loss 0.5531776099652052\n",
      "Epoch8685 | train loss 0.5531770798005163\n",
      "Epoch8686 | train loss 0.5531775630824268\n",
      "Epoch8687 | train loss 0.5531777360290289\n",
      "Epoch8688 | train loss 0.5531779127568006\n",
      "Epoch8689 | train loss 0.5531777755357326\n",
      "Epoch8690 | train loss 0.5531764480285346\n",
      "Epoch8691 | train loss 0.5531780595518648\n",
      "Epoch8692 | train loss 0.5531776537373662\n",
      "Epoch8693 | train loss 0.5531770824454725\n",
      "Epoch8694 | train loss 0.553177557233721\n",
      "Epoch8695 | train loss 0.5531777288392186\n",
      "Epoch8696 | train loss 0.5531779013946653\n",
      "Epoch8697 | train loss 0.5531777643226087\n",
      "Epoch8698 | train loss 0.5531778072007001\n",
      "Epoch8699 | train loss 0.5531773479282855\n",
      "Epoch8700 | train loss 0.5531776700355112\n",
      "Epoch8701 | train loss 0.5531770516932011\n",
      "Epoch8702 | train loss 0.5531779038906097\n",
      "Epoch8703 | train loss 0.553176518380642\n",
      "Epoch8704 | train loss 0.5531780304759741\n",
      "Epoch8705 | train loss 0.5531776370108128\n",
      "Epoch8706 | train loss 0.5531779003702104\n",
      "Epoch8707 | train loss 0.5531773570366204\n",
      "Epoch8708 | train loss 0.5531779291108251\n",
      "Epoch8709 | train loss 0.5531777289509773\n",
      "Epoch8710 | train loss 0.5531767055764795\n",
      "Epoch8711 | train loss 0.5531780182011425\n",
      "Epoch8712 | train loss 0.5531773542053997\n",
      "Epoch8713 | train loss 0.553177941981703\n",
      "Epoch8714 | train loss 0.5531775233149528\n",
      "Epoch8715 | train loss 0.5531768424250185\n",
      "Epoch8716 | train loss 0.5531774657405912\n",
      "Epoch8717 | train loss 0.5531780008226633\n",
      "Epoch8718 | train loss 0.5531773622147739\n",
      "Epoch8719 | train loss 0.553177858311683\n",
      "Epoch8720 | train loss 0.5531777322478593\n",
      "Epoch8721 | train loss 0.5531767912767828\n",
      "Epoch8722 | train loss 0.553177976384759\n",
      "Epoch8723 | train loss 0.5531774949282408\n",
      "Epoch8724 | train loss 0.5531770104542375\n",
      "Epoch8725 | train loss 0.5531778481975198\n",
      "Epoch8726 | train loss 0.5531777756847441\n",
      "Epoch8727 | train loss 0.5531773079000414\n",
      "Epoch8728 | train loss 0.5531778881140054\n",
      "Epoch8729 | train loss 0.5531776846386492\n",
      "Epoch8730 | train loss 0.5531775546073914\n",
      "Epoch8731 | train loss 0.5531769779138267\n",
      "Epoch8732 | train loss 0.5531775812618435\n",
      "Epoch8733 | train loss 0.5531764337979257\n",
      "Epoch8734 | train loss 0.5531780071184039\n",
      "Epoch8735 | train loss 0.553177746143192\n",
      "Epoch8736 | train loss 0.5531775129958987\n",
      "Epoch8737 | train loss 0.553177848495543\n",
      "Epoch8738 | train loss 0.5531777158565819\n",
      "Epoch8739 | train loss 0.5531776583194733\n",
      "Epoch8740 | train loss 0.5531769848242402\n",
      "Epoch8741 | train loss 0.5531778197363019\n",
      "Epoch8742 | train loss 0.5531775710731744\n",
      "Epoch8743 | train loss 0.5531778830103576\n",
      "Epoch8744 | train loss 0.5531776812672615\n",
      "Epoch8745 | train loss 0.5531776141934097\n",
      "Epoch8746 | train loss 0.5531777702830731\n",
      "Epoch8747 | train loss 0.553177223559469\n",
      "Epoch8748 | train loss 0.553177830260247\n",
      "Epoch8749 | train loss 0.5531777318194508\n",
      "Epoch8750 | train loss 0.5531766979768872\n",
      "Epoch8751 | train loss 0.5531779076531529\n",
      "Epoch8752 | train loss 0.5531774973869323\n",
      "Epoch8753 | train loss 0.5531777507252991\n",
      "Epoch8754 | train loss 0.5531776536814869\n",
      "Epoch8755 | train loss 0.5531776167079806\n",
      "Epoch8756 | train loss 0.5531777580641211\n",
      "Epoch8757 | train loss 0.5531773869507015\n",
      "Epoch8758 | train loss 0.5531769914925099\n",
      "Epoch8759 | train loss 0.5531777668558061\n",
      "Epoch8760 | train loss 0.5531777720525861\n",
      "Epoch8761 | train loss 0.553177390396595\n",
      "Epoch8762 | train loss 0.5531778150051833\n",
      "Epoch8763 | train loss 0.5531776254996658\n",
      "Epoch8764 | train loss 0.5531776444800198\n",
      "Epoch8765 | train loss 0.5531777575612068\n",
      "Epoch8766 | train loss 0.553177581820637\n",
      "Epoch8767 | train loss 0.5531777403131127\n",
      "Epoch8768 | train loss 0.5531774943135679\n",
      "Epoch8769 | train loss 0.5531768691912293\n",
      "Epoch8770 | train loss 0.553177528269589\n",
      "Epoch8771 | train loss 0.5531778230890632\n",
      "Epoch8772 | train loss 0.5531776713393629\n",
      "Epoch8773 | train loss 0.5531775885634125\n",
      "Epoch8774 | train loss 0.5531777390837669\n",
      "Epoch8775 | train loss 0.5531777034513652\n",
      "Epoch8776 | train loss 0.5531777245737612\n",
      "Epoch8777 | train loss 0.5531773403845728\n",
      "Epoch8778 | train loss 0.5531777375936509\n",
      "Epoch8779 | train loss 0.5531776839494705\n",
      "Epoch8780 | train loss 0.553177600093186\n",
      "Epoch8781 | train loss 0.5531777239963412\n",
      "Epoch8782 | train loss 0.5531773953512311\n",
      "Epoch8783 | train loss 0.5531769397482276\n",
      "Epoch8784 | train loss 0.5531776960007846\n",
      "Epoch8785 | train loss 0.5531777288392186\n",
      "Epoch8786 | train loss 0.5531774736195803\n",
      "Epoch8787 | train loss 0.5531777248717844\n",
      "Epoch8788 | train loss 0.5531776982732117\n",
      "Epoch8789 | train loss 0.5531768426671624\n",
      "Epoch8790 | train loss 0.553177730794996\n",
      "Epoch8791 | train loss 0.5531776409037411\n",
      "Epoch8792 | train loss 0.5531776946596801\n",
      "Epoch8793 | train loss 0.553177659921348\n",
      "Epoch8794 | train loss 0.5531776891835034\n",
      "Epoch8795 | train loss 0.5531773645244539\n",
      "Epoch8796 | train loss 0.5531778005324304\n",
      "Epoch8797 | train loss 0.5531776157207787\n",
      "Epoch8798 | train loss 0.5531775298714637\n",
      "Epoch8799 | train loss 0.553177684918046\n",
      "Epoch8800 | train loss 0.5531776507012546\n",
      "Epoch8801 | train loss 0.5531776656024158\n",
      "Epoch8802 | train loss 0.5531773436442018\n",
      "Epoch8803 | train loss 0.5531777863763273\n",
      "Epoch8804 | train loss 0.5531777117028832\n",
      "Epoch8805 | train loss 0.5531768116354943\n",
      "Epoch8806 | train loss 0.5531776884943247\n",
      "Epoch8807 | train loss 0.55317760983482\n",
      "Epoch8808 | train loss 0.5531777202151715\n",
      "Epoch8809 | train loss 0.5531775853224099\n",
      "Epoch8810 | train loss 0.553177701793611\n",
      "Epoch8811 | train loss 0.5531773305870593\n",
      "Epoch8812 | train loss 0.5531777751073241\n",
      "Epoch8813 | train loss 0.5531779146380722\n",
      "Epoch8814 | train loss 0.5531774808466434\n",
      "Epoch8815 | train loss 0.5531776333414018\n",
      "Epoch8816 | train loss 0.5531773887760937\n",
      "Epoch8817 | train loss 0.5531776602193713\n",
      "Epoch8818 | train loss 0.5531776627153158\n",
      "Epoch8819 | train loss 0.5531775197759271\n",
      "Epoch8820 | train loss 0.553177653066814\n",
      "Epoch8821 | train loss 0.5531777900829912\n",
      "Epoch8822 | train loss 0.5531775971502065\n",
      "Epoch8823 | train loss 0.553177544940263\n",
      "Epoch8824 | train loss 0.5531776078417897\n",
      "Epoch8825 | train loss 0.5531776230223477\n",
      "Epoch8826 | train loss 0.5531773764453828\n",
      "Epoch8827 | train loss 0.5531780343689024\n",
      "Epoch8828 | train loss 0.5531775118969381\n",
      "Epoch8829 | train loss 0.5531775851361453\n",
      "Epoch8830 | train loss 0.5531776036135853\n",
      "Epoch8831 | train loss 0.5531773564592004\n",
      "Epoch8832 | train loss 0.5531780173629522\n",
      "Epoch8833 | train loss 0.5531774999946356\n",
      "Epoch8834 | train loss 0.5531775730103254\n",
      "Epoch8835 | train loss 0.5531776011362672\n",
      "Epoch8836 | train loss 0.5531773326545953\n",
      "Epoch8837 | train loss 0.5531780162639915\n",
      "Epoch8838 | train loss 0.5531774949841202\n",
      "Epoch8839 | train loss 0.5531775668635964\n",
      "Epoch8840 | train loss 0.5531776487827301\n",
      "Epoch8841 | train loss 0.5531773298233748\n",
      "Epoch8842 | train loss 0.5531780221126974\n",
      "Epoch8843 | train loss 0.5531774836033583\n",
      "Epoch8844 | train loss 0.5531775568053127\n",
      "Epoch8845 | train loss 0.5531775799952448\n",
      "Epoch8846 | train loss 0.5531773056462407\n",
      "Epoch8847 | train loss 0.5531780055537819\n",
      "Epoch8848 | train loss 0.5531774759665131\n",
      "Epoch8849 | train loss 0.5531775431893766\n",
      "Epoch8850 | train loss 0.5531776288151741\n",
      "Epoch8851 | train loss 0.5531773073598742\n",
      "Epoch8852 | train loss 0.5531780917942524\n",
      "Epoch8853 | train loss 0.5531774494796992\n",
      "Epoch8854 | train loss 0.5531774435006082\n",
      "Epoch8855 | train loss 0.5531776197627187\n",
      "Epoch8856 | train loss 0.5531775919161737\n",
      "Epoch8857 | train loss 0.5531775517389178\n",
      "Epoch8858 | train loss 0.5531775541603565\n",
      "Epoch8859 | train loss 0.5531776879914105\n",
      "Epoch8860 | train loss 0.5531775239296257\n",
      "Epoch8861 | train loss 0.5531774748675525\n",
      "Epoch8862 | train loss 0.5531775354780257\n",
      "Epoch8863 | train loss 0.5531775996647775\n",
      "Epoch8864 | train loss 0.5531776781380177\n",
      "Epoch8865 | train loss 0.5531775371171535\n",
      "Epoch8866 | train loss 0.5531775557436049\n",
      "Epoch8867 | train loss 0.5531775666959584\n",
      "Epoch8868 | train loss 0.5531775488704443\n",
      "Epoch8869 | train loss 0.5531779362261295\n",
      "Epoch8870 | train loss 0.5531773736514151\n",
      "Epoch8871 | train loss 0.5531775703653693\n",
      "Epoch8872 | train loss 0.5531775490008295\n",
      "Epoch8873 | train loss 0.5531775172241032\n",
      "Epoch8874 | train loss 0.5531775832362473\n",
      "Epoch8875 | train loss 0.5531776650622487\n",
      "Epoch8876 | train loss 0.5531775098107755\n",
      "Epoch8877 | train loss 0.5531775420904159\n",
      "Epoch8878 | train loss 0.5531775508075952\n",
      "Epoch8879 | train loss 0.5531775260157883\n",
      "Epoch8880 | train loss 0.5531779281236231\n",
      "Epoch8881 | train loss 0.5531773577071726\n",
      "Epoch8882 | train loss 0.5531775534152985\n",
      "Epoch8883 | train loss 0.5531775361672043\n",
      "Epoch8884 | train loss 0.5531774931773543\n",
      "Epoch8885 | train loss 0.5531775647774339\n",
      "Epoch8886 | train loss 0.553177648819983\n",
      "Epoch8887 | train loss 0.553177498653531\n",
      "Epoch8888 | train loss 0.5531778989732266\n",
      "Epoch8889 | train loss 0.5531773305684328\n",
      "Epoch8890 | train loss 0.5531775422394276\n",
      "Epoch8891 | train loss 0.5531775262765586\n",
      "Epoch8892 | train loss 0.553177644200623\n",
      "Epoch8893 | train loss 0.5531774711050094\n",
      "Epoch8894 | train loss 0.5531778985075653\n",
      "Epoch8895 | train loss 0.5531773307919502\n",
      "Epoch8896 | train loss 0.5531775412522256\n",
      "Epoch8897 | train loss 0.553177518285811\n",
      "Epoch8898 | train loss 0.5531774867884814\n",
      "Epoch8899 | train loss 0.5531775547750294\n",
      "Epoch8900 | train loss 0.5531776302121579\n",
      "Epoch8901 | train loss 0.553177471831441\n",
      "Epoch8902 | train loss 0.553177888840437\n",
      "Epoch8903 | train loss 0.5531773496977985\n",
      "Epoch8904 | train loss 0.5531774602085352\n",
      "Epoch8905 | train loss 0.5531775299459696\n",
      "Epoch8906 | train loss 0.5531776121445\n",
      "Epoch8907 | train loss 0.5531774659268558\n",
      "Epoch8908 | train loss 0.5531778819300235\n",
      "Epoch8909 | train loss 0.5531773420237005\n",
      "Epoch8910 | train loss 0.5531774506531656\n",
      "Epoch8911 | train loss 0.553177527114749\n",
      "Epoch8912 | train loss 0.553177613094449\n",
      "Epoch8913 | train loss 0.5531774559058249\n",
      "Epoch8914 | train loss 0.5531778736971319\n",
      "Epoch8915 | train loss 0.5531773374043405\n",
      "Epoch8916 | train loss 0.5531774440407753\n",
      "Epoch8917 | train loss 0.5531779065728187\n",
      "Epoch8918 | train loss 0.5531774195469916\n",
      "Epoch8919 | train loss 0.5531774199008942\n",
      "Epoch8920 | train loss 0.5531775007024408\n",
      "Epoch8921 | train loss 0.5531775949522852\n",
      "Epoch8922 | train loss 0.5531774398125708\n",
      "Epoch8923 | train loss 0.553177858889103\n",
      "Epoch8924 | train loss 0.5531773083098233\n",
      "Epoch8925 | train loss 0.5531774194352329\n",
      "Epoch8926 | train loss 0.553177501950413\n",
      "Epoch8927 | train loss 0.5531775850430131\n",
      "Epoch8928 | train loss 0.5531774432584643\n",
      "Epoch8929 | train loss 0.5531778459995985\n",
      "Epoch8930 | train loss 0.5531773036159575\n",
      "Epoch8931 | train loss 0.553177416305989\n",
      "Epoch8932 | train loss 0.5531778780184686\n",
      "Epoch8933 | train loss 0.5531774055399\n",
      "Epoch8934 | train loss 0.5531773931905627\n",
      "Epoch8935 | train loss 0.5531774767488241\n",
      "Epoch8936 | train loss 0.5531775700859726\n",
      "Epoch8937 | train loss 0.5531774178147316\n",
      "Epoch8938 | train loss 0.5531778297759593\n",
      "Epoch8939 | train loss 0.5531772834062576\n",
      "Epoch8940 | train loss 0.5531773952394724\n",
      "Epoch8941 | train loss 0.553177862726152\n",
      "Epoch8942 | train loss 0.5531773883663118\n",
      "Epoch8943 | train loss 0.5531773759610951\n",
      "Epoch8944 | train loss 0.5531783653795719\n",
      "Epoch8945 | train loss 0.5531771248951555\n",
      "Epoch8946 | train loss 0.5531772830709815\n",
      "Epoch8947 | train loss 0.5531777855940163\n",
      "Epoch8948 | train loss 0.5531772573105991\n",
      "Epoch8949 | train loss 0.5531773734651506\n",
      "Epoch8950 | train loss 0.5531774513795972\n",
      "Epoch8951 | train loss 0.553177816234529\n",
      "Epoch8952 | train loss 0.5531773314625025\n",
      "Epoch8953 | train loss 0.5531774298474192\n",
      "Epoch8954 | train loss 0.5531778118386864\n",
      "Epoch8955 | train loss 0.5531773190759123\n",
      "Epoch8956 | train loss 0.5531771653704345\n",
      "Epoch8957 | train loss 0.5531774276681244\n",
      "Epoch8958 | train loss 0.5531778093986213\n",
      "Epoch8959 | train loss 0.5531773180700839\n",
      "Epoch8960 | train loss 0.55317741593346\n",
      "Epoch8961 | train loss 0.5531777944788336\n",
      "Epoch8962 | train loss 0.5531770021654665\n",
      "Epoch8963 | train loss 0.5531778851896525\n",
      "Epoch8964 | train loss 0.5531773466803134\n",
      "Epoch8965 | train loss 0.5531773755885661\n",
      "Epoch8966 | train loss 0.553177360855043\n",
      "Epoch8967 | train loss 0.5531778209097683\n",
      "Epoch8968 | train loss 0.5531772682629525\n",
      "Epoch8969 | train loss 0.553177349306643\n",
      "Epoch8970 | train loss 0.5531783286295832\n",
      "Epoch8971 | train loss 0.5531770868971944\n",
      "Epoch8972 | train loss 0.5531773128174245\n",
      "Epoch8973 | train loss 0.5531777185574174\n",
      "Epoch8974 | train loss 0.5531772052682936\n",
      "Epoch8975 | train loss 0.5531773256137967\n",
      "Epoch8976 | train loss 0.5531777925416828\n",
      "Epoch8977 | train loss 0.5531773230433464\n",
      "Epoch8978 | train loss 0.5531773178465664\n",
      "Epoch8979 | train loss 0.5531774013489484\n",
      "Epoch8980 | train loss 0.5531777727790177\n",
      "Epoch8981 | train loss 0.5531772815622389\n",
      "Epoch8982 | train loss 0.5531780953891575\n",
      "Epoch8983 | train loss 0.5531766780093312\n",
      "Epoch8984 | train loss 0.5531772508285939\n",
      "Epoch8985 | train loss 0.55317806718871\n",
      "Epoch8986 | train loss 0.5531775742396712\n",
      "Epoch8987 | train loss 0.5531759297661484\n",
      "Epoch8988 | train loss 0.5531774877943099\n",
      "Epoch8989 | train loss 0.5531726522743702\n",
      "Epoch8990 | train loss 0.5531683760881424\n",
      "Epoch8991 | train loss 0.5531640685908497\n",
      "Epoch8992 | train loss 0.5531597504392266\n",
      "Epoch8993 | train loss 0.5531581405550241\n",
      "Epoch8994 | train loss 0.5531563310138882\n",
      "Epoch8995 | train loss 0.5531530658714473\n",
      "Epoch8996 | train loss 0.5531516564637422\n",
      "Epoch8997 | train loss 0.5531504339724779\n",
      "Epoch8998 | train loss 0.5531484885886312\n",
      "Epoch8999 | train loss 0.5531483848206699\n",
      "Epoch9000 | train loss 0.5531466845795512\n",
      "Epoch9001 | train loss 0.5531467234902084\n",
      "Epoch9002 | train loss 0.5531453387439251\n",
      "Epoch9003 | train loss 0.5531461527198553\n",
      "Epoch9004 | train loss 0.553144142460078\n",
      "Epoch9005 | train loss 0.5531453587301075\n",
      "Epoch9006 | train loss 0.5531447669118643\n",
      "Epoch9007 | train loss 0.5531439393199981\n",
      "Epoch9008 | train loss 0.553142761439085\n",
      "Epoch9009 | train loss 0.5531429961696267\n",
      "Epoch9010 | train loss 0.5531432876177133\n",
      "Epoch9011 | train loss 0.5531422236561775\n",
      "Epoch9012 | train loss 0.553142589200288\n",
      "Epoch9013 | train loss 0.5531414888799191\n",
      "Epoch9014 | train loss 0.5531404284015298\n",
      "Epoch9015 | train loss 0.5531418661028147\n",
      "Epoch9016 | train loss 0.553141575306654\n",
      "Epoch9017 | train loss 0.5531413065083325\n",
      "Epoch9018 | train loss 0.5531410060636699\n",
      "Epoch9019 | train loss 0.5531407096423209\n",
      "Epoch9020 | train loss 0.5531405335478484\n",
      "Epoch9021 | train loss 0.5531404395401478\n",
      "Epoch9022 | train loss 0.5531406434997916\n",
      "Epoch9023 | train loss 0.5531403868086636\n",
      "Epoch9024 | train loss 0.5531409364566207\n",
      "Epoch9025 | train loss 0.5531410038471222\n",
      "Epoch9026 | train loss 0.5531395010836423\n",
      "Epoch9027 | train loss 0.5531403216160834\n",
      "Epoch9028 | train loss 0.553140536211431\n",
      "Epoch9029 | train loss 0.5531390278972685\n",
      "Epoch9030 | train loss 0.5531393488124013\n",
      "Epoch9031 | train loss 0.5531406731158495\n",
      "Epoch9032 | train loss 0.5531400387920439\n",
      "Epoch9033 | train loss 0.5531398376636207\n",
      "Epoch9034 | train loss 0.5531399240344763\n",
      "Epoch9035 | train loss 0.5531401246599853\n",
      "Epoch9036 | train loss 0.5531394366919994\n",
      "Epoch9037 | train loss 0.5531395824626089\n",
      "Epoch9038 | train loss 0.5531402859836817\n",
      "Epoch9039 | train loss 0.5531397292949259\n",
      "Epoch9040 | train loss 0.5531400915980339\n",
      "Epoch9041 | train loss 0.5531395901180803\n",
      "Epoch9042 | train loss 0.553138627577573\n",
      "Epoch9043 | train loss 0.5531381487846374\n",
      "Epoch9044 | train loss 0.5531389166414737\n",
      "Epoch9045 | train loss 0.5531386024877429\n",
      "Epoch9046 | train loss 0.5531396277062595\n",
      "Epoch9047 | train loss 0.5531401882134378\n",
      "Epoch9048 | train loss 0.5531394632905722\n",
      "Epoch9049 | train loss 0.5531387635506689\n",
      "Epoch9050 | train loss 0.5531391466408968\n",
      "Epoch9051 | train loss 0.5531392486207187\n",
      "Epoch9052 | train loss 0.5531397339887917\n",
      "Epoch9053 | train loss 0.5531377042084933\n",
      "Epoch9054 | train loss 0.5531389015726745\n",
      "Epoch9055 | train loss 0.553139269258827\n",
      "Epoch9056 | train loss 0.5531384093686939\n",
      "Epoch9057 | train loss 0.5531387516483665\n",
      "Epoch9058 | train loss 0.5531382906809449\n",
      "Epoch9059 | train loss 0.5531386222317815\n",
      "Epoch9060 | train loss 0.5531380489654839\n",
      "Epoch9061 | train loss 0.5531391522474587\n",
      "Epoch9062 | train loss 0.5531375115923584\n",
      "Epoch9063 | train loss 0.5531387243792415\n",
      "Epoch9064 | train loss 0.5531377271190285\n",
      "Epoch9065 | train loss 0.553138584382832\n",
      "Epoch9066 | train loss 0.5531376058980823\n",
      "Epoch9067 | train loss 0.5531372121721506\n",
      "Epoch9068 | train loss 0.5531390634737909\n",
      "Epoch9069 | train loss 0.5531367732398212\n",
      "Epoch9070 | train loss 0.5531378788873553\n",
      "Epoch9071 | train loss 0.553138636816293\n",
      "Epoch9072 | train loss 0.5531367756426334\n",
      "Epoch9073 | train loss 0.5531379449553788\n",
      "Epoch9074 | train loss 0.5531389361992478\n",
      "Epoch9075 | train loss 0.5531378300860524\n",
      "Epoch9076 | train loss 0.5531377772428095\n",
      "Epoch9077 | train loss 0.5531387271359562\n",
      "Epoch9078 | train loss 0.5531378577277064\n",
      "Epoch9079 | train loss 0.5531375746801496\n",
      "Epoch9080 | train loss 0.5531373299099505\n",
      "Epoch9081 | train loss 0.5531388774886727\n",
      "Epoch9082 | train loss 0.5531375549361109\n",
      "Epoch9083 | train loss 0.5531376887485385\n",
      "Epoch9084 | train loss 0.5531387813389301\n",
      "Epoch9085 | train loss 0.5531363140046597\n",
      "Epoch9086 | train loss 0.5531389053910971\n",
      "Epoch9087 | train loss 0.5531385498866439\n",
      "Epoch9088 | train loss 0.553136287741363\n",
      "Epoch9089 | train loss 0.5531380743160844\n",
      "Epoch9090 | train loss 0.5531375789828599\n",
      "Epoch9091 | train loss 0.5531383218802511\n",
      "Epoch9092 | train loss 0.5531377155892551\n",
      "Epoch9093 | train loss 0.5531371403113008\n",
      "Epoch9094 | train loss 0.5531373814307153\n",
      "Epoch9095 | train loss 0.5531370548717678\n",
      "Epoch9096 | train loss 0.5531385365873576\n",
      "Epoch9097 | train loss 0.5531383850798011\n",
      "Epoch9098 | train loss 0.5531366598419845\n",
      "Epoch9099 | train loss 0.5531360078975558\n",
      "Epoch9100 | train loss 0.5531384594738483\n",
      "Epoch9101 | train loss 0.5531382824666798\n",
      "Epoch9102 | train loss 0.5531364343501628\n",
      "Epoch9103 | train loss 0.5531357128545642\n",
      "Epoch9104 | train loss 0.553137843105942\n",
      "Epoch9105 | train loss 0.553138174880296\n",
      "Epoch9106 | train loss 0.5531370411068202\n",
      "Epoch9107 | train loss 0.5531378811970353\n",
      "Epoch9108 | train loss 0.5531377324461937\n",
      "Epoch9109 | train loss 0.5531364592351019\n",
      "Epoch9110 | train loss 0.5531361246667802\n",
      "Epoch9111 | train loss 0.5531379568018019\n",
      "Epoch9112 | train loss 0.5531380887329579\n",
      "Epoch9113 | train loss 0.5531370434351266\n",
      "Epoch9114 | train loss 0.5531368336267769\n",
      "Epoch9115 | train loss 0.5531380864977836\n",
      "Epoch9116 | train loss 0.5531363037228584\n",
      "Epoch9117 | train loss 0.5531365529820323\n",
      "Epoch9118 | train loss 0.5531380833126605\n",
      "Epoch9119 | train loss 0.5531367767043411\n",
      "Epoch9120 | train loss 0.5531373945251107\n",
      "Epoch9121 | train loss 0.5531362619064748\n",
      "Epoch9122 | train loss 0.5531377778016031\n",
      "Epoch9123 | train loss 0.5531368313170969\n",
      "Epoch9124 | train loss 0.5531364119052887\n",
      "Epoch9125 | train loss 0.5531375267915428\n",
      "Epoch9126 | train loss 0.5531379335001111\n",
      "Epoch9127 | train loss 0.5531366345472634\n",
      "Epoch9128 | train loss 0.5531366300582886\n",
      "Epoch9129 | train loss 0.5531361217424273\n",
      "Epoch9130 | train loss 0.5531372122466565\n",
      "Epoch9131 | train loss 0.5531369886547327\n",
      "Epoch9132 | train loss 0.5531360795721412\n",
      "Epoch9133 | train loss 0.553137570694089\n",
      "Epoch9134 | train loss 0.5531370846182108\n",
      "Epoch9135 | train loss 0.5531357748247683\n",
      "Epoch9136 | train loss 0.5531371880881488\n",
      "Epoch9137 | train loss 0.5531377345137298\n",
      "Epoch9138 | train loss 0.5531360222771764\n",
      "Epoch9139 | train loss 0.5531375953182578\n",
      "Epoch9140 | train loss 0.5531363239139319\n",
      "Epoch9141 | train loss 0.5531359940953553\n",
      "Epoch9142 | train loss 0.5531371839530766\n",
      "Epoch9143 | train loss 0.5531376026012004\n",
      "Epoch9144 | train loss 0.5531363877840341\n",
      "Epoch9145 | train loss 0.5531362122669816\n",
      "Epoch9146 | train loss 0.5531358104199171\n",
      "Epoch9147 | train loss 0.553136917091906\n",
      "Epoch9148 | train loss 0.5531366938725114\n",
      "Epoch9149 | train loss 0.5531353539414704\n",
      "Epoch9150 | train loss 0.5531373059935868\n",
      "Epoch9151 | train loss 0.5531373738124966\n",
      "Epoch9152 | train loss 0.5531369356438518\n",
      "Epoch9153 | train loss 0.5531361517123878\n",
      "Epoch9154 | train loss 0.5531368079409004\n",
      "Epoch9155 | train loss 0.5531348190642893\n",
      "Epoch9156 | train loss 0.5531373526714742\n",
      "Epoch9157 | train loss 0.5531373400613666\n",
      "Epoch9158 | train loss 0.5531366492062807\n",
      "Epoch9159 | train loss 0.5531346820481121\n",
      "Epoch9160 | train loss 0.5531372554227709\n",
      "Epoch9161 | train loss 0.5531373182497918\n",
      "Epoch9162 | train loss 0.5531359832175076\n",
      "Epoch9163 | train loss 0.5531358798593282\n",
      "Epoch9164 | train loss 0.5531371011957527\n",
      "Epoch9165 | train loss 0.5531350116059184\n",
      "Epoch9166 | train loss 0.553136657718569\n",
      "Epoch9167 | train loss 0.5531362659670412\n",
      "Epoch9168 | train loss 0.5531359010562301\n",
      "Epoch9169 | train loss 0.553136838003993\n",
      "Epoch9170 | train loss 0.5531362979486585\n",
      "Epoch9171 | train loss 0.5531352395378053\n",
      "Epoch9172 | train loss 0.5531367837078869\n",
      "Epoch9173 | train loss 0.5531366080977023\n",
      "Epoch9174 | train loss 0.5531370290927589\n",
      "Epoch9175 | train loss 0.5531365635618567\n",
      "Epoch9176 | train loss 0.5531364651955664\n",
      "Epoch9177 | train loss 0.5531351416930557\n",
      "Epoch9178 | train loss 0.5531367360427976\n",
      "Epoch9179 | train loss 0.5531364648230374\n",
      "Epoch9180 | train loss 0.5531364304758608\n",
      "Epoch9181 | train loss 0.5531345501169562\n",
      "Epoch9182 | train loss 0.5531365884467959\n",
      "Epoch9183 | train loss 0.5531368692778051\n",
      "Epoch9184 | train loss 0.5531350367888809\n",
      "Epoch9185 | train loss 0.5531358222104609\n",
      "Epoch9186 | train loss 0.5531363499350845\n",
      "Epoch9187 | train loss 0.5531366751901805\n",
      "Epoch9188 | train loss 0.5531361926347017\n",
      "Epoch9189 | train loss 0.5531345108896494\n",
      "Epoch9190 | train loss 0.5531364515610039\n",
      "Epoch9191 | train loss 0.5531367818824947\n",
      "Epoch9192 | train loss 0.5531362077407539\n",
      "Epoch9193 | train loss 0.5531344269774854\n",
      "Epoch9194 | train loss 0.5531364013254643\n",
      "Epoch9195 | train loss 0.553136537168175\n",
      "Epoch9196 | train loss 0.5531366078741848\n",
      "Epoch9197 | train loss 0.5531348672136664\n",
      "Epoch9198 | train loss 0.5531363007053733\n",
      "Epoch9199 | train loss 0.5531358489766717\n",
      "Epoch9200 | train loss 0.5531365417316556\n",
      "Epoch9201 | train loss 0.5531348410621285\n",
      "Epoch9202 | train loss 0.5531363600119948\n",
      "Epoch9203 | train loss 0.5531354563310742\n",
      "Epoch9204 | train loss 0.5531365889124572\n",
      "Epoch9205 | train loss 0.5531361747533083\n",
      "Epoch9206 | train loss 0.5531361331790685\n",
      "Epoch9207 | train loss 0.5531344532966613\n",
      "Epoch9208 | train loss 0.5531358036771417\n",
      "Epoch9209 | train loss 0.5531350325606763\n",
      "Epoch9210 | train loss 0.5531364413537085\n",
      "Epoch9211 | train loss 0.5531354011408984\n",
      "Epoch9212 | train loss 0.5531359342858195\n",
      "Epoch9213 | train loss 0.5531363903172314\n",
      "Epoch9214 | train loss 0.5531361964158714\n",
      "Epoch9215 | train loss 0.5531343664973974\n",
      "Epoch9216 | train loss 0.5531361866742373\n",
      "Epoch9217 | train loss 0.5531360494717955\n",
      "Epoch9218 | train loss 0.5531362489238382\n",
      "Epoch9219 | train loss 0.5531342053599656\n",
      "Epoch9220 | train loss 0.5531358867511154\n",
      "Epoch9221 | train loss 0.5531361662596465\n",
      "Epoch9222 | train loss 0.5531357843801379\n",
      "Epoch9223 | train loss 0.5531356525048614\n",
      "Epoch9224 | train loss 0.5531361319869756\n",
      "Epoch9225 | train loss 0.5531362441554666\n",
      "Epoch9226 | train loss 0.5531338495016098\n",
      "Epoch9227 | train loss 0.5531363001838326\n",
      "Epoch9228 | train loss 0.5531357560679316\n",
      "Epoch9229 | train loss 0.5531358172185719\n",
      "Epoch9230 | train loss 0.5531343728490173\n",
      "Epoch9231 | train loss 0.5531352384388447\n",
      "Epoch9232 | train loss 0.5531359546072782\n",
      "Epoch9233 | train loss 0.5531360998377204\n",
      "Epoch9234 | train loss 0.5531351954303682\n",
      "Epoch9235 | train loss 0.5531344583444298\n",
      "Epoch9236 | train loss 0.5531360596604645\n",
      "Epoch9237 | train loss 0.5531354656442999\n",
      "Epoch9238 | train loss 0.5531356792524457\n",
      "Epoch9239 | train loss 0.5531358980201184\n",
      "Epoch9240 | train loss 0.5531358551979065\n",
      "Epoch9241 | train loss 0.553135373108089\n",
      "Epoch9242 | train loss 0.5531346164084971\n",
      "Epoch9243 | train loss 0.5531347908265889\n",
      "Epoch9244 | train loss 0.5531360887736082\n",
      "Epoch9245 | train loss 0.5531360888294876\n",
      "Epoch9246 | train loss 0.5531346319615841\n",
      "Epoch9247 | train loss 0.5531359499879182\n",
      "Epoch9248 | train loss 0.5531359953992069\n",
      "Epoch9249 | train loss 0.5531338608078659\n",
      "Epoch9250 | train loss 0.5531358324550092\n",
      "Epoch9251 | train loss 0.5531345955468714\n",
      "Epoch9252 | train loss 0.5531359360180795\n",
      "Epoch9253 | train loss 0.5531359593570232\n",
      "Epoch9254 | train loss 0.5531345038302242\n",
      "Epoch9255 | train loss 0.5531344996020198\n",
      "Epoch9256 | train loss 0.5531348733231425\n",
      "Epoch9257 | train loss 0.5531359004229307\n",
      "Epoch9258 | train loss 0.5531357628665865\n",
      "Epoch9259 | train loss 0.553135182838887\n",
      "Epoch9260 | train loss 0.5531349126063287\n",
      "Epoch9261 | train loss 0.553134105950594\n",
      "Epoch9262 | train loss 0.5531353848613798\n",
      "Epoch9263 | train loss 0.5531356744840741\n",
      "Epoch9264 | train loss 0.5531348069943488\n",
      "Epoch9265 | train loss 0.5531355117633939\n",
      "Epoch9266 | train loss 0.5531355677358806\n",
      "Epoch9267 | train loss 0.5531349299289287\n",
      "Epoch9268 | train loss 0.5531355270370841\n",
      "Epoch9269 | train loss 0.5531338433176279\n",
      "Epoch9270 | train loss 0.5531347959116101\n",
      "Epoch9271 | train loss 0.553135188780725\n",
      "Epoch9272 | train loss 0.5531358425505459\n",
      "Epoch9273 | train loss 0.5531346322409809\n",
      "Epoch9274 | train loss 0.5531338805519045\n",
      "Epoch9275 | train loss 0.5531351749412715\n",
      "Epoch9276 | train loss 0.5531355921737849\n",
      "Epoch9277 | train loss 0.5531350597180427\n",
      "Epoch9278 | train loss 0.5531345144659281\n",
      "Epoch9279 | train loss 0.5531352376006544\n",
      "Epoch9280 | train loss 0.5531350763700903\n",
      "Epoch9281 | train loss 0.5531356867030263\n",
      "Epoch9282 | train loss 0.5531341655738652\n",
      "Epoch9283 | train loss 0.5531341988779604\n",
      "Epoch9284 | train loss 0.5531352272629738\n",
      "Epoch9285 | train loss 0.5531352021545172\n",
      "Epoch9286 | train loss 0.5531352745182813\n",
      "Epoch9287 | train loss 0.5531341095454991\n",
      "Epoch9288 | train loss 0.5531353010423481\n",
      "Epoch9289 | train loss 0.5531333723850548\n",
      "Epoch9290 | train loss 0.5531354430317879\n",
      "Epoch9291 | train loss 0.5531352467648685\n",
      "Epoch9292 | train loss 0.5531342386826873\n",
      "Epoch9293 | train loss 0.5531353888101875\n",
      "Epoch9294 | train loss 0.553135443944484\n",
      "Epoch9295 | train loss 0.5531340219825506\n",
      "Epoch9296 | train loss 0.5531352754868567\n",
      "Epoch9297 | train loss 0.5531341849453747\n",
      "Epoch9298 | train loss 0.553134731836617\n",
      "Epoch9299 | train loss 0.5531337765976787\n",
      "Epoch9300 | train loss 0.5531353613361716\n",
      "Epoch9301 | train loss 0.5531343995779753\n",
      "Epoch9302 | train loss 0.5531350492313504\n",
      "Epoch9303 | train loss 0.5531338712014258\n",
      "Epoch9304 | train loss 0.5531353223510087\n",
      "Epoch9305 | train loss 0.5531353517249227\n",
      "Epoch9306 | train loss 0.5531344482861459\n",
      "Epoch9307 | train loss 0.5531343459896744\n",
      "Epoch9308 | train loss 0.5531350765191019\n",
      "Epoch9309 | train loss 0.5531350217014551\n",
      "Epoch9310 | train loss 0.5531346350908279\n",
      "Epoch9311 | train loss 0.553134458232671\n",
      "Epoch9312 | train loss 0.5531331424042583\n",
      "Epoch9313 | train loss 0.553134393338114\n",
      "Epoch9314 | train loss 0.553134742025286\n",
      "Epoch9315 | train loss 0.5531350997835398\n",
      "Epoch9316 | train loss 0.5531341187097132\n",
      "Epoch9317 | train loss 0.5531349024549127\n",
      "Epoch9318 | train loss 0.5531330071948468\n",
      "Epoch9319 | train loss 0.5531348033063114\n",
      "Epoch9320 | train loss 0.5531349303945899\n",
      "Epoch9321 | train loss 0.5531345330551267\n",
      "Epoch9322 | train loss 0.5531342300958931\n",
      "Epoch9323 | train loss 0.5531345922686159\n",
      "Epoch9324 | train loss 0.553134248778224\n",
      "Epoch9325 | train loss 0.5531341423280537\n",
      "Epoch9326 | train loss 0.5531337987259031\n",
      "Epoch9327 | train loss 0.5531352675519884\n",
      "Epoch9328 | train loss 0.5531343755498529\n",
      "Epoch9329 | train loss 0.5531350296363234\n",
      "Epoch9330 | train loss 0.5531347369402647\n",
      "Epoch9331 | train loss 0.5531338723562658\n",
      "Epoch9332 | train loss 0.5531343686394393\n",
      "Epoch9333 | train loss 0.5531332428567112\n",
      "Epoch9334 | train loss 0.5531335680931807\n",
      "Epoch9335 | train loss 0.5531349707394838\n",
      "Epoch9336 | train loss 0.5531348409689962\n",
      "Epoch9337 | train loss 0.5531337677501142\n",
      "Epoch9338 | train loss 0.5531343986280263\n",
      "Epoch9339 | train loss 0.5531338223814964\n",
      "Epoch9340 | train loss 0.55313470127061\n",
      "Epoch9341 | train loss 0.5531345342844725\n",
      "Epoch9342 | train loss 0.553134192712605\n",
      "Epoch9343 | train loss 0.5531338534317911\n",
      "Epoch9344 | train loss 0.5531342841498553\n",
      "Epoch9345 | train loss 0.5531341861747205\n",
      "Epoch9346 | train loss 0.5531348264403642\n",
      "Epoch9347 | train loss 0.5531344704888761\n",
      "Epoch9348 | train loss 0.5531332547776401\n",
      "Epoch9349 | train loss 0.5531343744322658\n",
      "Epoch9350 | train loss 0.5531337777338922\n",
      "Epoch9351 | train loss 0.5531344051659107\n",
      "Epoch9352 | train loss 0.5531344728730619\n",
      "Epoch9353 | train loss 0.5531337631121278\n",
      "Epoch9354 | train loss 0.5531326665543019\n",
      "Epoch9355 | train loss 0.5531343410350382\n",
      "Epoch9356 | train loss 0.5531332735903561\n",
      "Epoch9357 | train loss 0.5531347046233713\n",
      "Epoch9358 | train loss 0.5531343334168196\n",
      "Epoch9359 | train loss 0.553133683372289\n",
      "Epoch9360 | train loss 0.5531339778751135\n",
      "Epoch9361 | train loss 0.5531343988329173\n",
      "Epoch9362 | train loss 0.5531345727108419\n",
      "Epoch9363 | train loss 0.5531334875151515\n",
      "Epoch9364 | train loss 0.5531339225918055\n",
      "Epoch9365 | train loss 0.5531335187889636\n",
      "Epoch9366 | train loss 0.55313452238217\n",
      "Epoch9367 | train loss 0.553134063500911\n",
      "Epoch9368 | train loss 0.5531337564066052\n",
      "Epoch9369 | train loss 0.5531342353671789\n",
      "Epoch9370 | train loss 0.5531336945295334\n",
      "Epoch9371 | train loss 0.5531335899233818\n",
      "Epoch9372 | train loss 0.5531343800760805\n",
      "Epoch9373 | train loss 0.5531343253701926\n",
      "Epoch9374 | train loss 0.5531334084272385\n",
      "Epoch9375 | train loss 0.5531325243785977\n",
      "Epoch9376 | train loss 0.5531344349496067\n",
      "Epoch9377 | train loss 0.5531354472227394\n",
      "Epoch9378 | train loss 0.5531329685635865\n",
      "Epoch9379 | train loss 0.5531343231350183\n",
      "Epoch9380 | train loss 0.5531337683834135\n",
      "Epoch9381 | train loss 0.5531322439573705\n",
      "Epoch9382 | train loss 0.5531346732936799\n",
      "Epoch9383 | train loss 0.5531328772753477\n",
      "Epoch9384 | train loss 0.5531353740021586\n",
      "Epoch9385 | train loss 0.5531328584998846\n",
      "Epoch9386 | train loss 0.5531342746317387\n",
      "Epoch9387 | train loss 0.5531329290568828\n",
      "Epoch9388 | train loss 0.5531328625790775\n",
      "Epoch9389 | train loss 0.55313411263749\n",
      "Epoch9390 | train loss 0.5531344925239682\n",
      "Epoch9391 | train loss 0.5531340392492712\n",
      "Epoch9392 | train loss 0.5531331543251872\n",
      "Epoch9393 | train loss 0.5531326178088785\n",
      "Epoch9394 | train loss 0.5531335408240556\n",
      "Epoch9395 | train loss 0.553133271690458\n",
      "Epoch9396 | train loss 0.553134216722101\n",
      "Epoch9397 | train loss 0.5531339707411825\n",
      "Epoch9398 | train loss 0.5531331135332584\n",
      "Epoch9399 | train loss 0.5531334658525884\n",
      "Epoch9400 | train loss 0.5531342028267682\n",
      "Epoch9401 | train loss 0.5531334317661822\n",
      "Epoch9402 | train loss 0.5531337491422892\n",
      "Epoch9403 | train loss 0.5531331254728138\n",
      "Epoch9404 | train loss 0.5531338449008762\n",
      "Epoch9405 | train loss 0.5531326109915972\n",
      "Epoch9406 | train loss 0.5531341864354908\n",
      "Epoch9407 | train loss 0.5531338163651526\n",
      "Epoch9408 | train loss 0.5531335358321666\n",
      "Epoch9409 | train loss 0.5531330197304487\n",
      "Epoch9410 | train loss 0.5531339276582002\n",
      "Epoch9411 | train loss 0.5531338767334819\n",
      "Epoch9412 | train loss 0.5531331683136522\n",
      "Epoch9413 | train loss 0.5531319877319038\n",
      "Epoch9414 | train loss 0.5531351883336901\n",
      "Epoch9415 | train loss 0.5531332180276514\n",
      "Epoch9416 | train loss 0.5531339068710804\n",
      "Epoch9417 | train loss 0.5531330958753824\n",
      "Epoch9418 | train loss 0.5531334958784282\n",
      "Epoch9419 | train loss 0.553133244998753\n",
      "Epoch9420 | train loss 0.5531331239640713\n",
      "Epoch9421 | train loss 0.5531339205428958\n",
      "Epoch9422 | train loss 0.5531337928958238\n",
      "Epoch9423 | train loss 0.5531333144009113\n",
      "Epoch9424 | train loss 0.5531330072320998\n",
      "Epoch9425 | train loss 0.5531334199383855\n",
      "Epoch9426 | train loss 0.5531333431787789\n",
      "Epoch9427 | train loss 0.5531336055323481\n",
      "Epoch9428 | train loss 0.5531338946893811\n",
      "Epoch9429 | train loss 0.5531325040571392\n",
      "Epoch9430 | train loss 0.5531338910385967\n",
      "Epoch9431 | train loss 0.5531325499154627\n",
      "Epoch9432 | train loss 0.5531339594721794\n",
      "Epoch9433 | train loss 0.5531336578726769\n",
      "Epoch9434 | train loss 0.5531332767754793\n",
      "Epoch9435 | train loss 0.5531329478509724\n",
      "Epoch9436 | train loss 0.5531334685906768\n",
      "Epoch9437 | train loss 0.5531331037171185\n",
      "Epoch9438 | train loss 0.5531327757798136\n",
      "Epoch9439 | train loss 0.5531333495117724\n",
      "Epoch9440 | train loss 0.5531335999444127\n",
      "Epoch9441 | train loss 0.5531329881586134\n",
      "Epoch9442 | train loss 0.5531339741498232\n",
      "Epoch9443 | train loss 0.5531320508942008\n",
      "Epoch9444 | train loss 0.5531327408924699\n",
      "Epoch9445 | train loss 0.5531336188875139\n",
      "Epoch9446 | train loss 0.5531330900080502\n",
      "Epoch9447 | train loss 0.5531336130946874\n",
      "Epoch9448 | train loss 0.5531325564160943\n",
      "Epoch9449 | train loss 0.5531331728212535\n",
      "Epoch9450 | train loss 0.5531336315535009\n",
      "Epoch9451 | train loss 0.5531320140697062\n",
      "Epoch9452 | train loss 0.5531337657570838\n",
      "Epoch9453 | train loss 0.5531323487125337\n",
      "Epoch9454 | train loss 0.5531327768787742\n",
      "Epoch9455 | train loss 0.5531330356374383\n",
      "Epoch9456 | train loss 0.5531334345042705\n",
      "Epoch9457 | train loss 0.5531318293511868\n",
      "Epoch9458 | train loss 0.5531323542818427\n",
      "Epoch9459 | train loss 0.5531323296017945\n",
      "Epoch9460 | train loss 0.5531315807811916\n",
      "Epoch9461 | train loss 0.5531323204189539\n",
      "Epoch9462 | train loss 0.5531315052509308\n",
      "Epoch9463 | train loss 0.5531321673095226\n",
      "Epoch9464 | train loss 0.5531324266456068\n",
      "Epoch9465 | train loss 0.553132787309587\n",
      "Epoch9466 | train loss 0.5531320781260729\n",
      "Epoch9467 | train loss 0.5531313217058778\n",
      "Epoch9468 | train loss 0.5531315337307752\n",
      "Epoch9469 | train loss 0.5531318863667548\n",
      "Epoch9470 | train loss 0.5531321672908962\n",
      "Epoch9471 | train loss 0.5531318683549762\n",
      "Epoch9472 | train loss 0.5531323525868356\n",
      "Epoch9473 | train loss 0.5531328002549708\n",
      "Epoch9474 | train loss 0.5531316026113927\n",
      "Epoch9475 | train loss 0.5531308238022029\n",
      "Epoch9476 | train loss 0.5531335945427418\n",
      "Epoch9477 | train loss 0.5531320082768798\n",
      "Epoch9478 | train loss 0.5531316223740578\n",
      "Epoch9479 | train loss 0.553132052756846\n",
      "Epoch9480 | train loss 0.5531321470811963\n",
      "Epoch9481 | train loss 0.5531318011693657\n",
      "Epoch9482 | train loss 0.5531322600878775\n",
      "Epoch9483 | train loss 0.5531308907456696\n",
      "Epoch9484 | train loss 0.553131844624877\n",
      "Epoch9485 | train loss 0.553131519202143\n",
      "Epoch9486 | train loss 0.5531319833174347\n",
      "Epoch9487 | train loss 0.5531320304982364\n",
      "Epoch9488 | train loss 0.5531317444518209\n",
      "Epoch9489 | train loss 0.5531321977451443\n",
      "Epoch9490 | train loss 0.5531308577023446\n",
      "Epoch9491 | train loss 0.5531319224461914\n",
      "Epoch9492 | train loss 0.5531322655268014\n",
      "Epoch9493 | train loss 0.5531311443820596\n",
      "Epoch9494 | train loss 0.5531317930296064\n",
      "Epoch9495 | train loss 0.5531316000781953\n",
      "Epoch9496 | train loss 0.5531322870589793\n",
      "Epoch9497 | train loss 0.5531315950863064\n",
      "Epoch9498 | train loss 0.5531321603432298\n",
      "Epoch9499 | train loss 0.5531307937949896\n",
      "Epoch9500 | train loss 0.5531314465403557\n",
      "Epoch9501 | train loss 0.5531321689672768\n",
      "Epoch9502 | train loss 0.5531319766491651\n",
      "Epoch9503 | train loss 0.5531316918879747\n",
      "Epoch9504 | train loss 0.5531312038935721\n",
      "Epoch9505 | train loss 0.5531321191042662\n",
      "Epoch9506 | train loss 0.5531314094550908\n",
      "Epoch9507 | train loss 0.5531320173665881\n",
      "Epoch9508 | train loss 0.5531306869909167\n",
      "Epoch9509 | train loss 0.5531322196871042\n",
      "Epoch9510 | train loss 0.5531327245011926\n",
      "Epoch9511 | train loss 0.5531303516589106\n",
      "Epoch9512 | train loss 0.5531324257701635\n",
      "Epoch9513 | train loss 0.553131270185113\n",
      "Epoch9514 | train loss 0.5531313113495707\n",
      "Epoch9515 | train loss 0.5531318434514105\n",
      "Epoch9516 | train loss 0.5531307293660939\n",
      "Epoch9517 | train loss 0.5531320066563785\n",
      "Epoch9518 | train loss 0.5531313098780811\n",
      "Epoch9519 | train loss 0.5531315424293279\n",
      "Epoch9520 | train loss 0.5531322244927287\n",
      "Epoch9521 | train loss 0.5531318012066185\n",
      "Epoch9522 | train loss 0.5531313736923039\n",
      "Epoch9523 | train loss 0.5531309663876891\n",
      "Epoch9524 | train loss 0.5531312525458634\n",
      "Epoch9525 | train loss 0.5531304684653878\n",
      "Epoch9526 | train loss 0.5531328250467777\n",
      "Epoch9527 | train loss 0.5531314491294325\n",
      "Epoch9528 | train loss 0.5531308981403709\n",
      "Epoch9529 | train loss 0.5531329257227481\n",
      "Epoch9530 | train loss 0.5531314319185913\n",
      "Epoch9531 | train loss 0.5531298261508346\n",
      "Epoch9532 | train loss 0.553133030347526\n",
      "Epoch9533 | train loss 0.5531304070539772\n",
      "Epoch9534 | train loss 0.553131464868784\n",
      "Epoch9535 | train loss 0.5531315660476684\n",
      "Epoch9536 | train loss 0.5531315216980874\n",
      "Epoch9537 | train loss 0.5531327237375081\n",
      "Epoch9538 | train loss 0.5531302961707115\n",
      "Epoch9539 | train loss 0.5531316139735282\n",
      "Epoch9540 | train loss 0.5531309580430388\n",
      "Epoch9541 | train loss 0.5531318243779242\n",
      "Epoch9542 | train loss 0.5531308502331376\n",
      "Epoch9543 | train loss 0.5531306798756123\n",
      "Epoch9544 | train loss 0.5531319427117706\n",
      "Epoch9545 | train loss 0.5531314837001264\n",
      "Epoch9546 | train loss 0.5531309201568365\n",
      "Epoch9547 | train loss 0.5531302367895842\n",
      "Epoch9548 | train loss 0.5531325669027864\n",
      "Epoch9549 | train loss 0.5531314176507294\n",
      "Epoch9550 | train loss 0.5531313011981547\n",
      "Epoch9551 | train loss 0.5531309843808413\n",
      "Epoch9552 | train loss 0.5531308638677\n",
      "Epoch9553 | train loss 0.5531316728517414\n",
      "Epoch9554 | train loss 0.55313083993271\n",
      "Epoch9555 | train loss 0.5531312562152744\n",
      "Epoch9556 | train loss 0.5531306852772832\n",
      "Epoch9557 | train loss 0.5531316308863461\n",
      "Epoch9558 | train loss 0.5531323057040572\n",
      "Epoch9559 | train loss 0.553130307123065\n",
      "Epoch9560 | train loss 0.5531300507858395\n",
      "Epoch9561 | train loss 0.5531318601965904\n",
      "Epoch9562 | train loss 0.5531301415525377\n",
      "Epoch9563 | train loss 0.5531316018663347\n",
      "Epoch9564 | train loss 0.5531324820965529\n",
      "Epoch9565 | train loss 0.5531306343525648\n",
      "Epoch9566 | train loss 0.5531311373226344\n",
      "Epoch9567 | train loss 0.5531305810809135\n",
      "Epoch9568 | train loss 0.5531306925229729\n",
      "Epoch9569 | train loss 0.5531320359744132\n",
      "Epoch9570 | train loss 0.5531314854882657\n",
      "Epoch9571 | train loss 0.5531308534927666\n",
      "Epoch9572 | train loss 0.5531307379156352\n",
      "Epoch9573 | train loss 0.5531312791630626\n",
      "Epoch9574 | train loss 0.5531305462867021\n",
      "Epoch9575 | train loss 0.5531314591504634\n",
      "Epoch9576 | train loss 0.5531306011043489\n",
      "Epoch9577 | train loss 0.5531311278045178\n",
      "Epoch9578 | train loss 0.5531323974952101\n",
      "Epoch9579 | train loss 0.5531311102956533\n",
      "Epoch9580 | train loss 0.553130717612803\n",
      "Epoch9581 | train loss 0.553130255471915\n",
      "Epoch9582 | train loss 0.5531314250454307\n",
      "Epoch9583 | train loss 0.5531319325231016\n",
      "Epoch9584 | train loss 0.5531297066435218\n",
      "Epoch9585 | train loss 0.5531313742697239\n",
      "Epoch9586 | train loss 0.5531322819180786\n",
      "Epoch9587 | train loss 0.5531311802752316\n",
      "Epoch9588 | train loss 0.5531307611614465\n",
      "Epoch9589 | train loss 0.553130054678768\n",
      "Epoch9590 | train loss 0.5531309915333986\n",
      "Epoch9591 | train loss 0.5531318144500256\n",
      "Epoch9592 | train loss 0.5531286766752601\n",
      "Epoch9593 | train loss 0.553132357839495\n",
      "Epoch9594 | train loss 0.5531306649185717\n",
      "Epoch9595 | train loss 0.5531318396143615\n",
      "Epoch9596 | train loss 0.5531304042227566\n",
      "Epoch9597 | train loss 0.5531316531449556\n",
      "Epoch9598 | train loss 0.553129694648087\n",
      "Epoch9599 | train loss 0.5531313715316355\n",
      "Epoch9600 | train loss 0.5531301082484424\n",
      "Epoch9601 | train loss 0.5531305070221424\n",
      "Epoch9602 | train loss 0.5531313228607178\n",
      "Epoch9603 | train loss 0.5531326109543443\n",
      "Epoch9604 | train loss 0.5531301604770124\n",
      "Epoch9605 | train loss 0.5531305400840938\n",
      "Epoch9606 | train loss 0.5531302415020763\n",
      "Epoch9607 | train loss 0.5531305437907577\n",
      "Epoch9608 | train loss 0.5531311344355345\n",
      "Epoch9609 | train loss 0.5531313438527286\n",
      "Epoch9610 | train loss 0.5531305066496134\n",
      "Epoch9611 | train loss 0.5531307533569634\n",
      "Epoch9612 | train loss 0.553131925277412\n",
      "Epoch9613 | train loss 0.5531311146914959\n",
      "Epoch9614 | train loss 0.5531292676925659\n",
      "Epoch9615 | train loss 0.5531301320530474\n",
      "Epoch9616 | train loss 0.5531311183981598\n",
      "Epoch9617 | train loss 0.5531316683627665\n",
      "Epoch9618 | train loss 0.5531315184757113\n",
      "Epoch9619 | train loss 0.5531301267445088\n",
      "Epoch9620 | train loss 0.5531309820897877\n",
      "Epoch9621 | train loss 0.5531296243704855\n",
      "Epoch9622 | train loss 0.5531309141404926\n",
      "Epoch9623 | train loss 0.5531307860091329\n",
      "Epoch9624 | train loss 0.5531318602338433\n",
      "Epoch9625 | train loss 0.553129199873656\n",
      "Epoch9626 | train loss 0.5531308784708381\n",
      "Epoch9627 | train loss 0.553130815513432\n",
      "Epoch9628 | train loss 0.5531297911144794\n",
      "Epoch9629 | train loss 0.5531306247785688\n",
      "Epoch9630 | train loss 0.5531317640282214\n",
      "Epoch9631 | train loss 0.5531299556791782\n",
      "Epoch9632 | train loss 0.5531304452009499\n",
      "Epoch9633 | train loss 0.5531312927231192\n",
      "Epoch9634 | train loss 0.5531298610381782\n",
      "Epoch9635 | train loss 0.5531307790800929\n",
      "Epoch9636 | train loss 0.5531313504464924\n",
      "Epoch9637 | train loss 0.5531305842846632\n",
      "Epoch9638 | train loss 0.5531293535232544\n",
      "Epoch9639 | train loss 0.5531317851133645\n",
      "Epoch9640 | train loss 0.55312982192263\n",
      "Epoch9641 | train loss 0.5531312948837876\n",
      "Epoch9642 | train loss 0.5531290745921433\n",
      "Epoch9643 | train loss 0.553131031114608\n",
      "Epoch9644 | train loss 0.5531293579004705\n",
      "Epoch9645 | train loss 0.5531300325505435\n",
      "Epoch9646 | train loss 0.5531322886236012\n",
      "Epoch9647 | train loss 0.5531303364410997\n",
      "Epoch9648 | train loss 0.5531306439265609\n",
      "Epoch9649 | train loss 0.5531309636309742\n",
      "Epoch9650 | train loss 0.5531297282129526\n",
      "Epoch9651 | train loss 0.5531306735053658\n",
      "Epoch9652 | train loss 0.5531303698197008\n",
      "Epoch9653 | train loss 0.5531315616704524\n",
      "Epoch9654 | train loss 0.5531292754039169\n",
      "Epoch9655 | train loss 0.5531295297853649\n",
      "Epoch9656 | train loss 0.5531309041753412\n",
      "Epoch9657 | train loss 0.5531305134296417\n",
      "Epoch9658 | train loss 0.5531310638785363\n",
      "Epoch9659 | train loss 0.553129883017391\n",
      "Epoch9660 | train loss 0.5531311834231019\n",
      "Epoch9661 | train loss 0.553129167649895\n",
      "Epoch9662 | train loss 0.5531315599940717\n",
      "Epoch9663 | train loss 0.5531297896802425\n",
      "Epoch9664 | train loss 0.5531294826976955\n",
      "Epoch9665 | train loss 0.5531306097842753\n",
      "Epoch9666 | train loss 0.553131074719131\n",
      "Epoch9667 | train loss 0.5531288580410183\n",
      "Epoch9668 | train loss 0.5531314553506672\n",
      "Epoch9669 | train loss 0.5531295047700405\n",
      "Epoch9670 | train loss 0.5531305880099535\n",
      "Epoch9671 | train loss 0.5531294964440167\n",
      "Epoch9672 | train loss 0.5531313740462065\n",
      "Epoch9673 | train loss 0.5531290439516305\n",
      "Epoch9674 | train loss 0.5531306697428227\n",
      "Epoch9675 | train loss 0.5531308366358281\n",
      "Epoch9676 | train loss 0.5531301076896489\n",
      "Epoch9677 | train loss 0.5531304197572172\n",
      "Epoch9678 | train loss 0.5531310022063554\n",
      "Epoch9679 | train loss 0.5531292404420673\n",
      "Epoch9680 | train loss 0.553129391502589\n",
      "Epoch9681 | train loss 0.5531308509781957\n",
      "Epoch9682 | train loss 0.553128855265677\n",
      "Epoch9683 | train loss 0.55313077153638\n",
      "Epoch9684 | train loss 0.5531292446702719\n",
      "Epoch9685 | train loss 0.5531309593841434\n",
      "Epoch9686 | train loss 0.5531313802488148\n",
      "Epoch9687 | train loss 0.5531295612826943\n",
      "Epoch9688 | train loss 0.5531288742087781\n",
      "Epoch9689 | train loss 0.5531301238574088\n",
      "Epoch9690 | train loss 0.5531295577995479\n",
      "Epoch9691 | train loss 0.5531311233341694\n",
      "Epoch9692 | train loss 0.5531286910176277\n",
      "Epoch9693 | train loss 0.553131015393883\n",
      "Epoch9694 | train loss 0.5531286418251693\n",
      "Epoch9695 | train loss 0.5531301265209914\n",
      "Epoch9696 | train loss 0.5531294367648661\n",
      "Epoch9697 | train loss 0.5531316541694105\n",
      "Epoch9698 | train loss 0.5531286928616465\n",
      "Epoch9699 | train loss 0.5531301260180771\n",
      "Epoch9700 | train loss 0.5531311203353106\n",
      "Epoch9701 | train loss 0.5531294605508447\n",
      "Epoch9702 | train loss 0.5531304884329438\n",
      "Epoch9703 | train loss 0.5531287679262459\n",
      "Epoch9704 | train loss 0.5531290758401155\n",
      "Epoch9705 | train loss 0.5531297378800809\n",
      "Epoch9706 | train loss 0.5531311074644327\n",
      "Epoch9707 | train loss 0.5531302999146283\n",
      "Epoch9708 | train loss 0.5531294660642743\n",
      "Epoch9709 | train loss 0.5531297788210213\n",
      "Epoch9710 | train loss 0.5531284247152507\n",
      "Epoch9711 | train loss 0.5531309203058481\n",
      "Epoch9712 | train loss 0.5531293300352991\n",
      "Epoch9713 | train loss 0.5531300936639308\n",
      "Epoch9714 | train loss 0.5531291168741882\n",
      "Epoch9715 | train loss 0.5531309806741774\n",
      "Epoch9716 | train loss 0.5531285826116801\n",
      "Epoch9717 | train loss 0.5531302428804338\n",
      "Epoch9718 | train loss 0.5531303450837731\n",
      "Epoch9719 | train loss 0.5531298026256263\n",
      "Epoch9720 | train loss 0.5531296860985457\n",
      "Epoch9721 | train loss 0.5531297643110156\n",
      "Epoch9722 | train loss 0.5531298167817295\n",
      "Epoch9723 | train loss 0.5531308906339109\n",
      "Epoch9724 | train loss 0.5531282842345536\n",
      "Epoch9725 | train loss 0.55312977720052\n",
      "Epoch9726 | train loss 0.553129176273942\n",
      "Epoch9727 | train loss 0.5531289867311716\n",
      "Epoch9728 | train loss 0.5531302918866277\n",
      "Epoch9729 | train loss 0.5531288186274469\n",
      "Epoch9730 | train loss 0.553130483161658\n",
      "Epoch9731 | train loss 0.5531300878524781\n",
      "Epoch9732 | train loss 0.5531293550692499\n",
      "Epoch9733 | train loss 0.5531299167126417\n",
      "Epoch9734 | train loss 0.5531298725679517\n",
      "Epoch9735 | train loss 0.55312913402915\n",
      "Epoch9736 | train loss 0.5531309039331973\n",
      "Epoch9737 | train loss 0.5531289764493704\n",
      "Epoch9738 | train loss 0.5531298846378923\n",
      "Epoch9739 | train loss 0.5531292139552534\n",
      "Epoch9740 | train loss 0.5531306374445557\n",
      "Epoch9741 | train loss 0.5531289630942047\n",
      "Epoch9742 | train loss 0.5531297972984612\n",
      "Epoch9743 | train loss 0.5531296600215136\n",
      "Epoch9744 | train loss 0.5531288151629269\n",
      "Epoch9745 | train loss 0.5531296960823238\n",
      "Epoch9746 | train loss 0.5531294737383723\n",
      "Epoch9747 | train loss 0.5531300426088274\n",
      "Epoch9748 | train loss 0.5531286445632577\n",
      "Epoch9749 | train loss 0.5531307342462242\n",
      "Epoch9750 | train loss 0.5531287651322782\n",
      "Epoch9751 | train loss 0.5531299120560288\n",
      "Epoch9752 | train loss 0.5531288929283619\n",
      "Epoch9753 | train loss 0.5531294282525778\n",
      "Epoch9754 | train loss 0.5531306437402964\n",
      "Epoch9755 | train loss 0.5531282005086541\n",
      "Epoch9756 | train loss 0.5531298788450658\n",
      "Epoch9757 | train loss 0.5531300100497901\n",
      "Epoch9758 | train loss 0.5531294775567949\n",
      "Epoch9759 | train loss 0.5531293111667037\n",
      "Epoch9760 | train loss 0.5531285445019603\n",
      "Epoch9761 | train loss 0.5531305682659149\n",
      "Epoch9762 | train loss 0.5531287625990808\n",
      "Epoch9763 | train loss 0.553129945769906\n",
      "Epoch9764 | train loss 0.5531288359686732\n",
      "Epoch9765 | train loss 0.5531301663257182\n",
      "Epoch9766 | train loss 0.5531297832541168\n",
      "Epoch9767 | train loss 0.5531281537562609\n",
      "Epoch9768 | train loss 0.5531304387189447\n",
      "Epoch9769 | train loss 0.5531299175508321\n",
      "Epoch9770 | train loss 0.553128776140511\n",
      "Epoch9771 | train loss 0.5531294925138355\n",
      "Epoch9772 | train loss 0.5531289236620068\n",
      "Epoch9773 | train loss 0.5531286656484008\n",
      "Epoch9774 | train loss 0.553131155539304\n",
      "Epoch9775 | train loss 0.5531284948997199\n",
      "Epoch9776 | train loss 0.5531306493096053\n",
      "Epoch9777 | train loss 0.5531279904767871\n",
      "Epoch9778 | train loss 0.553129226192832\n",
      "Epoch9779 | train loss 0.5531292723864317\n",
      "Epoch9780 | train loss 0.5531302043423056\n",
      "Epoch9781 | train loss 0.5531286647915841\n",
      "Epoch9782 | train loss 0.5531292320974172\n",
      "Epoch9783 | train loss 0.5531304273195565\n",
      "Epoch9784 | train loss 0.5531290878169238\n",
      "Epoch9785 | train loss 0.5531299199722707\n",
      "Epoch9786 | train loss 0.5531285978108644\n",
      "Epoch9787 | train loss 0.5531304671429098\n",
      "Epoch9788 | train loss 0.553129222150892\n",
      "Epoch9789 | train loss 0.553128018528223\n",
      "Epoch9790 | train loss 0.5531297313794493\n",
      "Epoch9791 | train loss 0.553129114061594\n",
      "Epoch9792 | train loss 0.5531289781443774\n",
      "Epoch9793 | train loss 0.5531291180104018\n",
      "Epoch9794 | train loss 0.5531307011283935\n",
      "Epoch9795 | train loss 0.5531286220066249\n",
      "Epoch9796 | train loss 0.5531283014826477\n",
      "Epoch9797 | train loss 0.5531300691328943\n",
      "Epoch9798 | train loss 0.5531296630203724\n",
      "Epoch9799 | train loss 0.5531297550722957\n",
      "Epoch9800 | train loss 0.5531284285522997\n",
      "Epoch9801 | train loss 0.553129679877311\n",
      "Epoch9802 | train loss 0.55312905035913\n",
      "Epoch9803 | train loss 0.5531278800591827\n",
      "Epoch9804 | train loss 0.5531306347995997\n",
      "Epoch9805 | train loss 0.5531285002268851\n",
      "Epoch9806 | train loss 0.5531283499673009\n",
      "Epoch9807 | train loss 0.5531298492848873\n",
      "Epoch9808 | train loss 0.5531302441097796\n",
      "Epoch9809 | train loss 0.5531284107454121\n",
      "Epoch9810 | train loss 0.553128884062171\n",
      "Epoch9811 | train loss 0.553129638619721\n",
      "Epoch9812 | train loss 0.5531282956898212\n",
      "Epoch9813 | train loss 0.5531281889788806\n",
      "Epoch9814 | train loss 0.5531291899643839\n",
      "Epoch9815 | train loss 0.5531298807822168\n",
      "Epoch9816 | train loss 0.5531290563941001\n",
      "Epoch9817 | train loss 0.553129608798772\n",
      "Epoch9818 | train loss 0.5531293759867549\n",
      "Epoch9819 | train loss 0.553128435332328\n",
      "Epoch9820 | train loss 0.5531280977837741\n",
      "Epoch9821 | train loss 0.5531301433220506\n",
      "Epoch9822 | train loss 0.553129657395184\n",
      "Epoch9823 | train loss 0.5531289391592145\n",
      "Epoch9824 | train loss 0.5531284211389721\n",
      "Epoch9825 | train loss 0.5531293937005103\n",
      "Epoch9826 | train loss 0.5531283437460661\n",
      "Epoch9827 | train loss 0.5531300668977202\n",
      "Epoch9828 | train loss 0.5531281196326018\n",
      "Epoch9829 | train loss 0.5531295304000378\n",
      "Epoch9830 | train loss 0.5531293141283095\n",
      "Epoch9831 | train loss 0.5531283554807306\n",
      "Epoch9832 | train loss 0.5531279690936208\n",
      "Epoch9833 | train loss 0.5531294056773186\n",
      "Epoch9834 | train loss 0.5531292464397848\n",
      "Epoch9835 | train loss 0.553128664419055\n",
      "Epoch9836 | train loss 0.5531299130059779\n",
      "Epoch9837 | train loss 0.5531279010139406\n",
      "Epoch9838 | train loss 0.5531286341696977\n",
      "Epoch9839 | train loss 0.553128757942468\n",
      "Epoch9840 | train loss 0.5531279022060335\n",
      "Epoch9841 | train loss 0.5531305693276226\n",
      "Epoch9842 | train loss 0.5531279224343598\n",
      "Epoch9843 | train loss 0.5531293107941747\n",
      "Epoch9844 | train loss 0.5531287389248609\n",
      "Epoch9845 | train loss 0.553128312844783\n",
      "Epoch9846 | train loss 0.5531305694393813\n",
      "Epoch9847 | train loss 0.5531280025094748\n",
      "Epoch9848 | train loss 0.5531298414431512\n",
      "Epoch9849 | train loss 0.553127936962992\n",
      "Epoch9850 | train loss 0.5531281039305032\n",
      "Epoch9851 | train loss 0.5531298277154565\n",
      "Epoch9852 | train loss 0.5531285493820906\n",
      "Epoch9853 | train loss 0.55312797838822\n",
      "Epoch9854 | train loss 0.5531297556124628\n",
      "Epoch9855 | train loss 0.5531283940188587\n",
      "Epoch9856 | train loss 0.553129599429667\n",
      "Epoch9857 | train loss 0.5531278882361949\n",
      "Epoch9858 | train loss 0.5531298315525055\n",
      "Epoch9859 | train loss 0.553128564581275\n",
      "Epoch9860 | train loss 0.5531286482140422\n",
      "Epoch9861 | train loss 0.5531272179074586\n",
      "Epoch9862 | train loss 0.5531297136470675\n",
      "Epoch9863 | train loss 0.5531280058063567\n",
      "Epoch9864 | train loss 0.5531300759874285\n",
      "Epoch9865 | train loss 0.5531291358359158\n",
      "Epoch9866 | train loss 0.5531273758225143\n",
      "Epoch9867 | train loss 0.5531297476775944\n",
      "Epoch9868 | train loss 0.5531284711882472\n",
      "Epoch9869 | train loss 0.5531278448179364\n",
      "Epoch9870 | train loss 0.5531297440081835\n",
      "Epoch9871 | train loss 0.5531284919381142\n",
      "Epoch9872 | train loss 0.5531283838674426\n",
      "Epoch9873 | train loss 0.553128753527999\n",
      "Epoch9874 | train loss 0.553128878492862\n",
      "Epoch9875 | train loss 0.5531292052753269\n",
      "Epoch9876 | train loss 0.5531280865892768\n",
      "Epoch9877 | train loss 0.5531293050758541\n",
      "Epoch9878 | train loss 0.55312852922827\n",
      "Epoch9879 | train loss 0.5531283582746983\n",
      "Epoch9880 | train loss 0.5531283077225089\n",
      "Epoch9881 | train loss 0.5531294960528612\n",
      "Epoch9882 | train loss 0.5531287241727114\n",
      "Epoch9883 | train loss 0.5531272461265325\n",
      "Epoch9884 | train loss 0.5531278086267412\n",
      "Epoch9885 | train loss 0.5531291793845594\n",
      "Epoch9886 | train loss 0.5531281906925142\n",
      "Epoch9887 | train loss 0.5531294723041356\n",
      "Epoch9888 | train loss 0.5531285566277802\n",
      "Epoch9889 | train loss 0.5531296890415252\n",
      "Epoch9890 | train loss 0.5531284319423139\n",
      "Epoch9891 | train loss 0.5531277403235435\n",
      "Epoch9892 | train loss 0.5531290076673031\n",
      "Epoch9893 | train loss 0.5531286785565317\n",
      "Epoch9894 | train loss 0.5531282401457429\n",
      "Epoch9895 | train loss 0.5531295291520655\n",
      "Epoch9896 | train loss 0.5531276177242398\n",
      "Epoch9897 | train loss 0.55312929822132\n",
      "Epoch9898 | train loss 0.5531282838433981\n",
      "Epoch9899 | train loss 0.5531287842430175\n",
      "Epoch9900 | train loss 0.5531295602209866\n",
      "Epoch9901 | train loss 0.5531276023574173\n",
      "Epoch9902 | train loss 0.5531285834498704\n",
      "Epoch9903 | train loss 0.5531286652944982\n",
      "Epoch9904 | train loss 0.5531286626681685\n",
      "Epoch9905 | train loss 0.5531293243728578\n",
      "Epoch9906 | train loss 0.5531274991668761\n",
      "Epoch9907 | train loss 0.5531277330033482\n",
      "Epoch9908 | train loss 0.5531275134533644\n",
      "Epoch9909 | train loss 0.5531292164325714\n",
      "Epoch9910 | train loss 0.5531285773403942\n",
      "Epoch9911 | train loss 0.5531289435923099\n",
      "Epoch9912 | train loss 0.553128259293735\n",
      "Epoch9913 | train loss 0.5531288951821626\n",
      "Epoch9914 | train loss 0.5531278645806015\n",
      "Epoch9915 | train loss 0.5531286142393946\n",
      "Epoch9916 | train loss 0.553129778187722\n",
      "Epoch9917 | train loss 0.5531277661770582\n",
      "Epoch9918 | train loss 0.5531287016160786\n",
      "Epoch9919 | train loss 0.5531286355853081\n",
      "Epoch9920 | train loss 0.5531275662593543\n",
      "Epoch9921 | train loss 0.5531285811215639\n",
      "Epoch9922 | train loss 0.5531280694715679\n",
      "Epoch9923 | train loss 0.5531292166933417\n",
      "Epoch9924 | train loss 0.5531280002556741\n",
      "Epoch9925 | train loss 0.5531282924488187\n",
      "Epoch9926 | train loss 0.5531280862540007\n",
      "Epoch9927 | train loss 0.5531284536421299\n",
      "Epoch9928 | train loss 0.553128926679492\n",
      "Epoch9929 | train loss 0.553128132596612\n",
      "Epoch9930 | train loss 0.5531289619021118\n",
      "Epoch9931 | train loss 0.5531288572214543\n",
      "Epoch9932 | train loss 0.5531284210644662\n",
      "Epoch9933 | train loss 0.5531266750209034\n",
      "Epoch9934 | train loss 0.5531278748251498\n",
      "Epoch9935 | train loss 0.5531294689327478\n",
      "Epoch9936 | train loss 0.5531284566223621\n",
      "Epoch9937 | train loss 0.5531288118846714\n",
      "Epoch9938 | train loss 0.5531280647590756\n",
      "Epoch9939 | train loss 0.5531274569220841\n",
      "Epoch9940 | train loss 0.5531280131265521\n",
      "Epoch9941 | train loss 0.5531298862025141\n",
      "Epoch9942 | train loss 0.553127720169723\n",
      "Epoch9943 | train loss 0.5531282536871731\n",
      "Epoch9944 | train loss 0.5531285930983723\n",
      "Epoch9945 | train loss 0.5531286805123091\n",
      "Epoch9946 | train loss 0.5531296624243259\n",
      "Epoch9947 | train loss 0.5531275419890881\n",
      "Epoch9948 | train loss 0.5531272215209901\n",
      "Epoch9949 | train loss 0.5531297938898205\n",
      "Epoch9950 | train loss 0.5531273352168501\n",
      "Epoch9951 | train loss 0.5531278578564525\n",
      "Epoch9952 | train loss 0.5531278846412897\n",
      "Epoch9953 | train loss 0.5531286431662739\n",
      "Epoch9954 | train loss 0.5531274214014411\n",
      "Epoch9955 | train loss 0.5531302954256535\n",
      "Epoch9956 | train loss 0.5531271885894239\n",
      "Epoch9957 | train loss 0.5531284390762449\n",
      "Epoch9958 | train loss 0.5531291177310049\n",
      "Epoch9959 | train loss 0.5531273599155248\n",
      "Epoch9960 | train loss 0.5531284149736166\n",
      "Epoch9961 | train loss 0.5531272133626044\n",
      "Epoch9962 | train loss 0.5531289565749467\n",
      "Epoch9963 | train loss 0.5531283244676888\n",
      "Epoch9964 | train loss 0.5531296580657363\n",
      "Epoch9965 | train loss 0.5531279691122473\n",
      "Epoch9966 | train loss 0.5531285759992898\n",
      "Epoch9967 | train loss 0.5531271182373166\n",
      "Epoch9968 | train loss 0.5531284943781793\n",
      "Epoch9969 | train loss 0.5531288377940655\n",
      "Epoch9970 | train loss 0.5531279321759939\n",
      "Epoch9971 | train loss 0.5531273138709366\n",
      "Epoch9972 | train loss 0.5531286569498479\n",
      "Epoch9973 | train loss 0.5531292549520731\n",
      "Epoch9974 | train loss 0.5531275762617588\n",
      "Epoch9975 | train loss 0.5531276614032685\n",
      "Epoch9976 | train loss 0.5531276159919798\n",
      "Epoch9977 | train loss 0.5531292579509318\n",
      "Epoch9978 | train loss 0.5531290175206959\n",
      "Epoch9979 | train loss 0.5531282570585608\n",
      "Epoch9980 | train loss 0.5531277842819691\n",
      "Epoch9981 | train loss 0.5531277672760189\n",
      "Epoch9982 | train loss 0.5531270681507885\n",
      "Epoch9983 | train loss 0.5531284642033278\n",
      "Epoch9984 | train loss 0.5531284255720675\n",
      "Epoch9985 | train loss 0.5531288760900498\n",
      "Epoch9986 | train loss 0.5531276961788535\n",
      "Epoch9987 | train loss 0.5531280652992427\n",
      "Epoch9988 | train loss 0.5531276310048997\n",
      "Epoch9989 | train loss 0.553129390925169\n",
      "Epoch9990 | train loss 0.5531272164173424\n",
      "Epoch9991 | train loss 0.5531273589655757\n",
      "Epoch9992 | train loss 0.5531284129060805\n",
      "Epoch9993 | train loss 0.5531279871612788\n",
      "Epoch9994 | train loss 0.5531276292540133\n",
      "Epoch9995 | train loss 0.5531281420961023\n",
      "Epoch9996 | train loss 0.553129305485636\n",
      "Epoch9997 | train loss 0.5531277055665851\n",
      "Epoch9998 | train loss 0.553127250187099\n",
      "Epoch9999 | train loss 0.5531269840151072\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      dataloader=train_dataloader,\n",
    "      loss_fn=loss,\n",
    "      optimizer=optimizer,\n",
    "      epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model(X_test).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_pred , y):\n",
    "    counter = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] != y_pred[i]:\n",
    "            counter +=1\n",
    "    return 1 - counter / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6765"
      ]
     },
     "execution_count": 1440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn(y_test_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()\n",
    "kernel = params['conv1.0.weight'].view(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1089e-01, -9.4194e-04,  4.6231e-01, -6.4247e-01, -5.4503e-01],\n",
       "        [ 4.9456e-01,  2.0058e+00,  2.1727e+00,  1.5817e+00, -1.9677e+00],\n",
       "        [-4.1240e-02, -3.7818e+00, -2.9657e+00, -2.1808e+00, -1.9417e+00],\n",
       "        [ 1.0392e+00,  1.0085e+00,  1.3716e-01,  2.6084e-01,  2.2983e-01]])"
      ]
     },
     "execution_count": 1442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Display the heatmap\n",
    "plt.imshow(kernel, cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create more complex conv model \n",
    "class ComplexeConvNet(nn.Module):\n",
    "    # in channels is equal to number of alphabet letters from which dataset is constructed 4 in case of abcd \n",
    "    # 1 out channels = one filter \n",
    "    # let's go with kernel size equal to pattern length 5 in oour case\n",
    "    def __init__(self,num_chars,pattern_len):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=num_chars , out_channels = 15 ,kernel_size= pattern_len,bias = True),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv1d(in_channels=15 , out_channels = 1 ,kernel_size= pattern_len,bias = True),\n",
    "                                   nn.ReLU()\n",
    "                                   )\n",
    "        self.fc1 = nn.Linear(in_features=7,out_features=20,bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=20,out_features=2,bias= True)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.squeeze()\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ComplexeConvNet(num_chars=4,pattern_len=5)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.001)\n",
    "loss2 = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 | train loss 0.6934448850899935\n",
      "Epoch1 | train loss 0.6933103831857443\n",
      "Epoch2 | train loss 0.6932147477567195\n",
      "Epoch3 | train loss 0.6931394296139479\n",
      "Epoch4 | train loss 0.6930762130767107\n",
      "Epoch5 | train loss 0.6930173265188933\n",
      "Epoch6 | train loss 0.6929600079357624\n",
      "Epoch7 | train loss 0.6929032275825739\n",
      "Epoch8 | train loss 0.6928449610620737\n",
      "Epoch9 | train loss 0.6927801555395127\n"
     ]
    }
   ],
   "source": [
    "train(model=model2,\n",
    "      dataloader=train_dataloader,\n",
    "      loss_fn=loss2,\n",
    "      optimizer=optimizer2,\n",
    "      epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
