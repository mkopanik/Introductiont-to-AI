{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1\n",
    "\n",
    "1. Generate strings of length 15 over the alphabet a, b, c, d\n",
    "\n",
    "2. Label your strings basing on matching a 5-element regular expression\n",
    "\n",
    "3. Balance your dataset of size 10000 so that approximately half of the dataset contains regex-matching parts.\n",
    "\n",
    "4. Prepare your data for training using one-hot encoding\n",
    "\n",
    "5. Divide your dataset into training and testing parts.\n",
    "\n",
    "6. Implement and train a model consisting of one convolutional layer with one filter followed by one fully-connected layer and train it to classify your strings. After training, examine the values of the filter\n",
    "\n",
    "7. Implement and train more complex models (more filters, layers) and analyze their performance on the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def generate_string(length = 15, alphabet = \"abcd\", pattern = \"cabad\", contains = True):\n",
    "      \n",
    "      pattern_len = len(pattern)\n",
    "      if contains: \n",
    "            # we need to generate prefix and sufix to our pattern both might be 0 lentgth ofc \n",
    "            prefix_len = random.randint(0,length - pattern_len)\n",
    "            suffix_len = length - pattern_len - prefix_len\n",
    "            prefix = ''.join(random.choices(\"abcd\" , k=prefix_len))\n",
    "            suffix = ''.join(random.choices(\"abcd\" , k=suffix_len))\n",
    "            return prefix + pattern + suffix\n",
    "      else: \n",
    "            while True:\n",
    "                  candidate = ''.join(random.choices(\"abcd\" , k=length))\n",
    "                  if pattern not in candidate:\n",
    "                        return candidate\n",
    "def generate_dataset(size = 10000):\n",
    "      expressions = []\n",
    "      labels = []\n",
    "      half = size // 2\n",
    "      # half = 9000\n",
    "      \n",
    "      \n",
    "      for _ in range(half):\n",
    "            expressions.append(generate_string(length=15,alphabet=\"abcd\",pattern=\"cabad\",contains=True))\n",
    "            labels.append(1)\n",
    "      for _ in range(size- half):\n",
    "            expressions.append(generate_string(length=15,alphabet=\"abcd\",pattern=\"cabad\",contains=False))\n",
    "            labels.append(0)\n",
    "            \n",
    "      return pd.DataFrame({\"expressions\":expressions,\"contains_pattern\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dadcbdabbcdcbdc'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_string(contains=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dcabcabadbcddcc'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_string(contains=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indexes = {'a':0,'b':1,'c':2,'d':3}\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_expression(s,map,num_classes):\n",
    "    one_hot = torch.zeros(size = (len(s),num_classes))\n",
    "    for i, char in enumerate(s):\n",
    "        one_hot[i,map[char]] = 1 \n",
    "    return one_hot\n",
    "def one_hot_encode_dataset(dataset,shape,map):\n",
    "    table = torch.empty(size = shape)\n",
    "    for i,s in enumerate(dataset.iloc[:,0]):\n",
    "        table[i] = one_hot_encode_expression(s,map = map,num_classes= shape[-1])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_character(char,characters = ['a','b','c','d']):\n",
    "    index = torch.argmax(char)\n",
    "    return characters[index]\n",
    "\n",
    "def decode_string(dataset, index):\n",
    "    expression = \"\"\n",
    "    for letter in dataset[index]:\n",
    "        expression += decode_character(letter)\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generate_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode_expression(s,char_indexes,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.empty(size = (10000,15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_dataset(dataset,shape,map):\n",
    "    table = torch.empty(size = shape)\n",
    "    for i,s in enumerate(dataset.iloc[:,0]):\n",
    "        table[i] = one_hot_encode_expression(s,map = map,num_classes= shape[-1])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot_encode_dataset(dataset=df,shape = (10000,15,4),map =char_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_string(dataset=X,index=5000) == df.iloc[5000,0]  # to make sure that one hot encoding works correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(data=df.iloc[:,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2)  # to have shape as desired by pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create custom dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.5250 - loss: 0.7138 - val_accuracy: 0.6025 - val_loss: 0.6663\n",
      "Epoch 2/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.6035 - loss: 0.6684 - val_accuracy: 0.6345 - val_loss: 0.6511\n",
      "Epoch 3/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.6124 - loss: 0.6590 - val_accuracy: 0.6400 - val_loss: 0.6426\n",
      "Epoch 4/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.6159 - loss: 0.6550 - val_accuracy: 0.6430 - val_loss: 0.6361\n",
      "Epoch 5/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.6297 - loss: 0.6435 - val_accuracy: 0.6380 - val_loss: 0.6339\n",
      "Epoch 6/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.6209 - loss: 0.6479 - val_accuracy: 0.6520 - val_loss: 0.6326\n",
      "Epoch 7/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.6255 - loss: 0.6417 - val_accuracy: 0.6335 - val_loss: 0.6293\n",
      "Epoch 8/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.6191 - loss: 0.6421 - val_accuracy: 0.6380 - val_loss: 0.6253\n",
      "Epoch 9/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.6236 - loss: 0.6423 - val_accuracy: 0.6350 - val_loss: 0.6281\n",
      "Epoch 10/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.6124 - loss: 0.6479 - val_accuracy: 0.6305 - val_loss: 0.6269\n",
      "Epoch 11/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.6234 - loss: 0.6412 - val_accuracy: 0.6370 - val_loss: 0.6229\n",
      "Epoch 12/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.6452 - loss: 0.6354 - val_accuracy: 0.6405 - val_loss: 0.6233\n",
      "Epoch 13/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.6336 - loss: 0.6337 - val_accuracy: 0.6380 - val_loss: 0.6236\n",
      "Epoch 14/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.6327 - loss: 0.6389 - val_accuracy: 0.6400 - val_loss: 0.6242\n",
      "Epoch 15/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.6373 - loss: 0.6340 - val_accuracy: 0.6385 - val_loss: 0.6248\n",
      "Epoch 16/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.6406 - loss: 0.6323 - val_accuracy: 0.6360 - val_loss: 0.6260\n",
      "Epoch 17/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.6323 - loss: 0.6348 - val_accuracy: 0.6365 - val_loss: 0.6221\n",
      "Epoch 18/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.6436 - loss: 0.6313 - val_accuracy: 0.6425 - val_loss: 0.6255\n",
      "Epoch 19/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.6303 - loss: 0.6332 - val_accuracy: 0.6520 - val_loss: 0.6222\n",
      "Epoch 20/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.6322 - loss: 0.6391 - val_accuracy: 0.6475 - val_loss: 0.6223\n",
      "Epoch 21/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.6478 - loss: 0.6307 - val_accuracy: 0.6345 - val_loss: 0.6224\n",
      "Epoch 22/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.6418 - loss: 0.6334 - val_accuracy: 0.6405 - val_loss: 0.6226\n",
      "Epoch 23/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.6487 - loss: 0.6278 - val_accuracy: 0.6380 - val_loss: 0.6262\n",
      "Epoch 24/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.6271 - loss: 0.6396 - val_accuracy: 0.6540 - val_loss: 0.6234\n",
      "Epoch 25/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.6485 - loss: 0.6306 - val_accuracy: 0.6345 - val_loss: 0.6264\n",
      "Epoch 26/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.6437 - loss: 0.6317 - val_accuracy: 0.6455 - val_loss: 0.6217\n",
      "Epoch 27/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.6347 - loss: 0.6358 - val_accuracy: 0.6450 - val_loss: 0.6216\n",
      "Epoch 28/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.6274 - loss: 0.6421 - val_accuracy: 0.6365 - val_loss: 0.6210\n",
      "Epoch 29/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.6358 - loss: 0.6383 - val_accuracy: 0.6460 - val_loss: 0.6221\n",
      "Epoch 30/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.6375 - loss: 0.6351 - val_accuracy: 0.6395 - val_loss: 0.6211\n",
      "Epoch 31/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.6321 - loss: 0.6359 - val_accuracy: 0.6505 - val_loss: 0.6220\n",
      "Epoch 32/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6336 - loss: 0.6427 - val_accuracy: 0.6380 - val_loss: 0.6225\n",
      "Epoch 33/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.6378 - loss: 0.6314 - val_accuracy: 0.6325 - val_loss: 0.6273\n",
      "Epoch 34/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6356 - loss: 0.6331 - val_accuracy: 0.6300 - val_loss: 0.6280\n",
      "Epoch 35/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.6327 - loss: 0.6414 - val_accuracy: 0.6335 - val_loss: 0.6266\n",
      "Epoch 36/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.6338 - loss: 0.6327 - val_accuracy: 0.6355 - val_loss: 0.6217\n",
      "Epoch 37/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.6183 - loss: 0.6415 - val_accuracy: 0.6370 - val_loss: 0.6213\n",
      "Epoch 38/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.6342 - loss: 0.6362 - val_accuracy: 0.6415 - val_loss: 0.6208\n",
      "Epoch 39/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.6226 - loss: 0.6395 - val_accuracy: 0.6350 - val_loss: 0.6220\n",
      "Epoch 40/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.6387 - loss: 0.6356 - val_accuracy: 0.6380 - val_loss: 0.6254\n",
      "Epoch 41/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.6336 - loss: 0.6366 - val_accuracy: 0.6455 - val_loss: 0.6213\n",
      "Epoch 42/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6462 - loss: 0.6339 - val_accuracy: 0.6460 - val_loss: 0.6213\n",
      "Epoch 43/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 0.6251 - loss: 0.6392 - val_accuracy: 0.6430 - val_loss: 0.6206\n",
      "Epoch 44/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.6392 - loss: 0.6321 - val_accuracy: 0.6410 - val_loss: 0.6218\n",
      "Epoch 45/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.6430 - loss: 0.6337 - val_accuracy: 0.6240 - val_loss: 0.6302\n",
      "Epoch 46/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.6393 - loss: 0.6383 - val_accuracy: 0.6375 - val_loss: 0.6228\n",
      "Epoch 47/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.6296 - loss: 0.6363 - val_accuracy: 0.6370 - val_loss: 0.6220\n",
      "Epoch 48/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.6398 - loss: 0.6294 - val_accuracy: 0.6565 - val_loss: 0.6238\n",
      "Epoch 49/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.6369 - loss: 0.6347 - val_accuracy: 0.6505 - val_loss: 0.6223\n",
      "Epoch 50/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6455 - loss: 0.6316 - val_accuracy: 0.6270 - val_loss: 0.6256\n",
      "Epoch 51/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.6328 - loss: 0.6364 - val_accuracy: 0.6540 - val_loss: 0.6231\n",
      "Epoch 52/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.6388 - loss: 0.6378 - val_accuracy: 0.6375 - val_loss: 0.6211\n",
      "Epoch 53/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.6325 - loss: 0.6355 - val_accuracy: 0.6570 - val_loss: 0.6219\n",
      "Epoch 54/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.6302 - loss: 0.6387 - val_accuracy: 0.6385 - val_loss: 0.6247\n",
      "Epoch 55/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.6302 - loss: 0.6351 - val_accuracy: 0.6465 - val_loss: 0.6211\n",
      "Epoch 56/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.6485 - loss: 0.6317 - val_accuracy: 0.6530 - val_loss: 0.6217\n",
      "Epoch 57/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6309 - loss: 0.6343 - val_accuracy: 0.6445 - val_loss: 0.6213\n",
      "Epoch 58/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.6235 - loss: 0.6413 - val_accuracy: 0.6560 - val_loss: 0.6227\n",
      "Epoch 59/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.6384 - loss: 0.6360 - val_accuracy: 0.6355 - val_loss: 0.6216\n",
      "Epoch 60/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.6347 - loss: 0.6343 - val_accuracy: 0.6575 - val_loss: 0.6235\n",
      "Epoch 61/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.6327 - loss: 0.6410 - val_accuracy: 0.6435 - val_loss: 0.6197\n",
      "Epoch 62/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.6258 - loss: 0.6364 - val_accuracy: 0.6595 - val_loss: 0.6240\n",
      "Epoch 63/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.6385 - loss: 0.6392 - val_accuracy: 0.6415 - val_loss: 0.6229\n",
      "Epoch 64/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.6349 - loss: 0.6375 - val_accuracy: 0.6335 - val_loss: 0.6216\n",
      "Epoch 65/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.6313 - loss: 0.6350 - val_accuracy: 0.6430 - val_loss: 0.6213\n",
      "Epoch 66/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.6437 - loss: 0.6305 - val_accuracy: 0.6425 - val_loss: 0.6214\n",
      "Epoch 67/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.6337 - loss: 0.6376 - val_accuracy: 0.6380 - val_loss: 0.6224\n",
      "Epoch 68/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.6322 - loss: 0.6402 - val_accuracy: 0.6395 - val_loss: 0.6207\n",
      "Epoch 69/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.6268 - loss: 0.6415 - val_accuracy: 0.6385 - val_loss: 0.6205\n",
      "Epoch 70/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.6495 - loss: 0.6297 - val_accuracy: 0.6350 - val_loss: 0.6214\n",
      "Epoch 71/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.6284 - loss: 0.6359 - val_accuracy: 0.6555 - val_loss: 0.6229\n",
      "Epoch 72/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.6335 - loss: 0.6378 - val_accuracy: 0.6580 - val_loss: 0.6245\n",
      "Epoch 73/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.6375 - loss: 0.6355 - val_accuracy: 0.6375 - val_loss: 0.6206\n",
      "Epoch 74/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.6412 - loss: 0.6287 - val_accuracy: 0.6385 - val_loss: 0.6224\n",
      "Epoch 75/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.6349 - loss: 0.6336 - val_accuracy: 0.6410 - val_loss: 0.6214\n",
      "Epoch 76/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.6369 - loss: 0.6304 - val_accuracy: 0.6395 - val_loss: 0.6215\n",
      "Epoch 77/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6328 - loss: 0.6367 - val_accuracy: 0.6355 - val_loss: 0.6258\n",
      "Epoch 78/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.6439 - loss: 0.6303 - val_accuracy: 0.6375 - val_loss: 0.6239\n",
      "Epoch 79/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.6453 - loss: 0.6285 - val_accuracy: 0.6355 - val_loss: 0.6246\n",
      "Epoch 80/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.6444 - loss: 0.6264 - val_accuracy: 0.6360 - val_loss: 0.6226\n",
      "Epoch 81/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.6407 - loss: 0.6366 - val_accuracy: 0.6410 - val_loss: 0.6212\n",
      "Epoch 82/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.6383 - loss: 0.6358 - val_accuracy: 0.6520 - val_loss: 0.6212\n",
      "Epoch 83/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.6359 - loss: 0.6342 - val_accuracy: 0.6330 - val_loss: 0.6219\n",
      "Epoch 84/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.6362 - loss: 0.6331 - val_accuracy: 0.6520 - val_loss: 0.6200\n",
      "Epoch 85/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.6412 - loss: 0.6326 - val_accuracy: 0.6520 - val_loss: 0.6222\n",
      "Epoch 86/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.6426 - loss: 0.6354 - val_accuracy: 0.6355 - val_loss: 0.6218\n",
      "Epoch 87/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.6356 - loss: 0.6327 - val_accuracy: 0.6405 - val_loss: 0.6193\n",
      "Epoch 88/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.6462 - loss: 0.6300 - val_accuracy: 0.6345 - val_loss: 0.6231\n",
      "Epoch 89/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.6369 - loss: 0.6382 - val_accuracy: 0.6375 - val_loss: 0.6221\n",
      "Epoch 90/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.6326 - loss: 0.6359 - val_accuracy: 0.6520 - val_loss: 0.6198\n",
      "Epoch 91/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.6353 - loss: 0.6313 - val_accuracy: 0.6400 - val_loss: 0.6198\n",
      "Epoch 92/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.6414 - loss: 0.6327 - val_accuracy: 0.6395 - val_loss: 0.6234\n",
      "Epoch 93/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.6417 - loss: 0.6293 - val_accuracy: 0.6355 - val_loss: 0.6255\n",
      "Epoch 94/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.6400 - loss: 0.6307 - val_accuracy: 0.6380 - val_loss: 0.6248\n",
      "Epoch 95/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.6433 - loss: 0.6331 - val_accuracy: 0.6200 - val_loss: 0.6337\n",
      "Epoch 96/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.6329 - loss: 0.6368 - val_accuracy: 0.6355 - val_loss: 0.6224\n",
      "Epoch 97/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.6332 - loss: 0.6343 - val_accuracy: 0.6375 - val_loss: 0.6216\n",
      "Epoch 98/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.6353 - loss: 0.6340 - val_accuracy: 0.6385 - val_loss: 0.6218\n",
      "Epoch 99/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.6341 - loss: 0.6343 - val_accuracy: 0.6365 - val_loss: 0.6211\n",
      "Epoch 100/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.6414 - loss: 0.6279 - val_accuracy: 0.6330 - val_loss: 0.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c7e03c8080>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "simple_model = models.Sequential([\n",
    "    layers.Input((15, 4)),\n",
    "    layers.Conv1D(filters = 1, kernel_size=5,use_bias = False),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation='sigmoid',use_bias = False)\n",
    "])\n",
    "\n",
    "simple_model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "simple_model.fit(X_train, y_train, batch_size= 10,epochs = 100, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_pred , y):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y = np.array(y)\n",
    "    counter = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] != y_pred[i]:\n",
    "            counter +=1\n",
    "    return 1 - counter / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.round(simple_model(X_test)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.633"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn(y_test_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cabad'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Access the Conv1D layer\n",
    "conv_layer = simple_model.layers[0]\n",
    "\n",
    "# Extract the weights (kernel and bias)\n",
    "kernel = conv_layer.get_weights()\n",
    "kernel = np.array(kernel).reshape(5, 4)   # 5 element regex\n",
    "\n",
    "sns.heatmap(data = kernel,cmap='hot')\n",
    "plt.show()\n",
    "\"cabad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29337633, -0.32988846,  0.6179288 , -0.31840023],\n",
       "       [ 0.52570355, -0.38821188, -0.03456175, -0.7037126 ],\n",
       "       [ 0.03659063,  0.600945  , -0.5910369 , -0.1709293 ],\n",
       "       [ 0.829106  ,  0.00814482, -0.24208462,  0.16870154],\n",
       "       [-0.27370355, -0.33012393, -0.11381502,  0.58762896]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akopa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4892 - val_accuracy: 0.9855 - val_loss: 0.0566\n",
      "Epoch 2/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0399 - val_accuracy: 0.9940 - val_loss: 0.0199\n",
      "Epoch 3/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0140 - val_accuracy: 0.9950 - val_loss: 0.0164\n",
      "Epoch 4/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0079 - val_accuracy: 0.9965 - val_loss: 0.0123\n",
      "Epoch 5/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9955 - val_loss: 0.0156\n",
      "Epoch 6/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0064 - val_accuracy: 0.9965 - val_loss: 0.0153\n",
      "Epoch 7/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 0.9970 - val_loss: 0.0129\n",
      "Epoch 8/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.9950 - val_loss: 0.0226\n",
      "Epoch 9/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9970 - val_loss: 0.0134\n",
      "Epoch 10/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0032 - val_accuracy: 0.9965 - val_loss: 0.0130\n",
      "Epoch 11/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9965 - val_loss: 0.0170\n",
      "Epoch 12/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9970 - val_loss: 0.0155\n",
      "Epoch 13/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.9960 - val_loss: 0.0145\n",
      "Epoch 14/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9970 - val_loss: 0.0154\n",
      "Epoch 15/15\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9930 - val_loss: 0.0408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c7e25d6360>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv1D(filters = 32, kernel_size=3, activation='relu', input_shape=(15, 4)),\n",
    "    layers.MaxPool1D(pool_size = 2),\n",
    "    layers.Conv1D(64, 3, activation = 'relu'), \n",
    "    layers.MaxPool1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.round(model(X_test)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn(y_test_pred,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
