{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1\n",
    "\n",
    "Using tensorflow, construct and train a network consisting of fully connected layers for classification of MNIST dataset.\n",
    " Construct and train a fully connected autoencoder. Be able to explain details of your implementation and justify the decisions made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected Mnist classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten , Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy , MeanSquaredError\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to doc we should have 60000 examples in training and 10000 examples in testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset Shape:\n",
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('MNIST Dataset Shape:')\n",
    "print('X_train: ' + str(X_train.shape))\n",
    "print('Y_train: ' + str(Y_train.shape))\n",
    "print('X_test:  '  + str(X_test.shape))\n",
    "print('Y_test:  '  + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected neural network model \n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),  # shoud be 28*28 , vector of length 784,\n",
    "    Dense(units = 128 , use_bias = True, activation = 'relu'),\n",
    "    Dense(units = 64 , use_bias = True, activation = 'relu'),\n",
    "    Dense(units = 10 , activation = 'softmax')   # as we have 10 numbers to classify so we want to get same number of classes in the end \n",
    "     \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare optimizer as proposed using Adam \n",
    "model.compile(optimizer= Adam(learning_rate=0.001), # defalt lr \n",
    "              loss = CategoricalCrossentropy(from_logits= False), # as we have output from final layer in probabability like values \n",
    "              metrics = ['accuracy'] \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-hot encoding for target \n",
    "train_labels = to_categorical(Y_train,num_classes=10) # one hot encoding 3 type of flowers  # full set \n",
    "test_labels = to_categorical(Y_test,num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7803 - loss: 4.2862\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - accuracy: 0.9170 - loss: 0.3087\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2063\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1595\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1433\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 988us/step - accuracy: 0.9670 - loss: 0.1195\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9702 - loss: 0.1076\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.1027\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step - accuracy: 0.9746 - loss: 0.0884\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9779 - loss: 0.0818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x331f158e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,train_labels, epochs=10 , batch_size= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m784\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,160</span> (1.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m328,160\u001b[0m (1.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,774</span> (854.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m218,774\u001b[0m (854.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.9636 - loss: 0.1566\n",
      "Test Loss: 0.1325\n",
      "Test Accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, test_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need independent variable so X_test and X_train for tests\n",
    "\n",
    "# normalize \n",
    "X_train = X_train / 255.0 # transafer 0-255 rgb scale to 0-1 scale\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# flatten data \n",
    "X_train = X_train.reshape((-1,28*28))\n",
    "X_test = X_test.reshape((-1,28*28))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make proper use of encoder we should reduce dimensionality otherwise we will just train encoder to copy original data, that's not very useful\n",
    "encoder_dim = 256\n",
    "\n",
    "# encoder \n",
    "encoder = Sequential([\n",
    "    Dense(units = 128 , use_bias = True, activation = 'relu'),\n",
    "    Dense(encoder_dim, activation='relu')\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(128,activation='relu'), # output from encode\n",
    "    Dense(28*28, activation='sigmoid') # same as original\n",
    "])\n",
    "# composing autoencoder \n",
    "autoencoder = Sequential([encoder,decoder])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=MeanSquaredError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.0373\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0082\n",
      "Epoch 3/20\n",
      "\u001b[1m 633/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0063"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m learned_values \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input and target are the same\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:243\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignature specifies \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m arguments, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_definition\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39minput_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Function Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m   )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m InterpolateRuntimeError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 243\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_captures\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# The caller must use record_operation to record this operation in the\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:4599\u001b[0m, in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   4597\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(control):\n\u001b[1;32m   4598\u001b[0m         control()\n\u001b[0;32m-> 4599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNullContextmanager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4601\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m get_default_graph()\u001b[38;5;241m.\u001b[39mcontrol_dependencies(control_inputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:176\u001b[0m, in \u001b[0;36mNullContextmanager.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNullContextmanager\u001b[39;00m(contextlib\u001b[38;5;241m.\u001b[39mAbstractContextManager[\u001b[38;5;28;01mNone\u001b[39;00m]):\n\u001b[0;32m--> 176\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    179\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learned_values = autoencoder.fit(\n",
    "    X_train, X_train,  # Input and target are the same\n",
    "    epochs=20,\n",
    "    batch_size=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 531us/step - loss: 0.0023\n",
      "Test Loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the autoencoder on the test set\n",
    "test_loss = autoencoder.evaluate(X_test, X_test, verbose=2)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick a random test sample\n",
    "import matplotlib.pyplot as plt \n",
    "sample_index = 0\n",
    "original = X_test[sample_index]\n",
    "encoded = encoder.predict(original.reshape(1, -1))\n",
    "decoded = decoder.predict(encoded)\n",
    "\n",
    "# Reshape for visualization\n",
    "original_image = original.reshape(28, 28)\n",
    "decoded_image = decoded.reshape(28, 28)\n",
    "\n",
    "# Plot the original and reconstructed images\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "# Reconstructed Image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Reconstructed\")\n",
    "plt.imshow(decoded_image, cmap='gray')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
